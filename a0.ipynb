{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dasika-Vaishnavi/NLP_John-Hewitt/blob/main/a0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRdIio8gyD5F"
      },
      "source": [
        "# **Assignment 0: Tokenization!**\n",
        "\n",
        "# **Code Submission Instructions**\n",
        "1. Set `SUBMISSION_READY = True`\n",
        "2. In Google Colab, please click File > Download > Download .py\n",
        "3. Upload the .py file to Gradescope\n",
        "# **Introduction**\n",
        "\n",
        "This notebook implements a **byte-level tokenizer** using a **trie-based vocabulary** and an iterative **byte-pair merging algorithm** (similar to BPE).\n",
        "\n",
        "The goal is to learn a **compact and efficient vocabulary** from raw text data, which can then be used to tokenize and encode text into integer IDs for NLP applications.\n",
        "\n",
        "Key features:\n",
        "- Works at the **byte level**, so it can handle any Unicode text without pre-tokenization.\n",
        "- Uses a **maximum-length greedy tokenization** heuristic to match the longest token in the trie.\n",
        "- Supports **configurable vocabulary size**, maximum token length, and control over merging across spaces.\n",
        "- Can **save/load** the vocabulary for reuse in other tasks or models.\n",
        "\n",
        "This notebook contains:\n",
        "1. Class definitions for `TokenizerLearner` and `Tokenizer`.\n",
        "2. Dataset loading and preprocessing.\n",
        "3. Vocabulary learning loop with adjacency counting.\n",
        "4. Vocabulary saving and verification.\n",
        "5. Example encoding and decoding to test the tokenizer.\n",
        "\n",
        "There is no need for a GPU for this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyQeJ7iYyHIp"
      },
      "source": [
        "# **Imports and Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlF0lpw7uRmW",
        "outputId": "810eca8f-af18-41e8-b77e-213cee4a294b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pygtrie\n",
            "  Downloading pygtrie-2.5.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Downloading pygtrie-2.5.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pygtrie\n",
            "Successfully installed pygtrie-2.5.0\n"
          ]
        }
      ],
      "source": [
        "# If you are not using Google Colab, ensure you have Python 3.8+\n",
        "!pip install pygtrie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dK7ek49OuJOv"
      },
      "outputs": [],
      "source": [
        "import pygtrie\n",
        "from collections import Counter\n",
        "import datasets\n",
        "import json\n",
        "import itertools\n",
        "\n",
        "SUBMISSION_READY = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-DJLa5uuk49"
      },
      "source": [
        "# **TokenizerLearner**\n",
        "The `TokenizerLearner` class builds a vocabulary using byte-pair merges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mJt8X2GLuxoc"
      },
      "outputs": [],
      "source": [
        "class TokenizerLearner:\n",
        "    def __init__(self, data_iterator, vocab_size=65536, docs_per_iter=10000, max_token_length=30, no_subwords_across_space=True):\n",
        "        print(f\"\\nInitializing TokenizerLearner:\")\n",
        "        print(f\"  - vocab_size: {vocab_size}\")\n",
        "        print(f\"  - docs_per_iter: {docs_per_iter}\")\n",
        "        print(f\"  - max_token_length: {max_token_length}\")\n",
        "        self.vocab_size = vocab_size\n",
        "        self.data = data_iterator\n",
        "        self.no_subwords_across_space = no_subwords_across_space\n",
        "        self.data_iterator = iter(data_iterator)\n",
        "        self.max_token_length = max_token_length\n",
        "        self.docs_per_iter = docs_per_iter\n",
        "        self.vocab = None\n",
        "\n",
        "        # Byte-level vs unicode literals to control token boundaries\n",
        "        self.space_char = list(b' ')[0]\n",
        "        self.newline_char = list(b'\\n')[0]\n",
        "\n",
        "    def maybe_add(self, most_common_adjacencies):\n",
        "        for most_common_adjacency in most_common_adjacencies:\n",
        "            if self.space_char in most_common_adjacency[0][1] and self.no_subwords_across_space:\n",
        "                continue\n",
        "            if len(most_common_adjacency[0][0]) + len(most_common_adjacency[0][1]) > self.max_token_length:\n",
        "                continue\n",
        "            if (most_common_adjacency[0][0] == self.newline_char) + (most_common_adjacency[0][1] == self.newline_char) == 1:\n",
        "                continue\n",
        "            new_token = most_common_adjacency[0][0] + most_common_adjacency[0][1]\n",
        "            new_string = bytes(new_token).decode('utf-8', errors='ignore')\n",
        "            print(f\"  Most common adjacency: '{new_token}' (count: {most_common_adjacency[1]})\")\n",
        "            print(f\"  Most common adjacency: '{new_string}' (count: {most_common_adjacency[1]})\")\n",
        "            return new_token\n",
        "        return None\n",
        "\n",
        "    def learn(self):\n",
        "        print(\"\\nStarting vocabulary learning...\")\n",
        "        iteration = 0\n",
        "\n",
        "        # Make a tokenizer\n",
        "        print(\"  Creating tokenizer...\")\n",
        "        self.tokenizer = Tokenizer(vocab=self.vocab, max_token_length=self.max_token_length)\n",
        "\n",
        "        # Initialize with all one-length byte strings\n",
        "        self.tokenizer.update_trie([(x,) for x in range(256)])\n",
        "\n",
        "        while len(self.tokenizer.trie) < self.vocab_size:\n",
        "            iteration += 1\n",
        "            print(f\"\\nIteration {iteration}:\")\n",
        "            print(f\"Current vocab size: {len(self.tokenizer.trie)}\")\n",
        "\n",
        "            text_docs = []\n",
        "            for i in range(self.docs_per_iter):\n",
        "                try:\n",
        "                    doc = next(self.data_iterator)\n",
        "                except StopIteration:\n",
        "                    self.data_iterator = iter(self.data)\n",
        "                    doc = next(self.data_iterator)\n",
        "                text = doc['text'].encode('utf-8')\n",
        "                text_docs.append(text)\n",
        "\n",
        "            # In this section,\n",
        "            # (1) iterate through a batch of text documents, tokenizing\n",
        "            # each one and counting token pair adjacences.\n",
        "            # use self.tokenizer._tokenize(doc) to tokenize (so you'll need to\n",
        "            # implement that first.)\n",
        "            # (2) next, go through the sorted token adjacenies pair and\n",
        "            # use the self.maybe_add function to get which token should be added\n",
        "            # (3) update the tokenizer's trie with the new token.\n",
        "            # --------------------------------- BEGIN STUDENT TODO\n",
        "            # Token adjacency counting\n",
        "            adj_counter = Counter()\n",
        "            for text in text_docs:\n",
        "                tokens = self.tokenizer._tokenize(text.decode('utf-8', errors='ignore'))\n",
        "                for a, b in zip(tokens[:-1], tokens[1:]):\n",
        "                    adj = ((tuple(a), tuple(b)))\n",
        "                    adj_counter[adj] += 1\n",
        "\n",
        "            # Sort adjacencies by frequency\n",
        "            most_common = adj_counter.most_common()\n",
        "            new_token = self.maybe_add(most_common)\n",
        "            if new_token:\n",
        "                self.tokenizer.update_trie([tuple(new_token)])\n",
        "            else:\n",
        "                print(\"No new valid token found. Stopping early.\")\n",
        "                break\n",
        "            # --------------------------------- END STUDENT TODO\n",
        "\n",
        "    def save(self, path):\n",
        "        print(f\"\\nSaving vocabulary to {path}\")\n",
        "        with open(path, 'w') as f:\n",
        "            for token in sorted(self.tokenizer.trie):\n",
        "                f.write(json.dumps([token])+'\\n')\n",
        "        print(f\"Saved {len(self.tokenizer.trie)} tokens\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-8yYry-u3kf"
      },
      "source": [
        "# **Tokenizer**\n",
        "The `Tokenizer` class performs encoding/decoding with the learned vocabulary.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ork3fez7uO7v"
      },
      "outputs": [],
      "source": [
        "class Tokenizer:\n",
        "    def __init__(self, vocab_path=None, vocab=None, max_token_length=30, partial_trie=None):\n",
        "        print(f\"\\nInitializing Tokenizer:\")\n",
        "        print(f\"  - vocab_path: {vocab_path}\")\n",
        "        print(f\"  - vocab size: {len(vocab) if vocab else 'None'}\")\n",
        "        print(f\"  - max_token_length: {max_token_length}\")\n",
        "        self.vocab_path = vocab_path\n",
        "        self.id_to_tok = []\n",
        "        self.trie = pygtrie.Trie()\n",
        "        self.trie = self.trie if partial_trie is None else partial_trie\n",
        "        self.max_token_length = max_token_length\n",
        "\n",
        "        if vocab_path or vocab:\n",
        "            self.update_trie(vocab)\n",
        "\n",
        "    def update_trie(self, new_vocab=None):\n",
        "        print(\"\\nUpdating trie...\")\n",
        "        if new_vocab is None and self.vocab_path:\n",
        "            print(f\"Loading from vocab file: {self.vocab_path}\")\n",
        "            with open(self.vocab_path, 'r') as f:\n",
        "                for i, line in enumerate(f):\n",
        "                    token = tuple(json.loads(line)[0])\n",
        "                    self.id_to_tok.append(token)\n",
        "                    self.trie[token] = i\n",
        "        elif new_vocab:\n",
        "            for token in new_vocab:\n",
        "                print(token)\n",
        "                self.id_to_tok.append(token)\n",
        "                self.trie[token] = len(self.trie)\n",
        "\n",
        "    def encode(self, text):\n",
        "        return self._tokenize(text, return_ids=True)\n",
        "\n",
        "    def decode(self, tokens):\n",
        "        tokens = [self.id_to_tok[x] for x in tokens]\n",
        "        return bytes(itertools.chain.from_iterable(tokens)).decode('utf-8', errors='ignore')\n",
        "\n",
        "    def _tokenize(self, text, return_ids=False):\n",
        "        # In this section,\n",
        "        # (1) encode the text to receive a bytestring using\n",
        "        #     text.encode('utf-8', errors='ignore')\n",
        "        # (2) tokenize the string using the trie we're developing\n",
        "        # As a hint, consider how to use the self.max_token_length to\n",
        "        # efficiently query the trie, and note that we use the maximum-length\n",
        "        # greedy tokenization heuristic.\n",
        "        # (3) if return_ids=True, then return a list of integer ids. Otherwise,\n",
        "        # return a list of byte lists.\n",
        "        # --------------------------------- BEGIN STUDENT TODO\n",
        "        if isinstance(text, bytes):\n",
        "            input_bytes = text\n",
        "        else:\n",
        "            input_bytes = text.encode('utf-8', errors='ignore')\n",
        "        tokens = []\n",
        "        i = 0\n",
        "        while i < len(input_bytes):\n",
        "            matched = None\n",
        "            max_token_len = min(self.max_token_length, len(input_bytes) - i)\n",
        "            # Greedy, longest-first match\n",
        "            for l in range(max_token_len, 0, -1):\n",
        "                candidate = tuple(input_bytes[i:i+l])\n",
        "                if candidate in self.trie:\n",
        "                    matched = candidate\n",
        "                    break\n",
        "            if matched is not None:\n",
        "                tokens.append(matched)\n",
        "                i += len(matched)\n",
        "            else:\n",
        "                tokens.append((input_bytes[i],))\n",
        "                i += 1\n",
        "        if return_ids:\n",
        "            return [self.trie[token] for token in tokens]\n",
        "        else:\n",
        "            return tokens\n",
        "\n",
        "\n",
        "        # --------------------------------- END STUDENT TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjuMD9lVycvt"
      },
      "source": [
        "# **Dataset Loading, Tokenizer Training, and Saving Vocabulary**\n",
        "The dataset lives [here](https://huggingface.co/datasets/coms4705-hewitt/fineweb-linuxlike/tree/main). It should download automatically.\n",
        "\n",
        "Runtime roughly scales with vocab size. Feel free to play around with it. What happens when it is less than 256?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e7ac66077fce463bb4ee552d4a9d95f2",
            "a3717070348044418763c84da3f17cf0",
            "a1c86ad1a82e41638fda9b391e0cc75f",
            "ec5f7408d0024aceb570c8c06ef33330",
            "d82fd14f4602429eb8c466c822892d6f",
            "705b2bb680d848dfa76085f1610462f0",
            "4aed39f9fdcc40bc95111e4761e5642f",
            "f0836cde68ac48d5a2d07d59d904e23b",
            "1ccd344ba3b44c0888f6dab4421b57f7",
            "30ba1a38b8dc41b6bdf60c7fc7c4c769",
            "eef5f36f17c14a3b85c7121d1e1f84ca"
          ]
        },
        "id": "Gfk8KrWsvNGc",
        "outputId": "d949b2fe-9871-4f4e-b1db-6a5f42cf1184"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting tokenizer test...\n",
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/27.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7ac66077fce463bb4ee552d4a9d95f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded\n",
            "\n",
            "Creating TokenizerLearner...\n",
            "\n",
            "Initializing TokenizerLearner:\n",
            "  - vocab_size: 600\n",
            "  - docs_per_iter: 20\n",
            "  - max_token_length: 30\n",
            "Starting learning process...\n",
            "\n",
            "Starting vocabulary learning...\n",
            "  Creating tokenizer...\n",
            "\n",
            "Initializing Tokenizer:\n",
            "  - vocab_path: None\n",
            "  - vocab size: None\n",
            "  - max_token_length: 30\n",
            "\n",
            "Updating trie...\n",
            "(0,)\n",
            "(1,)\n",
            "(2,)\n",
            "(3,)\n",
            "(4,)\n",
            "(5,)\n",
            "(6,)\n",
            "(7,)\n",
            "(8,)\n",
            "(9,)\n",
            "(10,)\n",
            "(11,)\n",
            "(12,)\n",
            "(13,)\n",
            "(14,)\n",
            "(15,)\n",
            "(16,)\n",
            "(17,)\n",
            "(18,)\n",
            "(19,)\n",
            "(20,)\n",
            "(21,)\n",
            "(22,)\n",
            "(23,)\n",
            "(24,)\n",
            "(25,)\n",
            "(26,)\n",
            "(27,)\n",
            "(28,)\n",
            "(29,)\n",
            "(30,)\n",
            "(31,)\n",
            "(32,)\n",
            "(33,)\n",
            "(34,)\n",
            "(35,)\n",
            "(36,)\n",
            "(37,)\n",
            "(38,)\n",
            "(39,)\n",
            "(40,)\n",
            "(41,)\n",
            "(42,)\n",
            "(43,)\n",
            "(44,)\n",
            "(45,)\n",
            "(46,)\n",
            "(47,)\n",
            "(48,)\n",
            "(49,)\n",
            "(50,)\n",
            "(51,)\n",
            "(52,)\n",
            "(53,)\n",
            "(54,)\n",
            "(55,)\n",
            "(56,)\n",
            "(57,)\n",
            "(58,)\n",
            "(59,)\n",
            "(60,)\n",
            "(61,)\n",
            "(62,)\n",
            "(63,)\n",
            "(64,)\n",
            "(65,)\n",
            "(66,)\n",
            "(67,)\n",
            "(68,)\n",
            "(69,)\n",
            "(70,)\n",
            "(71,)\n",
            "(72,)\n",
            "(73,)\n",
            "(74,)\n",
            "(75,)\n",
            "(76,)\n",
            "(77,)\n",
            "(78,)\n",
            "(79,)\n",
            "(80,)\n",
            "(81,)\n",
            "(82,)\n",
            "(83,)\n",
            "(84,)\n",
            "(85,)\n",
            "(86,)\n",
            "(87,)\n",
            "(88,)\n",
            "(89,)\n",
            "(90,)\n",
            "(91,)\n",
            "(92,)\n",
            "(93,)\n",
            "(94,)\n",
            "(95,)\n",
            "(96,)\n",
            "(97,)\n",
            "(98,)\n",
            "(99,)\n",
            "(100,)\n",
            "(101,)\n",
            "(102,)\n",
            "(103,)\n",
            "(104,)\n",
            "(105,)\n",
            "(106,)\n",
            "(107,)\n",
            "(108,)\n",
            "(109,)\n",
            "(110,)\n",
            "(111,)\n",
            "(112,)\n",
            "(113,)\n",
            "(114,)\n",
            "(115,)\n",
            "(116,)\n",
            "(117,)\n",
            "(118,)\n",
            "(119,)\n",
            "(120,)\n",
            "(121,)\n",
            "(122,)\n",
            "(123,)\n",
            "(124,)\n",
            "(125,)\n",
            "(126,)\n",
            "(127,)\n",
            "(128,)\n",
            "(129,)\n",
            "(130,)\n",
            "(131,)\n",
            "(132,)\n",
            "(133,)\n",
            "(134,)\n",
            "(135,)\n",
            "(136,)\n",
            "(137,)\n",
            "(138,)\n",
            "(139,)\n",
            "(140,)\n",
            "(141,)\n",
            "(142,)\n",
            "(143,)\n",
            "(144,)\n",
            "(145,)\n",
            "(146,)\n",
            "(147,)\n",
            "(148,)\n",
            "(149,)\n",
            "(150,)\n",
            "(151,)\n",
            "(152,)\n",
            "(153,)\n",
            "(154,)\n",
            "(155,)\n",
            "(156,)\n",
            "(157,)\n",
            "(158,)\n",
            "(159,)\n",
            "(160,)\n",
            "(161,)\n",
            "(162,)\n",
            "(163,)\n",
            "(164,)\n",
            "(165,)\n",
            "(166,)\n",
            "(167,)\n",
            "(168,)\n",
            "(169,)\n",
            "(170,)\n",
            "(171,)\n",
            "(172,)\n",
            "(173,)\n",
            "(174,)\n",
            "(175,)\n",
            "(176,)\n",
            "(177,)\n",
            "(178,)\n",
            "(179,)\n",
            "(180,)\n",
            "(181,)\n",
            "(182,)\n",
            "(183,)\n",
            "(184,)\n",
            "(185,)\n",
            "(186,)\n",
            "(187,)\n",
            "(188,)\n",
            "(189,)\n",
            "(190,)\n",
            "(191,)\n",
            "(192,)\n",
            "(193,)\n",
            "(194,)\n",
            "(195,)\n",
            "(196,)\n",
            "(197,)\n",
            "(198,)\n",
            "(199,)\n",
            "(200,)\n",
            "(201,)\n",
            "(202,)\n",
            "(203,)\n",
            "(204,)\n",
            "(205,)\n",
            "(206,)\n",
            "(207,)\n",
            "(208,)\n",
            "(209,)\n",
            "(210,)\n",
            "(211,)\n",
            "(212,)\n",
            "(213,)\n",
            "(214,)\n",
            "(215,)\n",
            "(216,)\n",
            "(217,)\n",
            "(218,)\n",
            "(219,)\n",
            "(220,)\n",
            "(221,)\n",
            "(222,)\n",
            "(223,)\n",
            "(224,)\n",
            "(225,)\n",
            "(226,)\n",
            "(227,)\n",
            "(228,)\n",
            "(229,)\n",
            "(230,)\n",
            "(231,)\n",
            "(232,)\n",
            "(233,)\n",
            "(234,)\n",
            "(235,)\n",
            "(236,)\n",
            "(237,)\n",
            "(238,)\n",
            "(239,)\n",
            "(240,)\n",
            "(241,)\n",
            "(242,)\n",
            "(243,)\n",
            "(244,)\n",
            "(245,)\n",
            "(246,)\n",
            "(247,)\n",
            "(248,)\n",
            "(249,)\n",
            "(250,)\n",
            "(251,)\n",
            "(252,)\n",
            "(253,)\n",
            "(254,)\n",
            "(255,)\n",
            "\n",
            "Iteration 1:\n",
            "Current vocab size: 256\n",
            "  Most common adjacency: '(32, 116)' (count: 1253)\n",
            "  Most common adjacency: ' t' (count: 1253)\n",
            "\n",
            "Updating trie...\n",
            "(32, 116)\n",
            "\n",
            "Iteration 2:\n",
            "Current vocab size: 257\n",
            "  Most common adjacency: '(32, 97)' (count: 621)\n",
            "  Most common adjacency: ' a' (count: 621)\n",
            "\n",
            "Updating trie...\n",
            "(32, 97)\n",
            "\n",
            "Iteration 3:\n",
            "Current vocab size: 258\n",
            "  Most common adjacency: '(105, 110)' (count: 912)\n",
            "  Most common adjacency: 'in' (count: 912)\n",
            "\n",
            "Updating trie...\n",
            "(105, 110)\n",
            "\n",
            "Iteration 4:\n",
            "Current vocab size: 259\n",
            "  Most common adjacency: '(104, 101)' (count: 726)\n",
            "  Most common adjacency: 'he' (count: 726)\n",
            "\n",
            "Updating trie...\n",
            "(104, 101)\n",
            "\n",
            "Iteration 5:\n",
            "Current vocab size: 260\n",
            "  Most common adjacency: '(114, 101)' (count: 484)\n",
            "  Most common adjacency: 're' (count: 484)\n",
            "\n",
            "Updating trie...\n",
            "(114, 101)\n",
            "\n",
            "Iteration 6:\n",
            "Current vocab size: 261\n",
            "  Most common adjacency: '(101, 114)' (count: 817)\n",
            "  Most common adjacency: 'er' (count: 817)\n",
            "\n",
            "Updating trie...\n",
            "(101, 114)\n",
            "\n",
            "Iteration 7:\n",
            "Current vocab size: 262\n",
            "  Most common adjacency: '(111, 110)' (count: 431)\n",
            "  Most common adjacency: 'on' (count: 431)\n",
            "\n",
            "Updating trie...\n",
            "(111, 110)\n",
            "\n",
            "Iteration 8:\n",
            "Current vocab size: 263\n",
            "  Most common adjacency: '(111, 114)' (count: 231)\n",
            "  Most common adjacency: 'or' (count: 231)\n",
            "\n",
            "Updating trie...\n",
            "(111, 114)\n",
            "\n",
            "Iteration 9:\n",
            "Current vocab size: 264\n",
            "  Most common adjacency: '(32, 116, 104, 101)' (count: 629)\n",
            "  Most common adjacency: ' the' (count: 629)\n",
            "\n",
            "Updating trie...\n",
            "(32, 116, 104, 101)\n",
            "\n",
            "Iteration 10:\n",
            "Current vocab size: 265\n",
            "  Most common adjacency: '(97, 116)' (count: 202)\n",
            "  Most common adjacency: 'at' (count: 202)\n",
            "\n",
            "Updating trie...\n",
            "(97, 116)\n",
            "\n",
            "Iteration 11:\n",
            "Current vocab size: 266\n",
            "  Most common adjacency: '(32, 115)' (count: 176)\n",
            "  Most common adjacency: ' s' (count: 176)\n",
            "\n",
            "Updating trie...\n",
            "(32, 115)\n",
            "\n",
            "Iteration 12:\n",
            "Current vocab size: 267\n",
            "  Most common adjacency: '(111, 117)' (count: 1250)\n",
            "  Most common adjacency: 'ou' (count: 1250)\n",
            "\n",
            "Updating trie...\n",
            "(111, 117)\n",
            "\n",
            "Iteration 13:\n",
            "Current vocab size: 268\n",
            "  Most common adjacency: '(32, 99)' (count: 284)\n",
            "  Most common adjacency: ' c' (count: 284)\n",
            "\n",
            "Updating trie...\n",
            "(32, 99)\n",
            "\n",
            "Iteration 14:\n",
            "Current vocab size: 269\n",
            "  Most common adjacency: '(110, 100)' (count: 323)\n",
            "  Most common adjacency: 'nd' (count: 323)\n",
            "\n",
            "Updating trie...\n",
            "(110, 100)\n",
            "\n",
            "Iteration 15:\n",
            "Current vocab size: 270\n",
            "  Most common adjacency: '(32, 102)' (count: 542)\n",
            "  Most common adjacency: ' f' (count: 542)\n",
            "\n",
            "Updating trie...\n",
            "(32, 102)\n",
            "\n",
            "Iteration 16:\n",
            "Current vocab size: 271\n",
            "  Most common adjacency: '(97, 110)' (count: 489)\n",
            "  Most common adjacency: 'an' (count: 489)\n",
            "\n",
            "Updating trie...\n",
            "(97, 110)\n",
            "\n",
            "Iteration 17:\n",
            "Current vocab size: 272\n",
            "  Most common adjacency: '(105, 110, 103)' (count: 581)\n",
            "  Most common adjacency: 'ing' (count: 581)\n",
            "\n",
            "Updating trie...\n",
            "(105, 110, 103)\n",
            "\n",
            "Iteration 18:\n",
            "Current vocab size: 273\n",
            "  Most common adjacency: '(101, 115)' (count: 308)\n",
            "  Most common adjacency: 'es' (count: 308)\n",
            "\n",
            "Updating trie...\n",
            "(101, 115)\n",
            "\n",
            "Iteration 19:\n",
            "Current vocab size: 274\n",
            "  Most common adjacency: '(32, 119)' (count: 629)\n",
            "  Most common adjacency: ' w' (count: 629)\n",
            "\n",
            "Updating trie...\n",
            "(32, 119)\n",
            "\n",
            "Iteration 20:\n",
            "Current vocab size: 275\n",
            "  Most common adjacency: '(105, 116)' (count: 299)\n",
            "  Most common adjacency: 'it' (count: 299)\n",
            "\n",
            "Updating trie...\n",
            "(105, 116)\n",
            "\n",
            "Iteration 21:\n",
            "Current vocab size: 276\n",
            "  Most common adjacency: '(32, 109)' (count: 1447)\n",
            "  Most common adjacency: ' m' (count: 1447)\n",
            "\n",
            "Updating trie...\n",
            "(32, 109)\n",
            "\n",
            "Iteration 22:\n",
            "Current vocab size: 277\n",
            "  Most common adjacency: '(97, 108)' (count: 655)\n",
            "  Most common adjacency: 'al' (count: 655)\n",
            "\n",
            "Updating trie...\n",
            "(97, 108)\n",
            "\n",
            "Iteration 23:\n",
            "Current vocab size: 278\n",
            "  Most common adjacency: '(105, 115)' (count: 342)\n",
            "  Most common adjacency: 'is' (count: 342)\n",
            "\n",
            "Updating trie...\n",
            "(105, 115)\n",
            "\n",
            "Iteration 24:\n",
            "Current vocab size: 279\n",
            "  Most common adjacency: '(32, 112)' (count: 251)\n",
            "  Most common adjacency: ' p' (count: 251)\n",
            "\n",
            "Updating trie...\n",
            "(32, 112)\n",
            "\n",
            "Iteration 25:\n",
            "Current vocab size: 280\n",
            "  Most common adjacency: '(32, 100)' (count: 560)\n",
            "  Most common adjacency: ' d' (count: 560)\n",
            "\n",
            "Updating trie...\n",
            "(32, 100)\n",
            "\n",
            "Iteration 26:\n",
            "Current vocab size: 281\n",
            "  Most common adjacency: '(32, 97, 110, 100)' (count: 406)\n",
            "  Most common adjacency: ' and' (count: 406)\n",
            "\n",
            "Updating trie...\n",
            "(32, 97, 110, 100)\n",
            "\n",
            "Iteration 27:\n",
            "Current vocab size: 282\n",
            "  Most common adjacency: '(101, 100)' (count: 230)\n",
            "  Most common adjacency: 'ed' (count: 230)\n",
            "\n",
            "Updating trie...\n",
            "(101, 100)\n",
            "\n",
            "Iteration 28:\n",
            "Current vocab size: 283\n",
            "  Most common adjacency: '(105, 111, 110)' (count: 168)\n",
            "  Most common adjacency: 'ion' (count: 168)\n",
            "\n",
            "Updating trie...\n",
            "(105, 111, 110)\n",
            "\n",
            "Iteration 29:\n",
            "Current vocab size: 284\n",
            "  Most common adjacency: '(101, 110)' (count: 366)\n",
            "  Most common adjacency: 'en' (count: 366)\n",
            "\n",
            "Updating trie...\n",
            "(101, 110)\n",
            "\n",
            "Iteration 30:\n",
            "Current vocab size: 285\n",
            "  Most common adjacency: '(32, 111)' (count: 320)\n",
            "  Most common adjacency: ' o' (count: 320)\n",
            "\n",
            "Updating trie...\n",
            "(32, 111)\n",
            "\n",
            "Iteration 31:\n",
            "Current vocab size: 286\n",
            "  Most common adjacency: '(32, 116, 111)' (count: 209)\n",
            "  Most common adjacency: ' to' (count: 209)\n",
            "\n",
            "Updating trie...\n",
            "(32, 116, 111)\n",
            "\n",
            "Iteration 32:\n",
            "Current vocab size: 287\n",
            "  Most common adjacency: '(32, 98)' (count: 159)\n",
            "  Most common adjacency: ' b' (count: 159)\n",
            "\n",
            "Updating trie...\n",
            "(32, 98)\n",
            "\n",
            "Iteration 33:\n",
            "Current vocab size: 288\n",
            "  Most common adjacency: '(32, 105, 110)' (count: 281)\n",
            "  Most common adjacency: ' in' (count: 281)\n",
            "\n",
            "Updating trie...\n",
            "(32, 105, 110)\n",
            "\n",
            "Iteration 34:\n",
            "Current vocab size: 289\n",
            "  Most common adjacency: '(97, 114)' (count: 163)\n",
            "  Most common adjacency: 'ar' (count: 163)\n",
            "\n",
            "Updating trie...\n",
            "(97, 114)\n",
            "\n",
            "Iteration 35:\n",
            "Current vocab size: 290\n",
            "  Most common adjacency: '(32, 111, 102)' (count: 292)\n",
            "  Most common adjacency: ' of' (count: 292)\n",
            "\n",
            "Updating trie...\n",
            "(32, 111, 102)\n",
            "\n",
            "Iteration 36:\n",
            "Current vocab size: 291\n",
            "  Most common adjacency: '(124, 124)' (count: 443)\n",
            "  Most common adjacency: '||' (count: 443)\n",
            "\n",
            "Updating trie...\n",
            "(124, 124)\n",
            "\n",
            "Iteration 37:\n",
            "Current vocab size: 292\n",
            "  Most common adjacency: '(108, 101)' (count: 194)\n",
            "  Most common adjacency: 'le' (count: 194)\n",
            "\n",
            "Updating trie...\n",
            "(108, 101)\n",
            "\n",
            "Iteration 38:\n",
            "Current vocab size: 293\n",
            "  Most common adjacency: '(105, 99)' (count: 174)\n",
            "  Most common adjacency: 'ic' (count: 174)\n",
            "\n",
            "Updating trie...\n",
            "(105, 99)\n",
            "\n",
            "Iteration 39:\n",
            "Current vocab size: 294\n",
            "  Most common adjacency: '(111, 109)' (count: 173)\n",
            "  Most common adjacency: 'om' (count: 173)\n",
            "\n",
            "Updating trie...\n",
            "(111, 109)\n",
            "\n",
            "Iteration 40:\n",
            "Current vocab size: 295\n",
            "  Most common adjacency: '(117, 115)' (count: 211)\n",
            "  Most common adjacency: 'us' (count: 211)\n",
            "\n",
            "Updating trie...\n",
            "(117, 115)\n",
            "\n",
            "Iteration 41:\n",
            "Current vocab size: 296\n",
            "  Most common adjacency: '(46, 10)' (count: 138)\n",
            "  Most common adjacency: '.\n",
            "' (count: 138)\n",
            "\n",
            "Updating trie...\n",
            "(46, 10)\n",
            "\n",
            "Iteration 42:\n",
            "Current vocab size: 297\n",
            "  Most common adjacency: '(114, 111)' (count: 204)\n",
            "  Most common adjacency: 'ro' (count: 204)\n",
            "\n",
            "Updating trie...\n",
            "(114, 111)\n",
            "\n",
            "Iteration 43:\n",
            "Current vocab size: 298\n",
            "  Most common adjacency: '(32, 83)' (count: 455)\n",
            "  Most common adjacency: ' S' (count: 455)\n",
            "\n",
            "Updating trie...\n",
            "(32, 83)\n",
            "\n",
            "Iteration 44:\n",
            "Current vocab size: 299\n",
            "  Most common adjacency: '(99, 116)' (count: 185)\n",
            "  Most common adjacency: 'ct' (count: 185)\n",
            "\n",
            "Updating trie...\n",
            "(99, 116)\n",
            "\n",
            "Iteration 45:\n",
            "Current vocab size: 300\n",
            "  Most common adjacency: '(32, 121)' (count: 225)\n",
            "  Most common adjacency: ' y' (count: 225)\n",
            "\n",
            "Updating trie...\n",
            "(32, 121)\n",
            "\n",
            "Iteration 46:\n",
            "Current vocab size: 301\n",
            "  Most common adjacency: '(105, 108)' (count: 307)\n",
            "  Most common adjacency: 'il' (count: 307)\n",
            "\n",
            "Updating trie...\n",
            "(105, 108)\n",
            "\n",
            "Iteration 47:\n",
            "Current vocab size: 302\n",
            "  Most common adjacency: '(97, 115)' (count: 114)\n",
            "  Most common adjacency: 'as' (count: 114)\n",
            "\n",
            "Updating trie...\n",
            "(97, 115)\n",
            "\n",
            "Iteration 48:\n",
            "Current vocab size: 303\n",
            "  Most common adjacency: '(32, 68)' (count: 196)\n",
            "  Most common adjacency: ' D' (count: 196)\n",
            "\n",
            "Updating trie...\n",
            "(32, 68)\n",
            "\n",
            "Iteration 49:\n",
            "Current vocab size: 304\n",
            "  Most common adjacency: '(32, 121, 111, 117)' (count: 243)\n",
            "  Most common adjacency: ' you' (count: 243)\n",
            "\n",
            "Updating trie...\n",
            "(32, 121, 111, 117)\n",
            "\n",
            "Iteration 50:\n",
            "Current vocab size: 305\n",
            "  Most common adjacency: '(226, 128)' (count: 257)\n",
            "  Most common adjacency: '' (count: 257)\n",
            "\n",
            "Updating trie...\n",
            "(226, 128)\n",
            "\n",
            "Iteration 51:\n",
            "Current vocab size: 306\n",
            "  Most common adjacency: '(101, 110, 116)' (count: 247)\n",
            "  Most common adjacency: 'ent' (count: 247)\n",
            "\n",
            "Updating trie...\n",
            "(101, 110, 116)\n",
            "\n",
            "Iteration 52:\n",
            "Current vocab size: 307\n",
            "  Most common adjacency: '(32, 50)' (count: 357)\n",
            "  Most common adjacency: ' 2' (count: 357)\n",
            "\n",
            "Updating trie...\n",
            "(32, 50)\n",
            "\n",
            "Iteration 53:\n",
            "Current vocab size: 308\n",
            "  Most common adjacency: '(32, 116, 104)' (count: 230)\n",
            "  Most common adjacency: ' th' (count: 230)\n",
            "\n",
            "Updating trie...\n",
            "(32, 116, 104)\n",
            "\n",
            "Iteration 54:\n",
            "Current vocab size: 309\n",
            "  Most common adjacency: '(115, 116)' (count: 312)\n",
            "  Most common adjacency: 'st' (count: 312)\n",
            "\n",
            "Updating trie...\n",
            "(115, 116)\n",
            "\n",
            "Iteration 55:\n",
            "Current vocab size: 310\n",
            "  Most common adjacency: '(32, 73)' (count: 285)\n",
            "  Most common adjacency: ' I' (count: 285)\n",
            "\n",
            "Updating trie...\n",
            "(32, 73)\n",
            "\n",
            "Iteration 56:\n",
            "Current vocab size: 311\n",
            "  Most common adjacency: '(32, 104)' (count: 196)\n",
            "  Most common adjacency: ' h' (count: 196)\n",
            "\n",
            "Updating trie...\n",
            "(32, 104)\n",
            "\n",
            "Iteration 57:\n",
            "Current vocab size: 312\n",
            "  Most common adjacency: '(32, 111, 114)' (count: 263)\n",
            "  Most common adjacency: ' or' (count: 263)\n",
            "\n",
            "Updating trie...\n",
            "(32, 111, 114)\n",
            "\n",
            "Iteration 58:\n",
            "Current vocab size: 313\n",
            "  Most common adjacency: '(32, 114, 101)' (count: 124)\n",
            "  Most common adjacency: ' re' (count: 124)\n",
            "\n",
            "Updating trie...\n",
            "(32, 114, 101)\n",
            "\n",
            "Iteration 59:\n",
            "Current vocab size: 314\n",
            "  Most common adjacency: '(118, 101)' (count: 103)\n",
            "  Most common adjacency: 've' (count: 103)\n",
            "\n",
            "Updating trie...\n",
            "(118, 101)\n",
            "\n",
            "Iteration 60:\n",
            "Current vocab size: 315\n",
            "  Most common adjacency: '(101, 116)' (count: 89)\n",
            "  Most common adjacency: 'et' (count: 89)\n",
            "\n",
            "Updating trie...\n",
            "(101, 116)\n",
            "\n",
            "Iteration 61:\n",
            "Current vocab size: 316\n",
            "  Most common adjacency: '(32, 67)' (count: 130)\n",
            "  Most common adjacency: ' C' (count: 130)\n",
            "\n",
            "Updating trie...\n",
            "(32, 67)\n",
            "\n",
            "Iteration 62:\n",
            "Current vocab size: 317\n",
            "  Most common adjacency: '(32, 101)' (count: 147)\n",
            "  Most common adjacency: ' e' (count: 147)\n",
            "\n",
            "Updating trie...\n",
            "(32, 101)\n",
            "\n",
            "Iteration 63:\n",
            "Current vocab size: 318\n",
            "  Most common adjacency: '(114, 97)' (count: 465)\n",
            "  Most common adjacency: 'ra' (count: 465)\n",
            "\n",
            "Updating trie...\n",
            "(114, 97)\n",
            "\n",
            "Iteration 64:\n",
            "Current vocab size: 319\n",
            "  Most common adjacency: '(117, 116)' (count: 426)\n",
            "  Most common adjacency: 'ut' (count: 426)\n",
            "\n",
            "Updating trie...\n",
            "(117, 116)\n",
            "\n",
            "Iteration 65:\n",
            "Current vocab size: 320\n",
            "  Most common adjacency: '(32, 110)' (count: 172)\n",
            "  Most common adjacency: ' n' (count: 172)\n",
            "\n",
            "Updating trie...\n",
            "(32, 110)\n",
            "\n",
            "Iteration 66:\n",
            "Current vocab size: 321\n",
            "  Most common adjacency: '(111, 119)' (count: 188)\n",
            "  Most common adjacency: 'ow' (count: 188)\n",
            "\n",
            "Updating trie...\n",
            "(111, 119)\n",
            "\n",
            "Iteration 67:\n",
            "Current vocab size: 322\n",
            "  Most common adjacency: '(32, 102, 111, 114)' (count: 111)\n",
            "  Most common adjacency: ' for' (count: 111)\n",
            "\n",
            "Updating trie...\n",
            "(32, 102, 111, 114)\n",
            "\n",
            "Iteration 68:\n",
            "Current vocab size: 323\n",
            "  Most common adjacency: '(111, 116)' (count: 204)\n",
            "  Most common adjacency: 'ot' (count: 204)\n",
            "\n",
            "Updating trie...\n",
            "(111, 116)\n",
            "\n",
            "Iteration 69:\n",
            "Current vocab size: 324\n",
            "  Most common adjacency: '(105, 97)' (count: 418)\n",
            "  Most common adjacency: 'ia' (count: 418)\n",
            "\n",
            "Updating trie...\n",
            "(105, 97)\n",
            "\n",
            "Iteration 70:\n",
            "Current vocab size: 325\n",
            "  Most common adjacency: '(32, 108)' (count: 151)\n",
            "  Most common adjacency: ' l' (count: 151)\n",
            "\n",
            "Updating trie...\n",
            "(32, 108)\n",
            "\n",
            "Iteration 71:\n",
            "Current vocab size: 326\n",
            "  Most common adjacency: '(32, 105, 115)' (count: 223)\n",
            "  Most common adjacency: ' is' (count: 223)\n",
            "\n",
            "Updating trie...\n",
            "(32, 105, 115)\n",
            "\n",
            "Iteration 72:\n",
            "Current vocab size: 327\n",
            "  Most common adjacency: '(32, 77)' (count: 135)\n",
            "  Most common adjacency: ' M' (count: 135)\n",
            "\n",
            "Updating trie...\n",
            "(32, 77)\n",
            "\n",
            "Iteration 73:\n",
            "Current vocab size: 328\n",
            "  Most common adjacency: '(97, 100)' (count: 67)\n",
            "  Most common adjacency: 'ad' (count: 67)\n",
            "\n",
            "Updating trie...\n",
            "(97, 100)\n",
            "\n",
            "Iteration 74:\n",
            "Current vocab size: 329\n",
            "  Most common adjacency: '(105, 109)' (count: 226)\n",
            "  Most common adjacency: 'im' (count: 226)\n",
            "\n",
            "Updating trie...\n",
            "(105, 109)\n",
            "\n",
            "Iteration 75:\n",
            "Current vocab size: 330\n",
            "  Most common adjacency: '(32, 121, 111, 117, 114)' (count: 117)\n",
            "  Most common adjacency: ' your' (count: 117)\n",
            "\n",
            "Updating trie...\n",
            "(32, 121, 111, 117, 114)\n",
            "\n",
            "Iteration 76:\n",
            "Current vocab size: 331\n",
            "  Most common adjacency: '(116, 101, 114)' (count: 133)\n",
            "  Most common adjacency: 'ter' (count: 133)\n",
            "\n",
            "Updating trie...\n",
            "(116, 101, 114)\n",
            "\n",
            "Iteration 77:\n",
            "Current vocab size: 332\n",
            "  Most common adjacency: '(46, 46)' (count: 1077)\n",
            "  Most common adjacency: '..' (count: 1077)\n",
            "\n",
            "Updating trie...\n",
            "(46, 46)\n",
            "\n",
            "Iteration 78:\n",
            "Current vocab size: 333\n",
            "  Most common adjacency: '(115, 46)' (count: 614)\n",
            "  Most common adjacency: 's.' (count: 614)\n",
            "\n",
            "Updating trie...\n",
            "(115, 46)\n",
            "\n",
            "Iteration 79:\n",
            "Current vocab size: 334\n",
            "  Most common adjacency: '(32, 84)' (count: 142)\n",
            "  Most common adjacency: ' T' (count: 142)\n",
            "\n",
            "Updating trie...\n",
            "(32, 84)\n",
            "\n",
            "Iteration 80:\n",
            "Current vocab size: 335\n",
            "  Most common adjacency: '(32, 111, 110)' (count: 65)\n",
            "  Most common adjacency: ' on' (count: 65)\n",
            "\n",
            "Updating trie...\n",
            "(32, 111, 110)\n",
            "\n",
            "Iteration 81:\n",
            "Current vocab size: 336\n",
            "  Most common adjacency: '(99, 101)' (count: 136)\n",
            "  Most common adjacency: 'ce' (count: 136)\n",
            "\n",
            "Updating trie...\n",
            "(99, 101)\n",
            "\n",
            "Iteration 82:\n",
            "Current vocab size: 337\n",
            "  Most common adjacency: '(45, 45)' (count: 701)\n",
            "  Most common adjacency: '--' (count: 701)\n",
            "\n",
            "Updating trie...\n",
            "(45, 45)\n",
            "\n",
            "Iteration 83:\n",
            "Current vocab size: 338\n",
            "  Most common adjacency: '(97, 109)' (count: 115)\n",
            "  Most common adjacency: 'am' (count: 115)\n",
            "\n",
            "Updating trie...\n",
            "(97, 109)\n",
            "\n",
            "Iteration 84:\n",
            "Current vocab size: 339\n",
            "  Most common adjacency: '(108, 108)' (count: 72)\n",
            "  Most common adjacency: 'll' (count: 72)\n",
            "\n",
            "Updating trie...\n",
            "(108, 108)\n",
            "\n",
            "Iteration 85:\n",
            "Current vocab size: 340\n",
            "  Most common adjacency: '(48, 48)' (count: 258)\n",
            "  Most common adjacency: '00' (count: 258)\n",
            "\n",
            "Updating trie...\n",
            "(48, 48)\n",
            "\n",
            "Iteration 86:\n",
            "Current vocab size: 341\n",
            "  Most common adjacency: '(224, 170)' (count: 785)\n",
            "  Most common adjacency: '' (count: 785)\n",
            "\n",
            "Updating trie...\n",
            "(224, 170)\n",
            "\n",
            "Iteration 87:\n",
            "Current vocab size: 342\n",
            "  Most common adjacency: '(226, 128, 153)' (count: 130)\n",
            "  Most common adjacency: 'â€™' (count: 130)\n",
            "\n",
            "Updating trie...\n",
            "(226, 128, 153)\n",
            "\n",
            "Iteration 88:\n",
            "Current vocab size: 343\n",
            "  Most common adjacency: '(101, 99, 116)' (count: 109)\n",
            "  Most common adjacency: 'ect' (count: 109)\n",
            "\n",
            "Updating trie...\n",
            "(101, 99, 116)\n",
            "\n",
            "Iteration 89:\n",
            "Current vocab size: 344\n",
            "  Most common adjacency: '(101, 120)' (count: 64)\n",
            "  Most common adjacency: 'ex' (count: 64)\n",
            "\n",
            "Updating trie...\n",
            "(101, 120)\n",
            "\n",
            "Iteration 90:\n",
            "Current vocab size: 345\n",
            "  Most common adjacency: '(101, 115, 116)' (count: 202)\n",
            "  Most common adjacency: 'est' (count: 202)\n",
            "\n",
            "Updating trie...\n",
            "(101, 115, 116)\n",
            "\n",
            "Iteration 91:\n",
            "Current vocab size: 346\n",
            "  Most common adjacency: '(97, 116, 105, 111, 110)' (count: 95)\n",
            "  Most common adjacency: 'ation' (count: 95)\n",
            "\n",
            "Updating trie...\n",
            "(97, 116, 105, 111, 110)\n",
            "\n",
            "Iteration 92:\n",
            "Current vocab size: 347\n",
            "  Most common adjacency: '(120, 97, 109)' (count: 438)\n",
            "  Most common adjacency: 'xam' (count: 438)\n",
            "\n",
            "Updating trie...\n",
            "(120, 97, 109)\n",
            "\n",
            "Iteration 93:\n",
            "Current vocab size: 348\n",
            "  Most common adjacency: '(99, 111)' (count: 155)\n",
            "  Most common adjacency: 'co' (count: 155)\n",
            "\n",
            "Updating trie...\n",
            "(99, 111)\n",
            "\n",
            "Iteration 94:\n",
            "Current vocab size: 349\n",
            "  Most common adjacency: '(97, 98)' (count: 45)\n",
            "  Most common adjacency: 'ab' (count: 45)\n",
            "\n",
            "Updating trie...\n",
            "(97, 98)\n",
            "\n",
            "Iteration 95:\n",
            "Current vocab size: 350\n",
            "  Most common adjacency: '(32, 117, 115)' (count: 109)\n",
            "  Most common adjacency: ' us' (count: 109)\n",
            "\n",
            "Updating trie...\n",
            "(32, 117, 115)\n",
            "\n",
            "Iteration 96:\n",
            "Current vocab size: 351\n",
            "  Most common adjacency: '(112, 112)' (count: 148)\n",
            "  Most common adjacency: 'pp' (count: 148)\n",
            "\n",
            "Updating trie...\n",
            "(112, 112)\n",
            "\n",
            "Iteration 97:\n",
            "Current vocab size: 352\n",
            "  Most common adjacency: '(32, 98, 101)' (count: 108)\n",
            "  Most common adjacency: ' be' (count: 108)\n",
            "\n",
            "Updating trie...\n",
            "(32, 98, 101)\n",
            "\n",
            "Iteration 98:\n",
            "Current vocab size: 353\n",
            "  Most common adjacency: '(108, 121)' (count: 157)\n",
            "  Most common adjacency: 'ly' (count: 157)\n",
            "\n",
            "Updating trie...\n",
            "(108, 121)\n",
            "\n",
            "Iteration 99:\n",
            "Current vocab size: 354\n",
            "  Most common adjacency: '(32, 116, 104, 97, 116)' (count: 155)\n",
            "  Most common adjacency: ' that' (count: 155)\n",
            "\n",
            "Updating trie...\n",
            "(32, 116, 104, 97, 116)\n",
            "\n",
            "Iteration 100:\n",
            "Current vocab size: 355\n",
            "  Most common adjacency: '(32, 80)' (count: 68)\n",
            "  Most common adjacency: ' P' (count: 68)\n",
            "\n",
            "Updating trie...\n",
            "(32, 80)\n",
            "\n",
            "Iteration 101:\n",
            "Current vocab size: 356\n",
            "  Most common adjacency: '(32, 65)' (count: 89)\n",
            "  Most common adjacency: ' A' (count: 89)\n",
            "\n",
            "Updating trie...\n",
            "(32, 65)\n",
            "\n",
            "Iteration 102:\n",
            "Current vocab size: 357\n",
            "  Most common adjacency: '(99, 104)' (count: 136)\n",
            "  Most common adjacency: 'ch' (count: 136)\n",
            "\n",
            "Updating trie...\n",
            "(99, 104)\n",
            "\n",
            "Iteration 103:\n",
            "Current vocab size: 358\n",
            "  Most common adjacency: '(118, 101, 114)' (count: 101)\n",
            "  Most common adjacency: 'ver' (count: 101)\n",
            "\n",
            "Updating trie...\n",
            "(118, 101, 114)\n",
            "\n",
            "Iteration 104:\n",
            "Current vocab size: 359\n",
            "  Most common adjacency: '(117, 110)' (count: 99)\n",
            "  Most common adjacency: 'un' (count: 99)\n",
            "\n",
            "Updating trie...\n",
            "(117, 110)\n",
            "\n",
            "Iteration 105:\n",
            "Current vocab size: 360\n",
            "  Most common adjacency: '(32, 112, 111)' (count: 70)\n",
            "  Most common adjacency: ' po' (count: 70)\n",
            "\n",
            "Updating trie...\n",
            "(32, 112, 111)\n",
            "\n",
            "Iteration 106:\n",
            "Current vocab size: 361\n",
            "  Most common adjacency: '(32, 99, 111, 110)' (count: 69)\n",
            "  Most common adjacency: ' con' (count: 69)\n",
            "\n",
            "Updating trie...\n",
            "(32, 99, 111, 110)\n",
            "\n",
            "Iteration 107:\n",
            "Current vocab size: 362\n",
            "  Most common adjacency: '(101, 109)' (count: 83)\n",
            "  Most common adjacency: 'em' (count: 83)\n",
            "\n",
            "Updating trie...\n",
            "(101, 109)\n",
            "\n",
            "Iteration 108:\n",
            "Current vocab size: 363\n",
            "  Most common adjacency: '(115, 115)' (count: 98)\n",
            "  Most common adjacency: 'ss' (count: 98)\n",
            "\n",
            "Updating trie...\n",
            "(115, 115)\n",
            "\n",
            "Iteration 109:\n",
            "Current vocab size: 364\n",
            "  Most common adjacency: '(32, 103)' (count: 79)\n",
            "  Most common adjacency: ' g' (count: 79)\n",
            "\n",
            "Updating trie...\n",
            "(32, 103)\n",
            "\n",
            "Iteration 110:\n",
            "Current vocab size: 365\n",
            "  Most common adjacency: '(105, 103)' (count: 87)\n",
            "  Most common adjacency: 'ig' (count: 87)\n",
            "\n",
            "Updating trie...\n",
            "(105, 103)\n",
            "\n",
            "Iteration 111:\n",
            "Current vocab size: 366\n",
            "  Most common adjacency: '(101, 108)' (count: 62)\n",
            "  Most common adjacency: 'el' (count: 62)\n",
            "\n",
            "Updating trie...\n",
            "(101, 108)\n",
            "\n",
            "Iteration 112:\n",
            "Current vocab size: 367\n",
            "  Most common adjacency: '(117, 108)' (count: 174)\n",
            "  Most common adjacency: 'ul' (count: 174)\n",
            "\n",
            "Updating trie...\n",
            "(117, 108)\n",
            "\n",
            "Iteration 113:\n",
            "Current vocab size: 368\n",
            "  Most common adjacency: '(95, 95)' (count: 997)\n",
            "  Most common adjacency: '__' (count: 997)\n",
            "\n",
            "Updating trie...\n",
            "(95, 95)\n",
            "\n",
            "Iteration 114:\n",
            "Current vocab size: 369\n",
            "  Most common adjacency: '(32, 208)' (count: 67)\n",
            "  Most common adjacency: ' ' (count: 67)\n",
            "\n",
            "Updating trie...\n",
            "(32, 208)\n",
            "\n",
            "Iteration 115:\n",
            "Current vocab size: 370\n",
            "  Most common adjacency: '(95, 95, 95, 95)' (count: 103)\n",
            "  Most common adjacency: '____' (count: 103)\n",
            "\n",
            "Updating trie...\n",
            "(95, 95, 95, 95)\n",
            "\n",
            "Iteration 116:\n",
            "Current vocab size: 371\n",
            "  Most common adjacency: '(32, 97, 110)' (count: 147)\n",
            "  Most common adjacency: ' an' (count: 147)\n",
            "\n",
            "Updating trie...\n",
            "(32, 97, 110)\n",
            "\n",
            "Iteration 117:\n",
            "Current vocab size: 372\n",
            "  Most common adjacency: '(10, 62)' (count: 110)\n",
            "  Most common adjacency: '\n",
            ">' (count: 110)\n",
            "\n",
            "Updating trie...\n",
            "(10, 62)\n",
            "\n",
            "Iteration 118:\n",
            "Current vocab size: 373\n",
            "  Most common adjacency: '(32, 49)' (count: 535)\n",
            "  Most common adjacency: ' 1' (count: 535)\n",
            "\n",
            "Updating trie...\n",
            "(32, 49)\n",
            "\n",
            "Iteration 119:\n",
            "Current vocab size: 374\n",
            "  Most common adjacency: '(107, 101)' (count: 120)\n",
            "  Most common adjacency: 'ke' (count: 120)\n",
            "\n",
            "Updating trie...\n",
            "(107, 101)\n",
            "\n",
            "Iteration 120:\n",
            "Current vocab size: 375\n",
            "  Most common adjacency: '(97, 103)' (count: 133)\n",
            "  Most common adjacency: 'ag' (count: 133)\n",
            "\n",
            "Updating trie...\n",
            "(97, 103)\n",
            "\n",
            "Iteration 121:\n",
            "Current vocab size: 376\n",
            "  Most common adjacency: '(32, 110, 111, 116)' (count: 78)\n",
            "  Most common adjacency: ' not' (count: 78)\n",
            "\n",
            "Updating trie...\n",
            "(32, 110, 111, 116)\n",
            "\n",
            "Iteration 122:\n",
            "Current vocab size: 377\n",
            "  Most common adjacency: '(101, 110, 100)' (count: 124)\n",
            "  Most common adjacency: 'end' (count: 124)\n",
            "\n",
            "Updating trie...\n",
            "(101, 110, 100)\n",
            "\n",
            "Iteration 123:\n",
            "Current vocab size: 378\n",
            "  Most common adjacency: '(32, 40)' (count: 72)\n",
            "  Most common adjacency: ' (' (count: 72)\n",
            "\n",
            "Updating trie...\n",
            "(32, 40)\n",
            "\n",
            "Iteration 124:\n",
            "Current vocab size: 379\n",
            "  Most common adjacency: '(32, 87)' (count: 65)\n",
            "  Most common adjacency: ' W' (count: 65)\n",
            "\n",
            "Updating trie...\n",
            "(32, 87)\n",
            "\n",
            "Iteration 125:\n",
            "Current vocab size: 380\n",
            "  Most common adjacency: '(105, 100)' (count: 42)\n",
            "  Most common adjacency: 'id' (count: 42)\n",
            "\n",
            "Updating trie...\n",
            "(105, 100)\n",
            "\n",
            "Iteration 126:\n",
            "Current vocab size: 381\n",
            "  Most common adjacency: '(32, 99, 97, 110)' (count: 44)\n",
            "  Most common adjacency: ' can' (count: 44)\n",
            "\n",
            "Updating trie...\n",
            "(32, 99, 97, 110)\n",
            "\n",
            "Iteration 127:\n",
            "Current vocab size: 382\n",
            "  Most common adjacency: '(32, 99, 111, 109)' (count: 122)\n",
            "  Most common adjacency: ' com' (count: 122)\n",
            "\n",
            "Updating trie...\n",
            "(32, 99, 111, 109)\n",
            "\n",
            "Iteration 128:\n",
            "Current vocab size: 383\n",
            "  Most common adjacency: '(97, 105, 110)' (count: 131)\n",
            "  Most common adjacency: 'ain' (count: 131)\n",
            "\n",
            "Updating trie...\n",
            "(97, 105, 110)\n",
            "\n",
            "Iteration 129:\n",
            "Current vocab size: 384\n",
            "  Most common adjacency: '(97, 121)' (count: 70)\n",
            "  Most common adjacency: 'ay' (count: 70)\n",
            "\n",
            "Updating trie...\n",
            "(97, 121)\n",
            "\n",
            "Iteration 130:\n",
            "Current vocab size: 385\n",
            "  Most common adjacency: '(105, 108, 108)' (count: 67)\n",
            "  Most common adjacency: 'ill' (count: 67)\n",
            "\n",
            "Updating trie...\n",
            "(105, 108, 108)\n",
            "\n",
            "Iteration 131:\n",
            "Current vocab size: 386\n",
            "  Most common adjacency: '(32, 115, 116)' (count: 138)\n",
            "  Most common adjacency: ' st' (count: 138)\n",
            "\n",
            "Updating trie...\n",
            "(32, 115, 116)\n",
            "\n",
            "Iteration 132:\n",
            "Current vocab size: 387\n",
            "  Most common adjacency: '(105, 116, 104)' (count: 95)\n",
            "  Most common adjacency: 'ith' (count: 95)\n",
            "\n",
            "Updating trie...\n",
            "(105, 116, 104)\n",
            "\n",
            "Iteration 133:\n",
            "Current vocab size: 388\n",
            "  Most common adjacency: '(32, 66)' (count: 120)\n",
            "  Most common adjacency: ' B' (count: 120)\n",
            "\n",
            "Updating trie...\n",
            "(32, 66)\n",
            "\n",
            "Iteration 134:\n",
            "Current vocab size: 389\n",
            "  Most common adjacency: '(32, 101, 120)' (count: 136)\n",
            "  Most common adjacency: ' ex' (count: 136)\n",
            "\n",
            "Updating trie...\n",
            "(32, 101, 120)\n",
            "\n",
            "Iteration 135:\n",
            "Current vocab size: 390\n",
            "  Most common adjacency: '(111, 100)' (count: 68)\n",
            "  Most common adjacency: 'od' (count: 68)\n",
            "\n",
            "Updating trie...\n",
            "(111, 100)\n",
            "\n",
            "Iteration 136:\n",
            "Current vocab size: 391\n",
            "  Most common adjacency: '(57, 57)' (count: 125)\n",
            "  Most common adjacency: '99' (count: 125)\n",
            "\n",
            "Updating trie...\n",
            "(57, 57)\n",
            "\n",
            "Iteration 137:\n",
            "Current vocab size: 392\n",
            "  Most common adjacency: '(61, 61)' (count: 439)\n",
            "  Most common adjacency: '==' (count: 439)\n",
            "\n",
            "Updating trie...\n",
            "(61, 61)\n",
            "\n",
            "Iteration 138:\n",
            "Current vocab size: 393\n",
            "  Most common adjacency: '(32, 97, 116)' (count: 118)\n",
            "  Most common adjacency: ' at' (count: 118)\n",
            "\n",
            "Updating trie...\n",
            "(32, 97, 116)\n",
            "\n",
            "Iteration 139:\n",
            "Current vocab size: 394\n",
            "  Most common adjacency: '(108, 100)' (count: 139)\n",
            "  Most common adjacency: 'ld' (count: 139)\n",
            "\n",
            "Updating trie...\n",
            "(108, 100)\n",
            "\n",
            "Iteration 140:\n",
            "Current vocab size: 395\n",
            "  Most common adjacency: '(32, 112, 114, 111)' (count: 58)\n",
            "  Most common adjacency: ' pro' (count: 58)\n",
            "\n",
            "Updating trie...\n",
            "(32, 112, 114, 111)\n",
            "\n",
            "Iteration 141:\n",
            "Current vocab size: 396\n",
            "  Most common adjacency: '(117, 114)' (count: 117)\n",
            "  Most common adjacency: 'ur' (count: 117)\n",
            "\n",
            "Updating trie...\n",
            "(117, 114)\n",
            "\n",
            "Iteration 142:\n",
            "Current vocab size: 397\n",
            "  Most common adjacency: '(32, 105, 116)' (count: 69)\n",
            "  Most common adjacency: ' it' (count: 69)\n",
            "\n",
            "Updating trie...\n",
            "(32, 105, 116)\n",
            "\n",
            "Iteration 143:\n",
            "Current vocab size: 398\n",
            "  Most common adjacency: '(97, 103, 101)' (count: 493)\n",
            "  Most common adjacency: 'age' (count: 493)\n",
            "\n",
            "Updating trie...\n",
            "(97, 103, 101)\n",
            "\n",
            "Iteration 144:\n",
            "Current vocab size: 399\n",
            "  Most common adjacency: '(10, 45)' (count: 107)\n",
            "  Most common adjacency: '\n",
            "-' (count: 107)\n",
            "\n",
            "Updating trie...\n",
            "(10, 45)\n",
            "\n",
            "Iteration 145:\n",
            "Current vocab size: 400\n",
            "  Most common adjacency: '(32, 46)' (count: 83)\n",
            "  Most common adjacency: ' .' (count: 83)\n",
            "\n",
            "Updating trie...\n",
            "(32, 46)\n",
            "\n",
            "Iteration 146:\n",
            "Current vocab size: 401\n",
            "  Most common adjacency: '(109, 101, 110, 116)' (count: 161)\n",
            "  Most common adjacency: 'ment' (count: 161)\n",
            "\n",
            "Updating trie...\n",
            "(109, 101, 110, 116)\n",
            "\n",
            "Iteration 147:\n",
            "Current vocab size: 402\n",
            "  Most common adjacency: '(111, 108)' (count: 65)\n",
            "  Most common adjacency: 'ol' (count: 65)\n",
            "\n",
            "Updating trie...\n",
            "(111, 108)\n",
            "\n",
            "Iteration 148:\n",
            "Current vocab size: 403\n",
            "  Most common adjacency: '(112, 101)' (count: 99)\n",
            "  Most common adjacency: 'pe' (count: 99)\n",
            "\n",
            "Updating trie...\n",
            "(112, 101)\n",
            "\n",
            "Iteration 149:\n",
            "Current vocab size: 404\n",
            "  Most common adjacency: '(32, 62)' (count: 99)\n",
            "  Most common adjacency: ' >' (count: 99)\n",
            "\n",
            "Updating trie...\n",
            "(32, 62)\n",
            "\n",
            "Iteration 150:\n",
            "Current vocab size: 405\n",
            "  Most common adjacency: '(114, 97, 116)' (count: 359)\n",
            "  Most common adjacency: 'rat' (count: 359)\n",
            "\n",
            "Updating trie...\n",
            "(114, 97, 116)\n",
            "\n",
            "Iteration 151:\n",
            "Current vocab size: 406\n",
            "  Most common adjacency: '(108, 111)' (count: 91)\n",
            "  Most common adjacency: 'lo' (count: 91)\n",
            "\n",
            "Updating trie...\n",
            "(108, 111)\n",
            "\n",
            "Iteration 152:\n",
            "Current vocab size: 407\n",
            "  Most common adjacency: '(101, 114, 115)' (count: 114)\n",
            "  Most common adjacency: 'ers' (count: 114)\n",
            "\n",
            "Updating trie...\n",
            "(101, 114, 115)\n",
            "\n",
            "Iteration 153:\n",
            "Current vocab size: 408\n",
            "  Most common adjacency: '(32, 226, 128)' (count: 112)\n",
            "  Most common adjacency: ' ' (count: 112)\n",
            "\n",
            "Updating trie...\n",
            "(32, 226, 128)\n",
            "\n",
            "Iteration 154:\n",
            "Current vocab size: 409\n",
            "  Most common adjacency: '(32, 63)' (count: 291)\n",
            "  Most common adjacency: ' ?' (count: 291)\n",
            "\n",
            "Updating trie...\n",
            "(32, 63)\n",
            "\n",
            "Iteration 155:\n",
            "Current vocab size: 410\n",
            "  Most common adjacency: '(32, 97, 100)' (count: 113)\n",
            "  Most common adjacency: ' ad' (count: 113)\n",
            "\n",
            "Updating trie...\n",
            "(32, 97, 100)\n",
            "\n",
            "Iteration 156:\n",
            "Current vocab size: 411\n",
            "  Most common adjacency: '(32, 79)' (count: 113)\n",
            "  Most common adjacency: ' O' (count: 113)\n",
            "\n",
            "Updating trie...\n",
            "(32, 79)\n",
            "\n",
            "Iteration 157:\n",
            "Current vocab size: 412\n",
            "  Most common adjacency: '(97, 99)' (count: 123)\n",
            "  Most common adjacency: 'ac' (count: 123)\n",
            "\n",
            "Updating trie...\n",
            "(97, 99)\n",
            "\n",
            "Iteration 158:\n",
            "Current vocab size: 413\n",
            "  Most common adjacency: '(100, 101, 100)' (count: 219)\n",
            "  Most common adjacency: 'ded' (count: 219)\n",
            "\n",
            "Updating trie...\n",
            "(100, 101, 100)\n",
            "\n",
            "Iteration 159:\n",
            "Current vocab size: 414\n",
            "  Most common adjacency: '(32, 45)' (count: 35)\n",
            "  Most common adjacency: ' -' (count: 35)\n",
            "\n",
            "Updating trie...\n",
            "(32, 45)\n",
            "\n",
            "Iteration 160:\n",
            "Current vocab size: 415\n",
            "  Most common adjacency: '(111, 114, 107)' (count: 61)\n",
            "  Most common adjacency: 'ork' (count: 61)\n",
            "\n",
            "Updating trie...\n",
            "(111, 114, 107)\n",
            "\n",
            "Iteration 161:\n",
            "Current vocab size: 416\n",
            "  Most common adjacency: '(99, 111, 109)' (count: 59)\n",
            "  Most common adjacency: 'com' (count: 59)\n",
            "\n",
            "Updating trie...\n",
            "(99, 111, 109)\n",
            "\n",
            "Iteration 162:\n",
            "Current vocab size: 417\n",
            "  Most common adjacency: '(105, 110, 101)' (count: 69)\n",
            "  Most common adjacency: 'ine' (count: 69)\n",
            "\n",
            "Updating trie...\n",
            "(105, 110, 101)\n",
            "\n",
            "Iteration 163:\n",
            "Current vocab size: 418\n",
            "  Most common adjacency: '(105, 115, 116)' (count: 61)\n",
            "  Most common adjacency: 'ist' (count: 61)\n",
            "\n",
            "Updating trie...\n",
            "(105, 115, 116)\n",
            "\n",
            "Iteration 164:\n",
            "Current vocab size: 419\n",
            "  Most common adjacency: '(118, 105, 99)' (count: 140)\n",
            "  Most common adjacency: 'vic' (count: 140)\n",
            "\n",
            "Updating trie...\n",
            "(118, 105, 99)\n",
            "\n",
            "Iteration 165:\n",
            "Current vocab size: 420\n",
            "  Most common adjacency: '(32, 118)' (count: 192)\n",
            "  Most common adjacency: ' v' (count: 192)\n",
            "\n",
            "Updating trie...\n",
            "(32, 118)\n",
            "\n",
            "Iteration 166:\n",
            "Current vocab size: 421\n",
            "  Most common adjacency: '(32, 119, 105, 116, 104)' (count: 115)\n",
            "  Most common adjacency: ' with' (count: 115)\n",
            "\n",
            "Updating trie...\n",
            "(32, 119, 105, 116, 104)\n",
            "\n",
            "Iteration 167:\n",
            "Current vocab size: 422\n",
            "  Most common adjacency: '(111, 117, 114)' (count: 84)\n",
            "  Most common adjacency: 'our' (count: 84)\n",
            "\n",
            "Updating trie...\n",
            "(111, 117, 114)\n",
            "\n",
            "Iteration 168:\n",
            "Current vocab size: 423\n",
            "  Most common adjacency: '(114, 97, 109)' (count: 126)\n",
            "  Most common adjacency: 'ram' (count: 126)\n",
            "\n",
            "Updating trie...\n",
            "(114, 97, 109)\n",
            "\n",
            "Iteration 169:\n",
            "Current vocab size: 424\n",
            "  Most common adjacency: '(97, 105, 108)' (count: 87)\n",
            "  Most common adjacency: 'ail' (count: 87)\n",
            "\n",
            "Updating trie...\n",
            "(97, 105, 108)\n",
            "\n",
            "Iteration 170:\n",
            "Current vocab size: 425\n",
            "  Most common adjacency: '(105, 102)' (count: 48)\n",
            "  Most common adjacency: 'if' (count: 48)\n",
            "\n",
            "Updating trie...\n",
            "(105, 102)\n",
            "\n",
            "Iteration 171:\n",
            "Current vocab size: 426\n",
            "  Most common adjacency: '(113, 117)' (count: 193)\n",
            "  Most common adjacency: 'qu' (count: 193)\n",
            "\n",
            "Updating trie...\n",
            "(113, 117)\n",
            "\n",
            "Iteration 172:\n",
            "Current vocab size: 427\n",
            "  Most common adjacency: '(32, 119, 101)' (count: 62)\n",
            "  Most common adjacency: ' we' (count: 62)\n",
            "\n",
            "Updating trie...\n",
            "(32, 119, 101)\n",
            "\n",
            "Iteration 173:\n",
            "Current vocab size: 428\n",
            "  Most common adjacency: '(112, 117, 116)' (count: 62)\n",
            "  Most common adjacency: 'put' (count: 62)\n",
            "\n",
            "Updating trie...\n",
            "(112, 117, 116)\n",
            "\n",
            "Iteration 174:\n",
            "Current vocab size: 429\n",
            "  Most common adjacency: '(68, 70)' (count: 425)\n",
            "  Most common adjacency: 'DF' (count: 425)\n",
            "\n",
            "Updating trie...\n",
            "(68, 70)\n",
            "\n",
            "Iteration 175:\n",
            "Current vocab size: 430\n",
            "  Most common adjacency: '(32, 70)' (count: 36)\n",
            "  Most common adjacency: ' F' (count: 36)\n",
            "\n",
            "Updating trie...\n",
            "(32, 70)\n",
            "\n",
            "Iteration 176:\n",
            "Current vocab size: 431\n",
            "  Most common adjacency: '(97, 105)' (count: 173)\n",
            "  Most common adjacency: 'ai' (count: 173)\n",
            "\n",
            "Updating trie...\n",
            "(97, 105)\n",
            "\n",
            "Iteration 177:\n",
            "Current vocab size: 432\n",
            "  Most common adjacency: '(105, 103, 110)' (count: 95)\n",
            "  Most common adjacency: 'ign' (count: 95)\n",
            "\n",
            "Updating trie...\n",
            "(105, 103, 110)\n",
            "\n",
            "Iteration 178:\n",
            "Current vocab size: 433\n",
            "  Most common adjacency: '(108, 111, 119)' (count: 82)\n",
            "  Most common adjacency: 'low' (count: 82)\n",
            "\n",
            "Updating trie...\n",
            "(108, 111, 119)\n",
            "\n",
            "Iteration 179:\n",
            "Current vocab size: 434\n",
            "  Most common adjacency: '(32, 82)' (count: 101)\n",
            "  Most common adjacency: ' R' (count: 101)\n",
            "\n",
            "Updating trie...\n",
            "(32, 82)\n",
            "\n",
            "Iteration 180:\n",
            "Current vocab size: 435\n",
            "  Most common adjacency: '(32, 105)' (count: 54)\n",
            "  Most common adjacency: ' i' (count: 54)\n",
            "\n",
            "Updating trie...\n",
            "(32, 105)\n",
            "\n",
            "Iteration 181:\n",
            "Current vocab size: 436\n",
            "  Most common adjacency: '(99, 101, 115, 115)' (count: 83)\n",
            "  Most common adjacency: 'cess' (count: 83)\n",
            "\n",
            "Updating trie...\n",
            "(99, 101, 115, 115)\n",
            "\n",
            "Iteration 182:\n",
            "Current vocab size: 437\n",
            "  Most common adjacency: '(110, 116)' (count: 150)\n",
            "  Most common adjacency: 'nt' (count: 150)\n",
            "\n",
            "Updating trie...\n",
            "(110, 116)\n",
            "\n",
            "Iteration 183:\n",
            "Current vocab size: 438\n",
            "  Most common adjacency: '(108, 105, 99)' (count: 77)\n",
            "  Most common adjacency: 'lic' (count: 77)\n",
            "\n",
            "Updating trie...\n",
            "(108, 105, 99)\n",
            "\n",
            "Iteration 184:\n",
            "Current vocab size: 439\n",
            "  Most common adjacency: '(101, 97, 114)' (count: 169)\n",
            "  Most common adjacency: 'ear' (count: 169)\n",
            "\n",
            "Updating trie...\n",
            "(101, 97, 114)\n",
            "\n",
            "Iteration 185:\n",
            "Current vocab size: 440\n",
            "  Most common adjacency: '(32, 119, 111, 114, 107)' (count: 92)\n",
            "  Most common adjacency: ' work' (count: 92)\n",
            "\n",
            "Updating trie...\n",
            "(32, 119, 111, 114, 107)\n",
            "\n",
            "Iteration 186:\n",
            "Current vocab size: 441\n",
            "  Most common adjacency: '(120, 120)' (count: 54)\n",
            "  Most common adjacency: 'xx' (count: 54)\n",
            "\n",
            "Updating trie...\n",
            "(120, 120)\n",
            "\n",
            "Iteration 187:\n",
            "Current vocab size: 442\n",
            "  Most common adjacency: '(105, 118, 101)' (count: 52)\n",
            "  Most common adjacency: 'ive' (count: 52)\n",
            "\n",
            "Updating trie...\n",
            "(105, 118, 101)\n",
            "\n",
            "Iteration 188:\n",
            "Current vocab size: 443\n",
            "  Most common adjacency: '(119, 97, 114)' (count: 71)\n",
            "  Most common adjacency: 'war' (count: 71)\n",
            "\n",
            "Updating trie...\n",
            "(119, 97, 114)\n",
            "\n",
            "Iteration 189:\n",
            "Current vocab size: 444\n",
            "  Most common adjacency: '(112, 116)' (count: 59)\n",
            "  Most common adjacency: 'pt' (count: 59)\n",
            "\n",
            "Updating trie...\n",
            "(112, 116)\n",
            "\n",
            "Iteration 190:\n",
            "Current vocab size: 445\n",
            "  Most common adjacency: '(32, 50, 48, 48)' (count: 258)\n",
            "  Most common adjacency: ' 200' (count: 258)\n",
            "\n",
            "Updating trie...\n",
            "(32, 50, 48, 48)\n",
            "\n",
            "Iteration 191:\n",
            "Current vocab size: 446\n",
            "  Most common adjacency: '(114, 105, 103)' (count: 122)\n",
            "  Most common adjacency: 'rig' (count: 122)\n",
            "\n",
            "Updating trie...\n",
            "(114, 105, 103)\n",
            "\n",
            "Iteration 192:\n",
            "Current vocab size: 447\n",
            "  Most common adjacency: '(105, 114)' (count: 192)\n",
            "  Most common adjacency: 'ir' (count: 192)\n",
            "\n",
            "Updating trie...\n",
            "(105, 114)\n",
            "\n",
            "Iteration 193:\n",
            "Current vocab size: 448\n",
            "  Most common adjacency: '(108, 101, 109, 101, 110, 116)' (count: 154)\n",
            "  Most common adjacency: 'lement' (count: 154)\n",
            "\n",
            "Updating trie...\n",
            "(108, 101, 109, 101, 110, 116)\n",
            "\n",
            "Iteration 194:\n",
            "Current vocab size: 449\n",
            "  Most common adjacency: '(32, 119, 105, 108, 108)' (count: 94)\n",
            "  Most common adjacency: ' will' (count: 94)\n",
            "\n",
            "Updating trie...\n",
            "(32, 119, 105, 108, 108)\n",
            "\n",
            "Iteration 195:\n",
            "Current vocab size: 450\n",
            "  Most common adjacency: '(111, 111, 116)' (count: 82)\n",
            "  Most common adjacency: 'oot' (count: 82)\n",
            "\n",
            "Updating trie...\n",
            "(111, 111, 116)\n",
            "\n",
            "Iteration 196:\n",
            "Current vocab size: 451\n",
            "  Most common adjacency: '(101, 99, 116, 105, 111, 110)' (count: 189)\n",
            "  Most common adjacency: 'ection' (count: 189)\n",
            "\n",
            "Updating trie...\n",
            "(101, 99, 116, 105, 111, 110)\n",
            "\n",
            "Iteration 197:\n",
            "Current vocab size: 452\n",
            "  Most common adjacency: '(111, 111)' (count: 75)\n",
            "  Most common adjacency: 'oo' (count: 75)\n",
            "\n",
            "Updating trie...\n",
            "(111, 111)\n",
            "\n",
            "Iteration 198:\n",
            "Current vocab size: 453\n",
            "  Most common adjacency: '(32, 76)' (count: 65)\n",
            "  Most common adjacency: ' L' (count: 65)\n",
            "\n",
            "Updating trie...\n",
            "(32, 76)\n",
            "\n",
            "Iteration 199:\n",
            "Current vocab size: 454\n",
            "  Most common adjacency: '(107, 101, 121)' (count: 130)\n",
            "  Most common adjacency: 'key' (count: 130)\n",
            "\n",
            "Updating trie...\n",
            "(107, 101, 121)\n",
            "\n",
            "Iteration 200:\n",
            "Current vocab size: 455\n",
            "  Most common adjacency: '(32, 72)' (count: 57)\n",
            "  Most common adjacency: ' H' (count: 57)\n",
            "\n",
            "Updating trie...\n",
            "(32, 72)\n",
            "\n",
            "Iteration 201:\n",
            "Current vocab size: 456\n",
            "  Most common adjacency: '(97, 116, 101)' (count: 75)\n",
            "  Most common adjacency: 'ate' (count: 75)\n",
            "\n",
            "Updating trie...\n",
            "(97, 116, 101)\n",
            "\n",
            "Iteration 202:\n",
            "Current vocab size: 457\n",
            "  Most common adjacency: '(102, 111, 114)' (count: 66)\n",
            "  Most common adjacency: 'for' (count: 66)\n",
            "\n",
            "Updating trie...\n",
            "(102, 111, 114)\n",
            "\n",
            "Iteration 203:\n",
            "Current vocab size: 458\n",
            "  Most common adjacency: '(114, 105)' (count: 40)\n",
            "  Most common adjacency: 'ri' (count: 40)\n",
            "\n",
            "Updating trie...\n",
            "(114, 105)\n",
            "\n",
            "Iteration 204:\n",
            "Current vocab size: 459\n",
            "  Most common adjacency: '(32, 78)' (count: 58)\n",
            "  Most common adjacency: ' N' (count: 58)\n",
            "\n",
            "Updating trie...\n",
            "(32, 78)\n",
            "\n",
            "Iteration 205:\n",
            "Current vocab size: 460\n",
            "  Most common adjacency: '(114, 101, 115, 115)' (count: 71)\n",
            "  Most common adjacency: 'ress' (count: 71)\n",
            "\n",
            "Updating trie...\n",
            "(114, 101, 115, 115)\n",
            "\n",
            "Iteration 206:\n",
            "Current vocab size: 461\n",
            "  Most common adjacency: '(32, 97, 115)' (count: 58)\n",
            "  Most common adjacency: ' as' (count: 58)\n",
            "\n",
            "Updating trie...\n",
            "(32, 97, 115)\n",
            "\n",
            "Iteration 207:\n",
            "Current vocab size: 462\n",
            "  Most common adjacency: '(117, 109)' (count: 60)\n",
            "  Most common adjacency: 'um' (count: 60)\n",
            "\n",
            "Updating trie...\n",
            "(117, 109)\n",
            "\n",
            "Iteration 208:\n",
            "Current vocab size: 463\n",
            "  Most common adjacency: '(102, 116)' (count: 60)\n",
            "  Most common adjacency: 'ft' (count: 60)\n",
            "\n",
            "Updating trie...\n",
            "(102, 116)\n",
            "\n",
            "Iteration 209:\n",
            "Current vocab size: 464\n",
            "  Most common adjacency: '(97, 110, 116)' (count: 65)\n",
            "  Most common adjacency: 'ant' (count: 65)\n",
            "\n",
            "Updating trie...\n",
            "(97, 110, 116)\n",
            "\n",
            "Iteration 210:\n",
            "Current vocab size: 465\n",
            "  Most common adjacency: '(32, 115, 101, 114)' (count: 65)\n",
            "  Most common adjacency: ' ser' (count: 65)\n",
            "\n",
            "Updating trie...\n",
            "(32, 115, 101, 114)\n",
            "\n",
            "Iteration 211:\n",
            "Current vocab size: 466\n",
            "  Most common adjacency: '(10, 124)' (count: 500)\n",
            "  Most common adjacency: '\n",
            "|' (count: 500)\n",
            "\n",
            "Updating trie...\n",
            "(10, 124)\n",
            "\n",
            "Iteration 212:\n",
            "Current vocab size: 467\n",
            "  Most common adjacency: '(111, 116, 111)' (count: 84)\n",
            "  Most common adjacency: 'oto' (count: 84)\n",
            "\n",
            "Updating trie...\n",
            "(111, 116, 111)\n",
            "\n",
            "Iteration 213:\n",
            "Current vocab size: 468\n",
            "  Most common adjacency: '(32, 34)' (count: 81)\n",
            "  Most common adjacency: ' \"' (count: 81)\n",
            "\n",
            "Updating trie...\n",
            "(32, 34)\n",
            "\n",
            "Iteration 214:\n",
            "Current vocab size: 469\n",
            "  Most common adjacency: '(32, 97, 114, 101)' (count: 37)\n",
            "  Most common adjacency: ' are' (count: 37)\n",
            "\n",
            "Updating trie...\n",
            "(32, 97, 114, 101)\n",
            "\n",
            "Iteration 215:\n",
            "Current vocab size: 470\n",
            "  Most common adjacency: '(117, 112)' (count: 53)\n",
            "  Most common adjacency: 'up' (count: 53)\n",
            "\n",
            "Updating trie...\n",
            "(117, 112)\n",
            "\n",
            "Iteration 216:\n",
            "Current vocab size: 471\n",
            "  Most common adjacency: '(101, 114, 109)' (count: 110)\n",
            "  Most common adjacency: 'erm' (count: 110)\n",
            "\n",
            "Updating trie...\n",
            "(101, 114, 109)\n",
            "\n",
            "Iteration 217:\n",
            "Current vocab size: 472\n",
            "  Most common adjacency: '(105, 112)' (count: 73)\n",
            "  Most common adjacency: 'ip' (count: 73)\n",
            "\n",
            "Updating trie...\n",
            "(105, 112)\n",
            "\n",
            "Iteration 218:\n",
            "Current vocab size: 473\n",
            "  Most common adjacency: '(115, 44)' (count: 46)\n",
            "  Most common adjacency: 's,' (count: 46)\n",
            "\n",
            "Updating trie...\n",
            "(115, 44)\n",
            "\n",
            "Iteration 219:\n",
            "Current vocab size: 474\n",
            "  Most common adjacency: '(196, 129)' (count: 150)\n",
            "  Most common adjacency: 'Ä' (count: 150)\n",
            "\n",
            "Updating trie...\n",
            "(196, 129)\n",
            "\n",
            "Iteration 220:\n",
            "Current vocab size: 475\n",
            "  Most common adjacency: '(32, 116, 104, 105, 115)' (count: 41)\n",
            "  Most common adjacency: ' this' (count: 41)\n",
            "\n",
            "Updating trie...\n",
            "(32, 116, 104, 105, 115)\n",
            "\n",
            "Iteration 221:\n",
            "Current vocab size: 476\n",
            "  Most common adjacency: '(102, 111, 114, 109)' (count: 114)\n",
            "  Most common adjacency: 'form' (count: 114)\n",
            "\n",
            "Updating trie...\n",
            "(102, 111, 114, 109)\n",
            "\n",
            "Iteration 222:\n",
            "Current vocab size: 477\n",
            "  Most common adjacency: '(97, 116, 97)' (count: 154)\n",
            "  Most common adjacency: 'ata' (count: 154)\n",
            "\n",
            "Updating trie...\n",
            "(97, 116, 97)\n",
            "\n",
            "Iteration 223:\n",
            "Current vocab size: 478\n",
            "  Most common adjacency: '(32, 61)' (count: 84)\n",
            "  Most common adjacency: ' =' (count: 84)\n",
            "\n",
            "Updating trie...\n",
            "(32, 61)\n",
            "\n",
            "Iteration 224:\n",
            "Current vocab size: 479\n",
            "  Most common adjacency: '(115, 101)' (count: 41)\n",
            "  Most common adjacency: 'se' (count: 41)\n",
            "\n",
            "Updating trie...\n",
            "(115, 101)\n",
            "\n",
            "Iteration 225:\n",
            "Current vocab size: 480\n",
            "  Most common adjacency: '(32, 119, 104)' (count: 62)\n",
            "  Most common adjacency: ' wh' (count: 62)\n",
            "\n",
            "Updating trie...\n",
            "(32, 119, 104)\n",
            "\n",
            "Iteration 226:\n",
            "Current vocab size: 481\n",
            "  Most common adjacency: '(98, 111)' (count: 72)\n",
            "  Most common adjacency: 'bo' (count: 72)\n",
            "\n",
            "Updating trie...\n",
            "(98, 111)\n",
            "\n",
            "Iteration 227:\n",
            "Current vocab size: 482\n",
            "  Most common adjacency: '(97, 100, 105)' (count: 75)\n",
            "  Most common adjacency: 'adi' (count: 75)\n",
            "\n",
            "Updating trie...\n",
            "(97, 100, 105)\n",
            "\n",
            "Iteration 228:\n",
            "Current vocab size: 483\n",
            "  Most common adjacency: '(117, 115, 116)' (count: 36)\n",
            "  Most common adjacency: 'ust' (count: 36)\n",
            "\n",
            "Updating trie...\n",
            "(117, 115, 116)\n",
            "\n",
            "Iteration 229:\n",
            "Current vocab size: 484\n",
            "  Most common adjacency: '(224, 184)' (count: 137)\n",
            "  Most common adjacency: '' (count: 137)\n",
            "\n",
            "Updating trie...\n",
            "(224, 184)\n",
            "\n",
            "Iteration 230:\n",
            "Current vocab size: 485\n",
            "  Most common adjacency: '(97, 108, 108)' (count: 53)\n",
            "  Most common adjacency: 'all' (count: 53)\n",
            "\n",
            "Updating trie...\n",
            "(97, 108, 108)\n",
            "\n",
            "Iteration 231:\n",
            "Current vocab size: 486\n",
            "  Most common adjacency: '(32, 100, 101)' (count: 106)\n",
            "  Most common adjacency: ' de' (count: 106)\n",
            "\n",
            "Updating trie...\n",
            "(32, 100, 101)\n",
            "\n",
            "Iteration 232:\n",
            "Current vocab size: 487\n",
            "  Most common adjacency: '(32, 97, 99)' (count: 47)\n",
            "  Most common adjacency: ' ac' (count: 47)\n",
            "\n",
            "Updating trie...\n",
            "(32, 97, 99)\n",
            "\n",
            "Iteration 233:\n",
            "Current vocab size: 488\n",
            "  Most common adjacency: '(32, 45, 62)' (count: 104)\n",
            "  Most common adjacency: ' ->' (count: 104)\n",
            "\n",
            "Updating trie...\n",
            "(32, 45, 62)\n",
            "\n",
            "Iteration 234:\n",
            "Current vocab size: 489\n",
            "  Most common adjacency: '(105, 109, 101, 114)' (count: 70)\n",
            "  Most common adjacency: 'imer' (count: 70)\n",
            "\n",
            "Updating trie...\n",
            "(105, 109, 101, 114)\n",
            "\n",
            "Iteration 235:\n",
            "Current vocab size: 490\n",
            "  Most common adjacency: '(116, 104)' (count: 92)\n",
            "  Most common adjacency: 'th' (count: 92)\n",
            "\n",
            "Updating trie...\n",
            "(116, 104)\n",
            "\n",
            "Iteration 236:\n",
            "Current vocab size: 491\n",
            "  Most common adjacency: '(111, 112)' (count: 48)\n",
            "  Most common adjacency: 'op' (count: 48)\n",
            "\n",
            "Updating trie...\n",
            "(111, 112)\n",
            "\n",
            "Iteration 237:\n",
            "Current vocab size: 492\n",
            "  Most common adjacency: '(105, 101, 115)' (count: 55)\n",
            "  Most common adjacency: 'ies' (count: 55)\n",
            "\n",
            "Updating trie...\n",
            "(105, 101, 115)\n",
            "\n",
            "Iteration 238:\n",
            "Current vocab size: 493\n",
            "  Most common adjacency: '(32, 119, 97, 115)' (count: 80)\n",
            "  Most common adjacency: ' was' (count: 80)\n",
            "\n",
            "Updating trie...\n",
            "(32, 119, 97, 115)\n",
            "\n",
            "Iteration 239:\n",
            "Current vocab size: 494\n",
            "  Most common adjacency: '(32, 74)' (count: 289)\n",
            "  Most common adjacency: ' J' (count: 289)\n",
            "\n",
            "Updating trie...\n",
            "(32, 74)\n",
            "\n",
            "Iteration 240:\n",
            "Current vocab size: 495\n",
            "  Most common adjacency: '(112, 111, 114)' (count: 233)\n",
            "  Most common adjacency: 'por' (count: 233)\n",
            "\n",
            "Updating trie...\n",
            "(112, 111, 114)\n",
            "\n",
            "Iteration 241:\n",
            "Current vocab size: 496\n",
            "  Most common adjacency: '(117, 100)' (count: 57)\n",
            "  Most common adjacency: 'ud' (count: 57)\n",
            "\n",
            "Updating trie...\n",
            "(117, 100)\n",
            "\n",
            "Iteration 242:\n",
            "Current vocab size: 497\n",
            "  Most common adjacency: '(32, 112, 108)' (count: 48)\n",
            "  Most common adjacency: ' pl' (count: 48)\n",
            "\n",
            "Updating trie...\n",
            "(32, 112, 108)\n",
            "\n",
            "Iteration 243:\n",
            "Current vocab size: 498\n",
            "  Most common adjacency: '(32, 100, 111)' (count: 36)\n",
            "  Most common adjacency: ' do' (count: 36)\n",
            "\n",
            "Updating trie...\n",
            "(32, 100, 111)\n",
            "\n",
            "Iteration 244:\n",
            "Current vocab size: 499\n",
            "  Most common adjacency: '(97, 112)' (count: 219)\n",
            "  Most common adjacency: 'ap' (count: 219)\n",
            "\n",
            "Updating trie...\n",
            "(97, 112)\n",
            "\n",
            "Iteration 245:\n",
            "Current vocab size: 500\n",
            "  Most common adjacency: '(117, 99, 116)' (count: 49)\n",
            "  Most common adjacency: 'uct' (count: 49)\n",
            "\n",
            "Updating trie...\n",
            "(117, 99, 116)\n",
            "\n",
            "Iteration 246:\n",
            "Current vocab size: 501\n",
            "  Most common adjacency: '(114, 111, 109)' (count: 117)\n",
            "  Most common adjacency: 'rom' (count: 117)\n",
            "\n",
            "Updating trie...\n",
            "(114, 111, 109)\n",
            "\n",
            "Iteration 247:\n",
            "Current vocab size: 502\n",
            "  Most common adjacency: '(97, 114, 100)' (count: 102)\n",
            "  Most common adjacency: 'ard' (count: 102)\n",
            "\n",
            "Updating trie...\n",
            "(97, 114, 100)\n",
            "\n",
            "Iteration 248:\n",
            "Current vocab size: 503\n",
            "  Most common adjacency: '(32, 69)' (count: 90)\n",
            "  Most common adjacency: ' E' (count: 90)\n",
            "\n",
            "Updating trie...\n",
            "(32, 69)\n",
            "\n",
            "Iteration 249:\n",
            "Current vocab size: 504\n",
            "  Most common adjacency: '(48, 49)' (count: 59)\n",
            "  Most common adjacency: '01' (count: 59)\n",
            "\n",
            "Updating trie...\n",
            "(48, 49)\n",
            "\n",
            "Iteration 250:\n",
            "Current vocab size: 505\n",
            "  Most common adjacency: '(105, 115, 104)' (count: 49)\n",
            "  Most common adjacency: 'ish' (count: 49)\n",
            "\n",
            "Updating trie...\n",
            "(105, 115, 104)\n",
            "\n",
            "Iteration 251:\n",
            "Current vocab size: 506\n",
            "  Most common adjacency: '(32, 109, 111, 100)' (count: 33)\n",
            "  Most common adjacency: ' mod' (count: 33)\n",
            "\n",
            "Updating trie...\n",
            "(32, 109, 111, 100)\n",
            "\n",
            "Iteration 252:\n",
            "Current vocab size: 507\n",
            "  Most common adjacency: '(116, 97, 108)' (count: 43)\n",
            "  Most common adjacency: 'tal' (count: 43)\n",
            "\n",
            "Updating trie...\n",
            "(116, 97, 108)\n",
            "\n",
            "Iteration 253:\n",
            "Current vocab size: 508\n",
            "  Most common adjacency: '(101, 119)' (count: 88)\n",
            "  Most common adjacency: 'ew' (count: 88)\n",
            "\n",
            "Updating trie...\n",
            "(101, 119)\n",
            "\n",
            "Iteration 254:\n",
            "Current vocab size: 509\n",
            "  Most common adjacency: '(41, 44)' (count: 95)\n",
            "  Most common adjacency: '),' (count: 95)\n",
            "\n",
            "Updating trie...\n",
            "(41, 44)\n",
            "\n",
            "Iteration 255:\n",
            "Current vocab size: 510\n",
            "  Most common adjacency: '(81, 76)' (count: 57)\n",
            "  Most common adjacency: 'QL' (count: 57)\n",
            "\n",
            "Updating trie...\n",
            "(81, 76)\n",
            "\n",
            "Iteration 256:\n",
            "Current vocab size: 511\n",
            "  Most common adjacency: '(111, 100, 101)' (count: 110)\n",
            "  Most common adjacency: 'ode' (count: 110)\n",
            "\n",
            "Updating trie...\n",
            "(111, 100, 101)\n",
            "\n",
            "Iteration 257:\n",
            "Current vocab size: 512\n",
            "  Most common adjacency: '(101, 118)' (count: 47)\n",
            "  Most common adjacency: 'ev' (count: 47)\n",
            "\n",
            "Updating trie...\n",
            "(101, 118)\n",
            "\n",
            "Iteration 258:\n",
            "Current vocab size: 513\n",
            "  Most common adjacency: '(101, 46)' (count: 50)\n",
            "  Most common adjacency: 'e.' (count: 50)\n",
            "\n",
            "Updating trie...\n",
            "(101, 46)\n",
            "\n",
            "Iteration 259:\n",
            "Current vocab size: 514\n",
            "  Most common adjacency: '(97, 121, 109, 101, 110, 116)' (count: 204)\n",
            "  Most common adjacency: 'ayment' (count: 204)\n",
            "\n",
            "Updating trie...\n",
            "(97, 121, 109, 101, 110, 116)\n",
            "\n",
            "Iteration 260:\n",
            "Current vocab size: 515\n",
            "  Most common adjacency: '(117, 99, 116, 105, 111, 110)' (count: 268)\n",
            "  Most common adjacency: 'uction' (count: 268)\n",
            "\n",
            "Updating trie...\n",
            "(117, 99, 116, 105, 111, 110)\n",
            "\n",
            "Iteration 261:\n",
            "Current vocab size: 516\n",
            "  Most common adjacency: '(99, 108)' (count: 81)\n",
            "  Most common adjacency: 'cl' (count: 81)\n",
            "\n",
            "Updating trie...\n",
            "(99, 108)\n",
            "\n",
            "Iteration 262:\n",
            "Current vocab size: 517\n",
            "  Most common adjacency: '(101, 97, 114, 99, 104)' (count: 173)\n",
            "  Most common adjacency: 'earch' (count: 173)\n",
            "\n",
            "Updating trie...\n",
            "(101, 97, 114, 99, 104)\n",
            "\n",
            "Iteration 263:\n",
            "Current vocab size: 518\n",
            "  Most common adjacency: '(111, 115, 116)' (count: 71)\n",
            "  Most common adjacency: 'ost' (count: 71)\n",
            "\n",
            "Updating trie...\n",
            "(111, 115, 116)\n",
            "\n",
            "Iteration 264:\n",
            "Current vocab size: 519\n",
            "  Most common adjacency: '(105, 107)' (count: 87)\n",
            "  Most common adjacency: 'ik' (count: 87)\n",
            "\n",
            "Updating trie...\n",
            "(105, 107)\n",
            "\n",
            "Iteration 265:\n",
            "Current vocab size: 520\n",
            "  Most common adjacency: '(39, 115)' (count: 54)\n",
            "  Most common adjacency: ''s' (count: 54)\n",
            "\n",
            "Updating trie...\n",
            "(39, 115)\n",
            "\n",
            "Iteration 266:\n",
            "Current vocab size: 521\n",
            "  Most common adjacency: '(110, 116, 101, 108)' (count: 675)\n",
            "  Most common adjacency: 'ntel' (count: 675)\n",
            "\n",
            "Updating trie...\n",
            "(110, 116, 101, 108)\n",
            "\n",
            "Iteration 267:\n",
            "Current vocab size: 522\n",
            "  Most common adjacency: '(101, 115, 115)' (count: 92)\n",
            "  Most common adjacency: 'ess' (count: 92)\n",
            "\n",
            "Updating trie...\n",
            "(101, 115, 115)\n",
            "\n",
            "Iteration 268:\n",
            "Current vocab size: 523\n",
            "  Most common adjacency: '(97, 118, 101)' (count: 39)\n",
            "  Most common adjacency: 'ave' (count: 39)\n",
            "\n",
            "Updating trie...\n",
            "(97, 118, 101)\n",
            "\n",
            "Iteration 269:\n",
            "Current vocab size: 524\n",
            "  Most common adjacency: '(82, 73)' (count: 204)\n",
            "  Most common adjacency: 'RI' (count: 204)\n",
            "\n",
            "Updating trie...\n",
            "(82, 73)\n",
            "\n",
            "Iteration 270:\n",
            "Current vocab size: 525\n",
            "  Most common adjacency: '(208, 176)' (count: 75)\n",
            "  Most common adjacency: 'Ð°' (count: 75)\n",
            "\n",
            "Updating trie...\n",
            "(208, 176)\n",
            "\n",
            "Iteration 271:\n",
            "Current vocab size: 526\n",
            "  Most common adjacency: '(105, 122)' (count: 28)\n",
            "  Most common adjacency: 'iz' (count: 28)\n",
            "\n",
            "Updating trie...\n",
            "(105, 122)\n",
            "\n",
            "Iteration 272:\n",
            "Current vocab size: 527\n",
            "  Most common adjacency: '(32, 50, 48, 49)' (count: 67)\n",
            "  Most common adjacency: ' 201' (count: 67)\n",
            "\n",
            "Updating trie...\n",
            "(32, 50, 48, 49)\n",
            "\n",
            "Iteration 273:\n",
            "Current vocab size: 528\n",
            "  Most common adjacency: '(32, 71)' (count: 101)\n",
            "  Most common adjacency: ' G' (count: 101)\n",
            "\n",
            "Updating trie...\n",
            "(32, 71)\n",
            "\n",
            "Iteration 274:\n",
            "Current vocab size: 529\n",
            "  Most common adjacency: '(83, 76)' (count: 126)\n",
            "  Most common adjacency: 'SL' (count: 126)\n",
            "\n",
            "Updating trie...\n",
            "(83, 76)\n",
            "\n",
            "Iteration 275:\n",
            "Current vocab size: 530\n",
            "  Most common adjacency: '(110, 103)' (count: 57)\n",
            "  Most common adjacency: 'ng' (count: 57)\n",
            "\n",
            "Updating trie...\n",
            "(110, 103)\n",
            "\n",
            "Iteration 276:\n",
            "Current vocab size: 531\n",
            "  Most common adjacency: '(32, 84, 104, 101)' (count: 63)\n",
            "  Most common adjacency: ' The' (count: 63)\n",
            "\n",
            "Updating trie...\n",
            "(32, 84, 104, 101)\n",
            "\n",
            "Iteration 277:\n",
            "Current vocab size: 532\n",
            "  Most common adjacency: '(97, 116, 116, 101, 114)' (count: 40)\n",
            "  Most common adjacency: 'atter' (count: 40)\n",
            "\n",
            "Updating trie...\n",
            "(97, 116, 116, 101, 114)\n",
            "\n",
            "Iteration 278:\n",
            "Current vocab size: 533\n",
            "  Most common adjacency: '(115, 116, 97, 108, 108)' (count: 32)\n",
            "  Most common adjacency: 'stall' (count: 32)\n",
            "\n",
            "Updating trie...\n",
            "(115, 116, 97, 108, 108)\n",
            "\n",
            "Iteration 279:\n",
            "Current vocab size: 534\n",
            "  Most common adjacency: '(97, 105, 114)' (count: 74)\n",
            "  Most common adjacency: 'air' (count: 74)\n",
            "\n",
            "Updating trie...\n",
            "(97, 105, 114)\n",
            "\n",
            "Iteration 280:\n",
            "Current vocab size: 535\n",
            "  Most common adjacency: '(32, 98, 121)' (count: 59)\n",
            "  Most common adjacency: ' by' (count: 59)\n",
            "\n",
            "Updating trie...\n",
            "(32, 98, 121)\n",
            "\n",
            "Iteration 281:\n",
            "Current vocab size: 536\n",
            "  Most common adjacency: '(39, 116)' (count: 47)\n",
            "  Most common adjacency: ''t' (count: 47)\n",
            "\n",
            "Updating trie...\n",
            "(39, 116)\n",
            "\n",
            "Iteration 282:\n",
            "Current vocab size: 537\n",
            "  Most common adjacency: '(97, 99, 107)' (count: 108)\n",
            "  Most common adjacency: 'ack' (count: 108)\n",
            "\n",
            "Updating trie...\n",
            "(97, 99, 107)\n",
            "\n",
            "Iteration 283:\n",
            "Current vocab size: 538\n",
            "  Most common adjacency: '(111, 117, 108, 100)' (count: 143)\n",
            "  Most common adjacency: 'ould' (count: 143)\n",
            "\n",
            "Updating trie...\n",
            "(111, 117, 108, 100)\n",
            "\n",
            "Iteration 284:\n",
            "Current vocab size: 539\n",
            "  Most common adjacency: '(114, 97, 116, 105, 111, 110)' (count: 80)\n",
            "  Most common adjacency: 'ration' (count: 80)\n",
            "\n",
            "Updating trie...\n",
            "(114, 97, 116, 105, 111, 110)\n",
            "\n",
            "Iteration 285:\n",
            "Current vocab size: 540\n",
            "  Most common adjacency: '(97, 109, 101)' (count: 49)\n",
            "  Most common adjacency: 'ame' (count: 49)\n",
            "\n",
            "Updating trie...\n",
            "(97, 109, 101)\n",
            "\n",
            "Iteration 286:\n",
            "Current vocab size: 541\n",
            "  Most common adjacency: '(111, 110, 105, 107)' (count: 67)\n",
            "  Most common adjacency: 'onik' (count: 67)\n",
            "\n",
            "Updating trie...\n",
            "(111, 110, 105, 107)\n",
            "\n",
            "Iteration 287:\n",
            "Current vocab size: 542\n",
            "  Most common adjacency: '(110, 101, 108)' (count: 283)\n",
            "  Most common adjacency: 'nel' (count: 283)\n",
            "\n",
            "Updating trie...\n",
            "(110, 101, 108)\n",
            "\n",
            "Iteration 288:\n",
            "Current vocab size: 543\n",
            "  Most common adjacency: '(32, 112, 111, 105, 110)' (count: 96)\n",
            "  Most common adjacency: ' poin' (count: 96)\n",
            "\n",
            "Updating trie...\n",
            "(32, 112, 111, 105, 110)\n",
            "\n",
            "Iteration 289:\n",
            "Current vocab size: 544\n",
            "  Most common adjacency: '(97, 98, 108, 101)' (count: 53)\n",
            "  Most common adjacency: 'able' (count: 53)\n",
            "\n",
            "Updating trie...\n",
            "(97, 98, 108, 101)\n",
            "\n",
            "Iteration 290:\n",
            "Current vocab size: 545\n",
            "  Most common adjacency: '(32, 80, 68, 70)' (count: 80)\n",
            "  Most common adjacency: ' PDF' (count: 80)\n",
            "\n",
            "Updating trie...\n",
            "(32, 80, 68, 70)\n",
            "\n",
            "Iteration 291:\n",
            "Current vocab size: 546\n",
            "  Most common adjacency: '(102, 111, 114, 109, 97, 116, 105, 111, 110)' (count: 79)\n",
            "  Most common adjacency: 'formation' (count: 79)\n",
            "\n",
            "Updating trie...\n",
            "(102, 111, 114, 109, 97, 116, 105, 111, 110)\n",
            "\n",
            "Iteration 292:\n",
            "Current vocab size: 547\n",
            "  Most common adjacency: '(111, 99)' (count: 32)\n",
            "  Most common adjacency: 'oc' (count: 32)\n",
            "\n",
            "Updating trie...\n",
            "(111, 99)\n",
            "\n",
            "Iteration 293:\n",
            "Current vocab size: 548\n",
            "  Most common adjacency: '(105, 108, 101)' (count: 25)\n",
            "  Most common adjacency: 'ile' (count: 25)\n",
            "\n",
            "Updating trie...\n",
            "(105, 108, 101)\n",
            "\n",
            "Iteration 294:\n",
            "Current vocab size: 549\n",
            "  Most common adjacency: '(105, 100, 101)' (count: 47)\n",
            "  Most common adjacency: 'ide' (count: 47)\n",
            "\n",
            "Updating trie...\n",
            "(105, 100, 101)\n",
            "\n",
            "Iteration 295:\n",
            "Current vocab size: 550\n",
            "  Most common adjacency: '(32, 101, 109)' (count: 42)\n",
            "  Most common adjacency: ' em' (count: 42)\n",
            "\n",
            "Updating trie...\n",
            "(32, 101, 109)\n",
            "\n",
            "Iteration 296:\n",
            "Current vocab size: 551\n",
            "  Most common adjacency: '(48, 124, 124)' (count: 135)\n",
            "  Most common adjacency: '0||' (count: 135)\n",
            "\n",
            "Updating trie...\n",
            "(48, 124, 124)\n",
            "\n",
            "Iteration 297:\n",
            "Current vocab size: 552\n",
            "  Most common adjacency: '(117, 103)' (count: 285)\n",
            "  Most common adjacency: 'ug' (count: 285)\n",
            "\n",
            "Updating trie...\n",
            "(117, 103)\n",
            "\n",
            "Iteration 298:\n",
            "Current vocab size: 553\n",
            "  Most common adjacency: '(32, 98, 105, 116)' (count: 90)\n",
            "  Most common adjacency: ' bit' (count: 90)\n",
            "\n",
            "Updating trie...\n",
            "(32, 98, 105, 116)\n",
            "\n",
            "Iteration 299:\n",
            "Current vocab size: 554\n",
            "  Most common adjacency: '(114, 121)' (count: 41)\n",
            "  Most common adjacency: 'ry' (count: 41)\n",
            "\n",
            "Updating trie...\n",
            "(114, 121)\n",
            "\n",
            "Iteration 300:\n",
            "Current vocab size: 555\n",
            "  Most common adjacency: '(112, 97, 114)' (count: 78)\n",
            "  Most common adjacency: 'par' (count: 78)\n",
            "\n",
            "Updating trie...\n",
            "(112, 97, 114)\n",
            "\n",
            "Iteration 301:\n",
            "Current vocab size: 556\n",
            "  Most common adjacency: '(32, 226, 128, 147)' (count: 206)\n",
            "  Most common adjacency: ' â€“' (count: 206)\n",
            "\n",
            "Updating trie...\n",
            "(32, 226, 128, 147)\n",
            "\n",
            "Iteration 302:\n",
            "Current vocab size: 557\n",
            "  Most common adjacency: '(82, 80)' (count: 213)\n",
            "  Most common adjacency: 'RP' (count: 213)\n",
            "\n",
            "Updating trie...\n",
            "(82, 80)\n",
            "\n",
            "Iteration 303:\n",
            "Current vocab size: 558\n",
            "  Most common adjacency: '(32, 75)' (count: 120)\n",
            "  Most common adjacency: ' K' (count: 120)\n",
            "\n",
            "Updating trie...\n",
            "(32, 75)\n",
            "\n",
            "Iteration 304:\n",
            "Current vocab size: 559\n",
            "  Most common adjacency: '(101, 120, 97, 115)' (count: 678)\n",
            "  Most common adjacency: 'exas' (count: 678)\n",
            "\n",
            "Updating trie...\n",
            "(101, 120, 97, 115)\n",
            "\n",
            "Iteration 305:\n",
            "Current vocab size: 560\n",
            "  Most common adjacency: '(121, 115, 116)' (count: 33)\n",
            "  Most common adjacency: 'yst' (count: 33)\n",
            "\n",
            "Updating trie...\n",
            "(121, 115, 116)\n",
            "\n",
            "Iteration 306:\n",
            "Current vocab size: 561\n",
            "  Most common adjacency: '(32, 97, 112, 112)' (count: 48)\n",
            "  Most common adjacency: ' app' (count: 48)\n",
            "\n",
            "Updating trie...\n",
            "(32, 97, 112, 112)\n",
            "\n",
            "Iteration 307:\n",
            "Current vocab size: 562\n",
            "  Most common adjacency: '(100, 105, 110, 103)' (count: 109)\n",
            "  Most common adjacency: 'ding' (count: 109)\n",
            "\n",
            "Updating trie...\n",
            "(100, 105, 110, 103)\n",
            "\n",
            "Iteration 308:\n",
            "Current vocab size: 563\n",
            "  Most common adjacency: '(97, 115, 116)' (count: 150)\n",
            "  Most common adjacency: 'ast' (count: 150)\n",
            "\n",
            "Updating trie...\n",
            "(97, 115, 116)\n",
            "\n",
            "Iteration 309:\n",
            "Current vocab size: 564\n",
            "  Most common adjacency: '(105, 116, 121)' (count: 85)\n",
            "  Most common adjacency: 'ity' (count: 85)\n",
            "\n",
            "Updating trie...\n",
            "(105, 116, 121)\n",
            "\n",
            "Iteration 310:\n",
            "Current vocab size: 565\n",
            "  Most common adjacency: '(97, 108, 105, 108, 101)' (count: 141)\n",
            "  Most common adjacency: 'alile' (count: 141)\n",
            "\n",
            "Updating trie...\n",
            "(97, 108, 105, 108, 101)\n",
            "\n",
            "Iteration 311:\n",
            "Current vocab size: 566\n",
            "  Most common adjacency: '(101, 108, 108)' (count: 72)\n",
            "  Most common adjacency: 'ell' (count: 72)\n",
            "\n",
            "Updating trie...\n",
            "(101, 108, 108)\n",
            "\n",
            "Iteration 312:\n",
            "Current vocab size: 567\n",
            "  Most common adjacency: '(124, 10, 124)' (count: 358)\n",
            "  Most common adjacency: '|\n",
            "|' (count: 358)\n",
            "\n",
            "Updating trie...\n",
            "(124, 10, 124)\n",
            "\n",
            "Iteration 313:\n",
            "Current vocab size: 568\n",
            "  Most common adjacency: '(116, 105, 99)' (count: 221)\n",
            "  Most common adjacency: 'tic' (count: 221)\n",
            "\n",
            "Updating trie...\n",
            "(116, 105, 99)\n",
            "\n",
            "Iteration 314:\n",
            "Current vocab size: 569\n",
            "  Most common adjacency: '(32, 100, 97, 116, 97)' (count: 39)\n",
            "  Most common adjacency: ' data' (count: 39)\n",
            "\n",
            "Updating trie...\n",
            "(32, 100, 97, 116, 97)\n",
            "\n",
            "Iteration 315:\n",
            "Current vocab size: 570\n",
            "  Most common adjacency: '(95, 95, 95, 95, 95, 95, 95, 95)' (count: 306)\n",
            "  Most common adjacency: '________' (count: 306)\n",
            "\n",
            "Updating trie...\n",
            "(95, 95, 95, 95, 95, 95, 95, 95)\n",
            "\n",
            "Iteration 316:\n",
            "Current vocab size: 571\n",
            "  Most common adjacency: '(108, 111, 97, 100)' (count: 58)\n",
            "  Most common adjacency: 'load' (count: 58)\n",
            "\n",
            "Updating trie...\n",
            "(108, 111, 97, 100)\n",
            "\n",
            "Iteration 317:\n",
            "Current vocab size: 572\n",
            "  Most common adjacency: '(97, 116, 99, 104)' (count: 48)\n",
            "  Most common adjacency: 'atch' (count: 48)\n",
            "\n",
            "Updating trie...\n",
            "(97, 116, 99, 104)\n",
            "\n",
            "Iteration 318:\n",
            "Current vocab size: 573\n",
            "  Most common adjacency: '(97, 115, 101)' (count: 38)\n",
            "  Most common adjacency: 'ase' (count: 38)\n",
            "\n",
            "Updating trie...\n",
            "(97, 115, 101)\n",
            "\n",
            "Iteration 319:\n",
            "Current vocab size: 574\n",
            "  Most common adjacency: '(32, 86)' (count: 51)\n",
            "  Most common adjacency: ' V' (count: 51)\n",
            "\n",
            "Updating trie...\n",
            "(32, 86)\n",
            "\n",
            "Iteration 320:\n",
            "Current vocab size: 575\n",
            "  Most common adjacency: '(114, 117, 115, 116)' (count: 94)\n",
            "  Most common adjacency: 'rust' (count: 94)\n",
            "\n",
            "Updating trie...\n",
            "(114, 117, 115, 116)\n",
            "\n",
            "Iteration 321:\n",
            "Current vocab size: 576\n",
            "  Most common adjacency: '(32, 97, 110, 121)' (count: 300)\n",
            "  Most common adjacency: ' any' (count: 300)\n",
            "\n",
            "Updating trie...\n",
            "(32, 97, 110, 121)\n",
            "\n",
            "Iteration 322:\n",
            "Current vocab size: 577\n",
            "  Most common adjacency: '(100, 101, 114)' (count: 60)\n",
            "  Most common adjacency: 'der' (count: 60)\n",
            "\n",
            "Updating trie...\n",
            "(100, 101, 114)\n",
            "\n",
            "Iteration 323:\n",
            "Current vocab size: 578\n",
            "  Most common adjacency: '(103, 114, 97, 109)' (count: 45)\n",
            "  Most common adjacency: 'gram' (count: 45)\n",
            "\n",
            "Updating trie...\n",
            "(103, 114, 97, 109)\n",
            "\n",
            "Iteration 324:\n",
            "Current vocab size: 579\n",
            "  Most common adjacency: '(104, 116)' (count: 115)\n",
            "  Most common adjacency: 'ht' (count: 115)\n",
            "\n",
            "Updating trie...\n",
            "(104, 116)\n",
            "\n",
            "Iteration 325:\n",
            "Current vocab size: 580\n",
            "  Most common adjacency: '(97, 102)' (count: 128)\n",
            "  Most common adjacency: 'af' (count: 128)\n",
            "\n",
            "Updating trie...\n",
            "(97, 102)\n",
            "\n",
            "Iteration 326:\n",
            "Current vocab size: 581\n",
            "  Most common adjacency: '(117, 115, 105, 110, 101)' (count: 33)\n",
            "  Most common adjacency: 'usine' (count: 33)\n",
            "\n",
            "Updating trie...\n",
            "(117, 115, 105, 110, 101)\n",
            "\n",
            "Iteration 327:\n",
            "Current vocab size: 582\n",
            "  Most common adjacency: '(101, 120, 101)' (count: 58)\n",
            "  Most common adjacency: 'exe' (count: 58)\n",
            "\n",
            "Updating trie...\n",
            "(101, 120, 101)\n",
            "\n",
            "Iteration 328:\n",
            "Current vocab size: 583\n",
            "  Most common adjacency: '(97, 110, 103)' (count: 35)\n",
            "  Most common adjacency: 'ang' (count: 35)\n",
            "\n",
            "Updating trie...\n",
            "(97, 110, 103)\n",
            "\n",
            "Iteration 329:\n",
            "Current vocab size: 584\n",
            "  Most common adjacency: '(108, 105, 99, 107)' (count: 26)\n",
            "  Most common adjacency: 'lick' (count: 26)\n",
            "\n",
            "Updating trie...\n",
            "(108, 105, 99, 107)\n",
            "\n",
            "Iteration 330:\n",
            "Current vocab size: 585\n",
            "  Most common adjacency: '(99, 107)' (count: 32)\n",
            "  Most common adjacency: 'ck' (count: 32)\n",
            "\n",
            "Updating trie...\n",
            "(99, 107)\n",
            "\n",
            "Iteration 331:\n",
            "Current vocab size: 586\n",
            "  Most common adjacency: '(112, 115)' (count: 70)\n",
            "  Most common adjacency: 'ps' (count: 70)\n",
            "\n",
            "Updating trie...\n",
            "(112, 115)\n",
            "\n",
            "Iteration 332:\n",
            "Current vocab size: 587\n",
            "  Most common adjacency: '(46, 10, 45)' (count: 31)\n",
            "  Most common adjacency: '.\n",
            "-' (count: 31)\n",
            "\n",
            "Updating trie...\n",
            "(46, 10, 45)\n",
            "\n",
            "Iteration 333:\n",
            "Current vocab size: 588\n",
            "  Most common adjacency: '(105, 110, 100)' (count: 51)\n",
            "  Most common adjacency: 'ind' (count: 51)\n",
            "\n",
            "Updating trie...\n",
            "(105, 110, 100)\n",
            "\n",
            "Iteration 334:\n",
            "Current vocab size: 589\n",
            "  Most common adjacency: '(117, 114, 101)' (count: 96)\n",
            "  Most common adjacency: 'ure' (count: 96)\n",
            "\n",
            "Updating trie...\n",
            "(117, 114, 101)\n",
            "\n",
            "Iteration 335:\n",
            "Current vocab size: 590\n",
            "  Most common adjacency: '(32, 104, 97, 118, 101)' (count: 47)\n",
            "  Most common adjacency: ' have' (count: 47)\n",
            "\n",
            "Updating trie...\n",
            "(32, 104, 97, 118, 101)\n",
            "\n",
            "Iteration 336:\n",
            "Current vocab size: 591\n",
            "  Most common adjacency: '(117, 98)' (count: 40)\n",
            "  Most common adjacency: 'ub' (count: 40)\n",
            "\n",
            "Updating trie...\n",
            "(117, 98)\n",
            "\n",
            "Iteration 337:\n",
            "Current vocab size: 592\n",
            "  Most common adjacency: '(226, 128, 157)' (count: 65)\n",
            "  Most common adjacency: 'â€' (count: 65)\n",
            "\n",
            "Updating trie...\n",
            "(226, 128, 157)\n",
            "\n",
            "Iteration 338:\n",
            "Current vocab size: 593\n",
            "  Most common adjacency: '(101, 99)' (count: 45)\n",
            "  Most common adjacency: 'ec' (count: 45)\n",
            "\n",
            "Updating trie...\n",
            "(101, 99)\n",
            "\n",
            "Iteration 339:\n",
            "Current vocab size: 594\n",
            "  Most common adjacency: '(32, 85)' (count: 38)\n",
            "  Most common adjacency: ' U' (count: 38)\n",
            "\n",
            "Updating trie...\n",
            "(32, 85)\n",
            "\n",
            "Iteration 340:\n",
            "Current vocab size: 595\n",
            "  Most common adjacency: '(111, 119, 115)' (count: 31)\n",
            "  Most common adjacency: 'ows' (count: 31)\n",
            "\n",
            "Updating trie...\n",
            "(111, 119, 115)\n",
            "\n",
            "Iteration 341:\n",
            "Current vocab size: 596\n",
            "  Most common adjacency: '(46, 46, 46, 46)' (count: 235)\n",
            "  Most common adjacency: '....' (count: 235)\n",
            "\n",
            "Updating trie...\n",
            "(46, 46, 46, 46)\n",
            "\n",
            "Iteration 342:\n",
            "Current vocab size: 597\n",
            "  Most common adjacency: '(112, 111, 114, 116)' (count: 47)\n",
            "  Most common adjacency: 'port' (count: 47)\n",
            "\n",
            "Updating trie...\n",
            "(112, 111, 114, 116)\n",
            "\n",
            "Iteration 343:\n",
            "Current vocab size: 598\n",
            "  Most common adjacency: '(105, 115, 116, 105, 99)' (count: 63)\n",
            "  Most common adjacency: 'istic' (count: 63)\n",
            "\n",
            "Updating trie...\n",
            "(105, 115, 116, 105, 99)\n",
            "\n",
            "Iteration 344:\n",
            "Current vocab size: 599\n",
            "  Most common adjacency: '(99, 116, 105, 111, 110)' (count: 42)\n",
            "  Most common adjacency: 'ction' (count: 42)\n",
            "\n",
            "Updating trie...\n",
            "(99, 116, 105, 111, 110)\n",
            "\n",
            "Learning complete!\n",
            "\n",
            "Saving vocabulary to vocab-65k-fw-byte-sas.txt\n",
            "Saved 600 tokens\n"
          ]
        }
      ],
      "source": [
        "print(\"Starting tokenizer test...\")\n",
        "print(\"Loading dataset...\")\n",
        "dataset = datasets.load_dataset('coms4705-hewitt/fineweb-linuxlike', 'default', streaming=True)['train']\n",
        "print(\"Dataset loaded\")\n",
        "\n",
        "print(\"\\nCreating TokenizerLearner...\")\n",
        "# learner = TokenizerLearner(dataset, vocab_size=65536, docs_per_iter=20, no_subwords_across_space=False)\n",
        "learner = TokenizerLearner(dataset, vocab_size=600, docs_per_iter=20, no_subwords_across_space=True)\n",
        "print(\"Starting learning process...\")\n",
        "if not SUBMISSION_READY:\n",
        "    learner.learn()\n",
        "print(\"\\nLearning complete!\")\n",
        "learner.save('vocab-65k-fw-byte-sas.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCqhVlJQzFPZ"
      },
      "source": [
        "# **Testing the Tokenizer**\n",
        "\n",
        "Once the vocabulary is learned, we can test the tokenizer by encoding some example strings and decoding them back to verify correctness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYnAIRaYzJQy",
        "outputId": "3669e7a9-c788-4b69-b715-75b5133dd82e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding and decoding examples:\n",
            "\n",
            "Original text:  Hello, world!\n",
            "Encoded bytes:  [72, 566, 111, 44, 274, 263, 394, 33]\n",
            "Individual 'decoded' token strings:  ['H', 'ell', 'o', ',', ' w', 'or', 'ld', '!']\n",
            "Broke 13 characters into 8 tokens!\n",
            "Decoded text: Hello, world!\n",
            "Is decoded same as original text?:  True\n",
            "\n",
            "Original text:  The quick brown fox jumps over the lazy dog.\n",
            "Encoded bytes:  [84, 259, 32, 426, 293, 107, 287, 297, 119, 110, 270, 111, 120, 32, 106, 462, 586, 285, 358, 264, 325, 97, 122, 121, 498, 103, 46]\n",
            "Individual 'decoded' token strings:  ['T', 'he', ' ', 'qu', 'ic', 'k', ' b', 'ro', 'w', 'n', ' f', 'o', 'x', ' ', 'j', 'um', 'ps', ' o', 'ver', ' the', ' l', 'a', 'z', 'y', ' do', 'g', '.']\n",
            "Broke 44 characters into 27 tokens!\n",
            "Decoded text: The quick brown fox jumps over the lazy dog.\n",
            "Is decoded same as original text?:  True\n",
            "\n",
            "Original text:  def tokenize(text): return text.split()\n",
            "Encoded bytes:  [100, 101, 102, 286, 374, 110, 526, 101, 40, 116, 344, 116, 41, 58, 313, 116, 396, 110, 256, 344, 116, 46, 115, 112, 108, 275, 40, 41]\n",
            "Individual 'decoded' token strings:  ['d', 'e', 'f', ' to', 'ke', 'n', 'iz', 'e', '(', 't', 'ex', 't', ')', ':', ' re', 't', 'ur', 'n', ' t', 'ex', 't', '.', 's', 'p', 'l', 'it', '(', ')']\n",
            "Broke 39 characters into 28 tokens!\n",
            "Decoded text: def tokenize(text): return text.split()\n",
            "Is decoded same as original text?:  True\n",
            "\n",
            "Original text:  ðŸŒŸ Unicode characters work too! ðŸš€\n",
            "Encoded bytes:  [240, 159, 140, 159, 594, 110, 293, 511, 268, 104, 289, 412, 331, 115, 440, 286, 111, 33, 32, 240, 159, 154, 128]\n",
            "Individual 'decoded' token strings:  ['', '', '', '', ' U', 'n', 'ic', 'ode', ' c', 'h', 'ar', 'ac', 'ter', 's', ' work', ' to', 'o', '!', ' ', '', '', '', '']\n",
            "Broke 32 characters into 23 tokens!\n",
            "Decoded text: ðŸŒŸ Unicode characters work too! ðŸš€\n",
            "Is decoded same as original text?:  True\n",
            "\n",
            "Original text:  What happens when you decode a â˜ƒ?\n",
            "Encoded bytes:  [87, 104, 265, 311, 499, 403, 110, 115, 480, 284, 304, 486, 348, 100, 101, 257, 32, 226, 152, 131, 63]\n",
            "Individual 'decoded' token strings:  ['W', 'h', 'at', ' h', 'ap', 'pe', 'n', 's', ' wh', 'en', ' you', ' de', 'co', 'd', 'e', ' a', ' ', '', '', '', '?']\n",
            "Broke 33 characters into 21 tokens!\n",
            "Decoded text: What happens when you decode a â˜ƒ?\n",
            "Is decoded same as original text?:  True\n"
          ]
        }
      ],
      "source": [
        "examples = [\n",
        "    \"Hello, world!\",\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"def tokenize(text): return text.split()\",\n",
        "    \"ðŸŒŸ Unicode characters work too! ðŸš€\",\n",
        "    \"What happens when you decode a \\u2603?\"\n",
        "]\n",
        "\n",
        "print(\"Encoding and decoding examples:\")\n",
        "for text in examples:\n",
        "    print(\"\\nOriginal text: \", text)\n",
        "    encoded = learner.tokenizer.encode(text)\n",
        "    print(\"Encoded bytes: \", encoded)\n",
        "    token_strings = [learner.tokenizer.decode([token]) for token in encoded]\n",
        "    print(\"Individual 'decoded' token strings: \", token_strings)\n",
        "    print(f\"Broke {len(text)} characters into {len(encoded)} tokens!\")\n",
        "    decoded = learner.tokenizer.decode(encoded)\n",
        "    print(\"Decoded text:\", decoded)\n",
        "    print('Is decoded same as original text?: ', decoded==text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the cell showing the output for tokenizing the snowman emoji (â˜ƒ), you see the following under **Individual 'decoded' token strings**:\n",
        "\n",
        "```\n",
        "['W', 'h', 'at', ' h', 'ap', 'pe', 'n', 's', ' wh', 'en', ' you', ' de', 'co', 'd', 'e', ' a', ' ', '', '', '', '?']\n",
        "```\n",
        "For the snowman emoji (right after the `' a', ' '`) you see three empty strings: `'', '', ''`.\n",
        "\n",
        "**What do the tokens look like?**\n",
        "- Each empty string corresponds to one of the bytes that make up the UTF-8 encoding of the snowman emoji (â˜ƒ).\n",
        "- Specifically, â˜ƒ in UTF-8 is represented as three bytes: `0xE2`, `0x98`, `0x83` (which are 226, 152, 131 in decimal).\n",
        "- Because this is a **byte-level** tokenizer and the snowman emoji doesn't appear in the limited training text, the tokenizer doesn't have a multi-byte token for it in its vocabulary.\n",
        "- Instead, it falls back to splitting it into individual bytes, each as a separate token.\n",
        "- When decoding these bytes to strings using `.decode('utf-8', errors='ignore')`, these non-ASCII bytes individually are invalid as standalone Unicode, so they're shown as empty strings.\n",
        "\n",
        "**Why does this happen?**\n",
        "- Your tokenizer is trained on regular text data, and with a small vocabulary size, it doesn't create tokens for rare or unseen Unicode code points like the snowman.\n",
        "- The byte-level architecture guarantees every Unicode sequence is representable, even if not natively in the vocab, by breaking it into 1-byte chunks. For unseen Unicode symbols, this produces as many 1-byte tokens as needed.\n",
        "- When printing, valid byte tokens are shown as their string form (like `'a'` for ASCII 97), but single bytes from a multi-byte emoji decode to empty strings because they're not valid on their own.\n",
        "\n",
        "**Summary**:  \n",
        "The snowman emoji is tokenized into three separate tokens (one for each UTF-8 byte), and each shows as an empty string because a single UTF-8 byte of an emoji doesn't decode properly as text. This demonstrates how a byte-level tokenizer gracefully handles unseen Unicode, but can't represent such tokens as readable strings unless the full sequence is present in the vocab.[1]\n",
        "\n"
      ],
      "metadata": {
        "id": "LeYs1tlNj9C-"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e7ac66077fce463bb4ee552d4a9d95f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3717070348044418763c84da3f17cf0",
              "IPY_MODEL_a1c86ad1a82e41638fda9b391e0cc75f",
              "IPY_MODEL_ec5f7408d0024aceb570c8c06ef33330"
            ],
            "layout": "IPY_MODEL_d82fd14f4602429eb8c466c822892d6f"
          }
        },
        "a3717070348044418763c84da3f17cf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_705b2bb680d848dfa76085f1610462f0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4aed39f9fdcc40bc95111e4761e5642f",
            "value": "README.md:â€‡100%"
          }
        },
        "a1c86ad1a82e41638fda9b391e0cc75f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0836cde68ac48d5a2d07d59d904e23b",
            "max": 27,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ccd344ba3b44c0888f6dab4421b57f7",
            "value": 27
          }
        },
        "ec5f7408d0024aceb570c8c06ef33330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30ba1a38b8dc41b6bdf60c7fc7c4c769",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_eef5f36f17c14a3b85c7121d1e1f84ca",
            "value": "â€‡27.0/27.0â€‡[00:00&lt;00:00,â€‡1.18kB/s]"
          }
        },
        "d82fd14f4602429eb8c466c822892d6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "705b2bb680d848dfa76085f1610462f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4aed39f9fdcc40bc95111e4761e5642f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0836cde68ac48d5a2d07d59d904e23b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ccd344ba3b44c0888f6dab4421b57f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30ba1a38b8dc41b6bdf60c7fc7c4c769": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eef5f36f17c14a3b85c7121d1e1f84ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}