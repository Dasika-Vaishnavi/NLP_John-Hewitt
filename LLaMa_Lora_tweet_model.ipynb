{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPJ6+I5BNWE63vYTJUG7foV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5b409086568f404d8e25b86b74701dcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13e429a99d7a4fedaee1f91ed2e6972f",
              "IPY_MODEL_1bc753360b2542da8186e99e4119da68",
              "IPY_MODEL_e8bfd25d55b646d393e5a94d69f65aad"
            ],
            "layout": "IPY_MODEL_363c22cf17844714a53455a683db8055"
          }
        },
        "13e429a99d7a4fedaee1f91ed2e6972f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a77e771e677e4a7c9b32fc9f2d2aa3d7",
            "placeholder": "​",
            "style": "IPY_MODEL_e6c91e23dfe849028a849de12e3485a0",
            "value": "Map: 100%"
          }
        },
        "1bc753360b2542da8186e99e4119da68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6259cc7556d94d819e0bb2522ac89034",
            "max": 93329,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8b763cdbfdf422c975440a9e1fbb520",
            "value": 93329
          }
        },
        "e8bfd25d55b646d393e5a94d69f65aad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24b3f792dbd84deba418f8da1a778962",
            "placeholder": "​",
            "style": "IPY_MODEL_18cdb204c829415db24c114d43e9e211",
            "value": " 93329/93329 [00:14&lt;00:00, 19430.22 examples/s]"
          }
        },
        "363c22cf17844714a53455a683db8055": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a77e771e677e4a7c9b32fc9f2d2aa3d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6c91e23dfe849028a849de12e3485a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6259cc7556d94d819e0bb2522ac89034": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8b763cdbfdf422c975440a9e1fbb520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24b3f792dbd84deba418f8da1a778962": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18cdb204c829415db24c114d43e9e211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ca9162382894d69ae33d498cce04425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd335e2698344eb5b77060b747208428",
              "IPY_MODEL_4d5d2894856e4bc19e69b11acfa55b96",
              "IPY_MODEL_2db8cf9e8f8c4b42ad9f93dd94792c59"
            ],
            "layout": "IPY_MODEL_32b51ca42d3744de9eaed3e5f82cb9af"
          }
        },
        "bd335e2698344eb5b77060b747208428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_896439906d0d4774a2eed47d40f037b7",
            "placeholder": "​",
            "style": "IPY_MODEL_079671600d674e6c834e02b59a66551f",
            "value": "Map: 100%"
          }
        },
        "4d5d2894856e4bc19e69b11acfa55b96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25d1ac125c044e2ab360fa3b7e094f68",
            "max": 23333,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6da34e48771346a9a960bb24df22d904",
            "value": 23333
          }
        },
        "2db8cf9e8f8c4b42ad9f93dd94792c59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e351a851a3a42a7a85f6e20767de3a7",
            "placeholder": "​",
            "style": "IPY_MODEL_ae74b3ba4a5041939a783ccd6c9d0d30",
            "value": " 23333/23333 [00:01&lt;00:00, 19733.39 examples/s]"
          }
        },
        "32b51ca42d3744de9eaed3e5f82cb9af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "896439906d0d4774a2eed47d40f037b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "079671600d674e6c834e02b59a66551f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25d1ac125c044e2ab360fa3b7e094f68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6da34e48771346a9a960bb24df22d904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e351a851a3a42a7a85f6e20767de3a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae74b3ba4a5041939a783ccd6c9d0d30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45a49d0e9a464acbba254b6fb3088562": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9aa3628ca10e4f78afc2ad44508494a2",
              "IPY_MODEL_66c5fff878dd4f89a4f614cdf62b909b",
              "IPY_MODEL_ebf6398688fb4b968dec45874ac1861b"
            ],
            "layout": "IPY_MODEL_23504bd666e64b02820a7bc38110ce5c"
          }
        },
        "9aa3628ca10e4f78afc2ad44508494a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a2a400bd37844c786e6d86139e2ef67",
            "placeholder": "​",
            "style": "IPY_MODEL_bd99bbe2015b4371903d8cd8a78cc656",
            "value": "Map: 100%"
          }
        },
        "66c5fff878dd4f89a4f614cdf62b909b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b768a16357c84234a36ac39e801e9139",
            "max": 23338,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ba9ad79b5b842789412799ff8279df9",
            "value": 23338
          }
        },
        "ebf6398688fb4b968dec45874ac1861b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b9b8d6720434b1ea7202f6f53feb16d",
            "placeholder": "​",
            "style": "IPY_MODEL_0b9149da85514462884cd9853833e77d",
            "value": " 23338/23338 [00:00&lt;00:00, 25194.20 examples/s]"
          }
        },
        "23504bd666e64b02820a7bc38110ce5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a2a400bd37844c786e6d86139e2ef67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd99bbe2015b4371903d8cd8a78cc656": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b768a16357c84234a36ac39e801e9139": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ba9ad79b5b842789412799ff8279df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b9b8d6720434b1ea7202f6f53feb16d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b9149da85514462884cd9853833e77d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dasika-Vaishnavi/NLP_John-Hewitt/blob/main/LLaMa_Lora_tweet_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Iqejnb7nRbaF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from datasets import Dataset, load_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, accuracy_score, precision_recall_fscore_support,\n",
        "    classification_report, confusion_matrix\n",
        ")\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# SECTION 1: SETUP & REPRODUCIBILITY\n",
        "# =====================================================================\n",
        "RANDOM_SEED = 4705\n",
        "\n",
        "def set_seed(seed_value=RANDOM_SEED):\n",
        "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed_value)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    print(f\"Global seed set to {seed_value}\")\n",
        "\n",
        "set_seed()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78i2GDu9Rm01",
        "outputId": "19f6f919-9df5-4879-9c64-ed7b7631b207"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global seed set to 4705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# SECTION 2: DATA LOADING & PREPROCESSING\n",
        "# =====================================================================\n",
        "print(\"Loading dataset...\")\n",
        "ds_en = load_dataset(\"siddharthgowda/twitter_500k_EN_only\", split=\"train\")\n",
        "ds_en = ds_en.to_pandas()\n",
        "print(f\"Initial dataset size: {len(ds_en)}\")\n",
        "\n",
        "# Convert engagement columns to numeric\n",
        "for col in [\"replies\", \"retweets\", \"likes\", \"quotes\"]:\n",
        "    ds_en[col] = pd.to_numeric(ds_en[col], errors=\"coerce\").fillna(0).astype(int)\n",
        "\n",
        "# Calculate total engagement\n",
        "ds_en[\"engagement\"] = ds_en[\"replies\"] + ds_en[\"retweets\"] + ds_en[\"likes\"] + ds_en[\"quotes\"]\n",
        "\n",
        "# Calculate the 99th percentile of engagement\n",
        "engagement_threshold = ds_en[\"engagement\"].quantile(0.99)\n",
        "print(f\"Engagement threshold for top 1%: {engagement_threshold}\")\n",
        "\n",
        "# Create binary labels: 1 for high virality (top 1%), 0 otherwise\n",
        "ds_en[\"labels\"] = (ds_en[\"engagement\"] >= engagement_threshold).astype(int)\n",
        "\n",
        "# Clean up any potential NaN\n",
        "ds_en = ds_en.dropna(subset=[\"tweet\", \"labels\"]).copy()\n",
        "ds_en[\"labels\"] = ds_en[\"labels\"].astype(int)\n",
        "\n",
        "print(f\"Label distribution:\\n{ds_en['labels'].value_counts()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVQ1PUBMRrxV",
        "outputId": "cce32d55-59a2-4f9e-9939-6451de0f6aac"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Initial dataset size: 574137\n",
            "Engagement threshold for top 1%: 4542.640000000014\n",
            "Label distribution:\n",
            "labels\n",
            "0    568395\n",
            "1      5742\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# SECTION 3: STRATIFIED SAMPLING\n",
        "# =====================================================================\n",
        "SAMPLE_SIZE = 140_000  # adjust based on compute resources\n",
        "\n",
        "print(f\"\\nPerforming stratified sampling of {SAMPLE_SIZE} samples...\")\n",
        "_, ds_sample_df, _, _ = train_test_split(\n",
        "    ds_en,\n",
        "    ds_en['labels'],\n",
        "    test_size=min(SAMPLE_SIZE, len(ds_en)),\n",
        "    random_state=RANDOM_SEED,\n",
        "    stratify=ds_en['labels']\n",
        ")\n",
        "\n",
        "print(f\"Sampled dataset size: {len(ds_sample_df)}\")\n",
        "print(f\"Sampled label distribution:\\n{ds_sample_df['labels'].value_counts()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcaBcwP7R2uM",
        "outputId": "18a6d0c2-fbe9-4f0a-882b-df9f374d61ff"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Performing stratified sampling of 140000 samples...\n",
            "Sampled dataset size: 140000\n",
            "Sampled label distribution:\n",
            "labels\n",
            "0    138600\n",
            "1      1400\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# SECTION 4: TRAIN/VAL/TEST SPLIT\n",
        "# =====================================================================\n",
        "X = ds_sample_df[[\"tweet\"]].values\n",
        "y = ds_sample_df[\"labels\"].astype(int).values\n",
        "\n",
        "print(f\"\\nSplitting data - X shape: {X.shape}, y shape: {y.shape}\")\n",
        "\n",
        "# Split: 70% train, 10% val, 20% test\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X, y, test_size=0.1667, random_state=RANDOM_SEED, stratify=y\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.2, random_state=RANDOM_SEED, stratify=y_temp\n",
        ")\n",
        "\n",
        "# Create DataFrames\n",
        "train_df = pd.DataFrame(X_train, columns=[\"tweet\"])\n",
        "train_df[\"labels\"] = y_train.flatten()\n",
        "train_df.rename(columns={\"tweet\": \"text\"}, inplace=True)\n",
        "\n",
        "valid_df = pd.DataFrame(X_val, columns=[\"tweet\"])\n",
        "valid_df[\"labels\"] = y_val.flatten()\n",
        "valid_df.rename(columns={\"tweet\": \"text\"}, inplace=True)\n",
        "\n",
        "test_df = pd.DataFrame(X_test, columns=[\"tweet\"])\n",
        "test_df[\"labels\"] = y_test.flatten()\n",
        "test_df.rename(columns={\"tweet\": \"text\"}, inplace=True)\n",
        "\n",
        "print(f\"\\nDataset splits:\")\n",
        "print(f\"Train: {len(train_df)} samples, {train_df['labels'].sum()} positive ({train_df['labels'].mean()*100:.2f}%)\")\n",
        "print(f\"Valid: {len(valid_df)} samples, {valid_df['labels'].sum()} positive ({valid_df['labels'].mean()*100:.2f}%)\")\n",
        "print(f\"Test:  {len(test_df)} samples, {test_df['labels'].sum()} positive ({test_df['labels'].mean()*100:.2f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-3fN_erR9Un",
        "outputId": "98133cfc-a780-41e2-94f2-ad604a903590"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Splitting data - X shape: (140000, 1), y shape: (140000,)\n",
            "\n",
            "Dataset splits:\n",
            "Train: 93329 samples, 934 positive (1.00%)\n",
            "Valid: 23333 samples, 233 positive (1.00%)\n",
            "Test:  23338 samples, 233 positive (1.00%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# SECTION 5: MODEL CONFIGURATION\n",
        "# =====================================================================\n",
        "MODEL_NAME = \"meta-llama/Llama-3.2-1B\"\n",
        "MAX_LENGTH = 128  # Reduce to 64 or 96 if OOM\n",
        "OUTPUT_DIR = \"./llama-virality-final\"\n"
      ],
      "metadata": {
        "id": "kxku83ZlSBaG"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(new_session=False)"
      ],
      "metadata": {
        "id": "PlJDtA1rSVGS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=\"meta-llama/Llama-3.2-1B\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyomNueISbjL",
        "outputId": "1c11634d-7eed-4b29-8259-0ffad99809dc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-1B\")"
      ],
      "metadata": {
        "id": "ghW7rj3-SiA_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# SECTION 6: LOAD MODEL WITH MEMORY OPTIMIZATIONS\n",
        "# =====================================================================\n",
        "print(f\"\\nLoading model: {MODEL_NAME}...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Set pad token (LLaMA doesn't have one by default)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Use bfloat16 if available, else float16\n",
        "dtype = torch.bfloat16 if torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8 else torch.float16\n",
        "print(f\"Using dtype: {dtype}\")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=2,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=dtype,\n",
        "    low_cpu_mem_usage=True\n",
        ")\n",
        "\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "# Ensure the classification head is in float32 for stability\n",
        "if hasattr(model, 'score'):\n",
        "    model.score = model.score.float()\n",
        "elif hasattr(model, 'classifier'):\n",
        "    model.classifier = model.classifier.float()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtYVXBUWSKwx",
        "outputId": "4bef01bc-7d9c-499b-f84b-f08897a59762"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading model: meta-llama/Llama-3.2-1B...\n",
            "Using dtype: torch.float16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# SECTION 7: APPLY LoRA FOR EFFICIENT TRAINING\n",
        "# =====================================================================\n",
        "print(\"Applying LoRA for parameter-efficient fine-tuning...\")\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    r=8,  # rank - reduce to 4 if OOM\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n",
        "    bias=\"none\",\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "# Enable gradient checkpointing\n",
        "model.gradient_checkpointing_enable()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVkzxxJ1SgoG",
        "outputId": "c644cea8-6b47-4705-d023-2fe69f84bc3a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying LoRA for parameter-efficient fine-tuning...\n",
            "trainable params: 1,708,032 || all params: 1,237,526,528 || trainable%: 0.1380\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff926e3f",
        "outputId": "b8391dac-252a-4b6d-999e-1c8a76c65528"
      },
      "source": [
        "# =====================================================================\n",
        "# SECTION 7: APPLY LoRA FOR EFFICIENT TRAINING\n",
        "# =====================================================================\n",
        "print(\"Applying LoRA for parameter-efficient fine-tuning...\")\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    r=8,  # rank - reduce to 4 if OOM\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n",
        "    bias=\"none\",\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "# Enable gradient checkpointing\n",
        "model.gradient_checkpointing_enable()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying LoRA for parameter-efficient fine-tuning...\n",
            "trainable params: 1,708,032 || all params: 1,237,526,528 || trainable%: 0.1380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/peft/mapping_func.py:72: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# SECTION 8: TOKENIZE DATA\n",
        "# =====================================================================\n",
        "print(\"\\nTokenizing datasets...\")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        padding=False,\n",
        "        truncation=True,\n",
        "        max_length=MAX_LENGTH,\n",
        "    )\n",
        "\n",
        "# Convert to Hugging Face Dataset format\n",
        "train_dataset = Dataset.from_pandas(train_df[[\"text\", \"labels\"]])\n",
        "val_dataset = Dataset.from_pandas(valid_df[[\"text\", \"labels\"]])\n",
        "test_dataset = Dataset.from_pandas(test_df[[\"text\", \"labels\"]])\n",
        "\n",
        "# Tokenize\n",
        "tokenized_train = train_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
        "tokenized_val = val_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
        "tokenized_test = test_dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
        "\n",
        "print(f\"Tokenization complete:\")\n",
        "print(f\"  Train: {len(tokenized_train)} samples\")\n",
        "print(f\"  Valid: {len(tokenized_val)} samples\")\n",
        "print(f\"  Test:  {len(tokenized_test)} samples\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "5b409086568f404d8e25b86b74701dcc",
            "13e429a99d7a4fedaee1f91ed2e6972f",
            "1bc753360b2542da8186e99e4119da68",
            "e8bfd25d55b646d393e5a94d69f65aad",
            "363c22cf17844714a53455a683db8055",
            "a77e771e677e4a7c9b32fc9f2d2aa3d7",
            "e6c91e23dfe849028a849de12e3485a0",
            "6259cc7556d94d819e0bb2522ac89034",
            "f8b763cdbfdf422c975440a9e1fbb520",
            "24b3f792dbd84deba418f8da1a778962",
            "18cdb204c829415db24c114d43e9e211",
            "5ca9162382894d69ae33d498cce04425",
            "bd335e2698344eb5b77060b747208428",
            "4d5d2894856e4bc19e69b11acfa55b96",
            "2db8cf9e8f8c4b42ad9f93dd94792c59",
            "32b51ca42d3744de9eaed3e5f82cb9af",
            "896439906d0d4774a2eed47d40f037b7",
            "079671600d674e6c834e02b59a66551f",
            "25d1ac125c044e2ab360fa3b7e094f68",
            "6da34e48771346a9a960bb24df22d904",
            "4e351a851a3a42a7a85f6e20767de3a7",
            "ae74b3ba4a5041939a783ccd6c9d0d30",
            "45a49d0e9a464acbba254b6fb3088562",
            "9aa3628ca10e4f78afc2ad44508494a2",
            "66c5fff878dd4f89a4f614cdf62b909b",
            "ebf6398688fb4b968dec45874ac1861b",
            "23504bd666e64b02820a7bc38110ce5c",
            "7a2a400bd37844c786e6d86139e2ef67",
            "bd99bbe2015b4371903d8cd8a78cc656",
            "b768a16357c84234a36ac39e801e9139",
            "1ba9ad79b5b842789412799ff8279df9",
            "4b9b8d6720434b1ea7202f6f53feb16d",
            "0b9149da85514462884cd9853833e77d"
          ]
        },
        "id": "yvBZ9vpTSNy2",
        "outputId": "d479fbc2-3b8d-4301-983e-16fd4dd88cc1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokenizing datasets...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/93329 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b409086568f404d8e25b86b74701dcc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/23333 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ca9162382894d69ae33d498cce04425"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/23338 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45a49d0e9a464acbba254b6fb3088562"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization complete:\n",
            "  Train: 93329 samples\n",
            "  Valid: 23333 samples\n",
            "  Test:  23338 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# SECTION 9: DATA COLLATOR & METRICS\n",
        "# =====================================================================\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    probs = torch.softmax(torch.tensor(predictions), dim=1)[:, 1].numpy()\n",
        "    preds = np.argmax(predictions, axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, preds, average='binary', zero_division=0\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        auc = roc_auc_score(labels, probs)\n",
        "    except:\n",
        "        auc = 0.0\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "        \"auc\": auc,\n",
        "    }"
      ],
      "metadata": {
        "id": "5NzCZxhsTQSg"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# SECTION 10: TRAINING ARGUMENTS (MEMORY-EFFICIENT)\n",
        "# =====================================================================\n",
        "# Detect if GPU supports bfloat16 (better than fp16 for training stability)\n",
        "use_bf16 = torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "\n",
        "    # MEMORY OPTIMIZATIONS\n",
        "    per_device_train_batch_size=2,  # Reduce to 1 if OOM\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=8,  # Effective batch = 2*8 = 16\n",
        "    bf16=use_bf16,  # Use bfloat16 if available (Ampere GPUs and newer)\n",
        "    fp16=not use_bf16,  # Fallback to fp16 for older GPUs\n",
        "    fp16_full_eval=True,  # Use fp16 for evaluation to save memory\n",
        "\n",
        "    # TRAINING SCHEDULE\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-4,  # Higher LR works well with LoRA\n",
        "    warmup_ratio=0.1,\n",
        "    weight_decay=0.01,\n",
        "\n",
        "    # EVALUATION & LOGGING\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=200,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=200,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "\n",
        "    logging_steps=100,\n",
        "    logging_dir=f\"{OUTPUT_DIR}/logs\",\n",
        "\n",
        "    # EFFICIENCY\n",
        "    dataloader_num_workers=2,\n",
        "    gradient_checkpointing=True,\n",
        "    optim=\"adamw_torch\",\n",
        "\n",
        "    # MISC\n",
        "    report_to=\"none\",\n",
        "    remove_unused_columns=True,\n",
        "    seed=RANDOM_SEED,\n",
        ")"
      ],
      "metadata": {
        "id": "G-1-zSFxTlKC"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# SECTION 11: INITIALIZE TRAINER\n",
        "# =====================================================================\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJZI9c4eTrk2",
        "outputId": "e47cb29f-cc2f-47dc-907c-f824d77f28dd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4104064424.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# SECTION 12: TRAIN MODEL\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"STARTING TRAINING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "try:\n",
        "    trainer.train()\n",
        "    print(\"\\n✓ Training completed successfully!\")\n",
        "except RuntimeError as e:\n",
        "    if \"out of memory\" in str(e):\n",
        "        print(\"\\n❌ OUT OF MEMORY ERROR\")\n",
        "        print(\"\\nTroubleshooting steps:\")\n",
        "        print(\"1. Reduce per_device_train_batch_size to 1\")\n",
        "        print(\"2. Increase gradient_accumulation_steps to 16 or 32\")\n",
        "        print(\"3. Reduce MAX_LENGTH to 64 or 96\")\n",
        "        print(\"4. Reduce LoRA rank to r=4\")\n",
        "        print(\"5. Use fewer target_modules: ['q_proj', 'v_proj']\")\n",
        "        raise\n",
        "    else:\n",
        "        raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eR4pwnDXTwqw",
        "outputId": "e18c84d5-c518-44fc-d3b0-86e41e9d4329"
      },
      "execution_count": 39,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STARTING TRAINING\n",
            "======================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2801' max='17502' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 2801/17502 1:18:28 < 6:52:11, 0.59 it/s, Epoch 0.48/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>2.952000</td>\n",
              "      <td>0.077138</td>\n",
              "      <td>0.989457</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.456954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.794000</td>\n",
              "      <td>0.101092</td>\n",
              "      <td>0.989757</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.490831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.066200</td>\n",
              "      <td>0.083713</td>\n",
              "      <td>0.989800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.547416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.655000</td>\n",
              "      <td>0.099779</td>\n",
              "      <td>0.989886</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.579982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.973500</td>\n",
              "      <td>0.100743</td>\n",
              "      <td>0.989886</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.632213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.516100</td>\n",
              "      <td>0.108556</td>\n",
              "      <td>0.989886</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.661512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>1.005700</td>\n",
              "      <td>0.090792</td>\n",
              "      <td>0.989886</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.693506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.758100</td>\n",
              "      <td>0.094145</td>\n",
              "      <td>0.989928</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.724878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.815900</td>\n",
              "      <td>0.080923</td>\n",
              "      <td>0.989971</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.738630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.604600</td>\n",
              "      <td>0.090267</td>\n",
              "      <td>0.989971</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.748500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>1.013900</td>\n",
              "      <td>0.076542</td>\n",
              "      <td>0.989928</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.756999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.656000</td>\n",
              "      <td>0.084072</td>\n",
              "      <td>0.989971</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.774174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.463800</td>\n",
              "      <td>0.113444</td>\n",
              "      <td>0.989971</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.799491</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3842' max='5834' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3842/5834 02:58 < 01:32, 21.50 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='17502' max='17502' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [17502/17502 8:40:39, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>2.952000</td>\n",
              "      <td>0.077138</td>\n",
              "      <td>0.989457</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.456954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.794000</td>\n",
              "      <td>0.101092</td>\n",
              "      <td>0.989757</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.490831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.066200</td>\n",
              "      <td>0.083713</td>\n",
              "      <td>0.989800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.547416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.655000</td>\n",
              "      <td>0.099779</td>\n",
              "      <td>0.989886</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.579982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.973500</td>\n",
              "      <td>0.100743</td>\n",
              "      <td>0.989886</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.632213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.516100</td>\n",
              "      <td>0.108556</td>\n",
              "      <td>0.989886</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.661512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>1.005700</td>\n",
              "      <td>0.090792</td>\n",
              "      <td>0.989886</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.693506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.758100</td>\n",
              "      <td>0.094145</td>\n",
              "      <td>0.989928</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.724878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.815900</td>\n",
              "      <td>0.080923</td>\n",
              "      <td>0.989971</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.738630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.604600</td>\n",
              "      <td>0.090267</td>\n",
              "      <td>0.989971</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.748500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>1.013900</td>\n",
              "      <td>0.076542</td>\n",
              "      <td>0.989928</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.756999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.656000</td>\n",
              "      <td>0.084072</td>\n",
              "      <td>0.989971</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.774174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.463800</td>\n",
              "      <td>0.113444</td>\n",
              "      <td>0.989971</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.799491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.824800</td>\n",
              "      <td>0.075214</td>\n",
              "      <td>0.989971</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.791321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.653600</td>\n",
              "      <td>0.093090</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.770435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.724300</td>\n",
              "      <td>0.090152</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.788091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.688700</td>\n",
              "      <td>0.084528</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.793825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.618400</td>\n",
              "      <td>0.081734</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.791295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.645600</td>\n",
              "      <td>0.108520</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.792216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.785200</td>\n",
              "      <td>0.082098</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.818965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.904800</td>\n",
              "      <td>0.085312</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.814444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.707400</td>\n",
              "      <td>0.084945</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.816930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.907800</td>\n",
              "      <td>0.092916</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.799088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.668900</td>\n",
              "      <td>0.070446</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.808114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.620700</td>\n",
              "      <td>0.078807</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.785736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.446500</td>\n",
              "      <td>0.089674</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.818888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.786400</td>\n",
              "      <td>0.060511</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.821433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.762300</td>\n",
              "      <td>0.084260</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.799138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.665400</td>\n",
              "      <td>0.096426</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.819178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.837400</td>\n",
              "      <td>0.075570</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.829145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.954200</td>\n",
              "      <td>0.067514</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.825778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.407800</td>\n",
              "      <td>0.090739</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.812815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.666000</td>\n",
              "      <td>0.073460</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.827675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.621300</td>\n",
              "      <td>0.073503</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.820430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.581400</td>\n",
              "      <td>0.070983</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.795562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.846600</td>\n",
              "      <td>0.079853</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.830114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.756900</td>\n",
              "      <td>0.095587</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.830059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.504600</td>\n",
              "      <td>0.095771</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.792164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.722200</td>\n",
              "      <td>0.095867</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.828638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.682100</td>\n",
              "      <td>0.097720</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.821938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.495200</td>\n",
              "      <td>0.089802</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.799502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.572400</td>\n",
              "      <td>0.093563</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.814537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.763600</td>\n",
              "      <td>0.078198</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.806347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.494800</td>\n",
              "      <td>0.072198</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.818654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.682100</td>\n",
              "      <td>0.067028</td>\n",
              "      <td>0.990057</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.004292</td>\n",
              "      <td>0.008547</td>\n",
              "      <td>0.820576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.715800</td>\n",
              "      <td>0.075292</td>\n",
              "      <td>0.989971</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.004292</td>\n",
              "      <td>0.008475</td>\n",
              "      <td>0.831892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.588900</td>\n",
              "      <td>0.106541</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.834275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9600</td>\n",
              "      <td>0.768700</td>\n",
              "      <td>0.094959</td>\n",
              "      <td>0.989971</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.838308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9800</td>\n",
              "      <td>0.594500</td>\n",
              "      <td>0.086206</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.836925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.407100</td>\n",
              "      <td>0.091996</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.844875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10200</td>\n",
              "      <td>0.780800</td>\n",
              "      <td>0.094379</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.838413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10400</td>\n",
              "      <td>0.810000</td>\n",
              "      <td>0.075722</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.845229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10600</td>\n",
              "      <td>0.578300</td>\n",
              "      <td>0.085299</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.845972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10800</td>\n",
              "      <td>0.695900</td>\n",
              "      <td>0.075106</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.844318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.379200</td>\n",
              "      <td>0.087273</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.840344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11200</td>\n",
              "      <td>1.028400</td>\n",
              "      <td>0.077200</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.832721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11400</td>\n",
              "      <td>0.613800</td>\n",
              "      <td>0.074168</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.835807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11600</td>\n",
              "      <td>0.704500</td>\n",
              "      <td>0.081986</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.835340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11800</td>\n",
              "      <td>0.506400</td>\n",
              "      <td>0.076934</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.843232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.429000</td>\n",
              "      <td>0.097574</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.849533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12200</td>\n",
              "      <td>0.399800</td>\n",
              "      <td>0.083697</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.851043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12400</td>\n",
              "      <td>0.718000</td>\n",
              "      <td>0.079985</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.851331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12600</td>\n",
              "      <td>0.723700</td>\n",
              "      <td>0.068951</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.847337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12800</td>\n",
              "      <td>0.592300</td>\n",
              "      <td>0.086117</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.846169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.631600</td>\n",
              "      <td>0.081820</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.840405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13200</td>\n",
              "      <td>0.600800</td>\n",
              "      <td>0.081213</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.851367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13400</td>\n",
              "      <td>0.398000</td>\n",
              "      <td>0.089365</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.843477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13600</td>\n",
              "      <td>0.603200</td>\n",
              "      <td>0.090185</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.851912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13800</td>\n",
              "      <td>0.603300</td>\n",
              "      <td>0.073629</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.848683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>0.611700</td>\n",
              "      <td>0.074431</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.851074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14200</td>\n",
              "      <td>0.897900</td>\n",
              "      <td>0.080464</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.846247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14400</td>\n",
              "      <td>0.415500</td>\n",
              "      <td>0.087032</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.849651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14600</td>\n",
              "      <td>0.600100</td>\n",
              "      <td>0.074695</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.849031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14800</td>\n",
              "      <td>0.693000</td>\n",
              "      <td>0.082767</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.849876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>0.705400</td>\n",
              "      <td>0.074490</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.854029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15200</td>\n",
              "      <td>0.752000</td>\n",
              "      <td>0.068712</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.852582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15400</td>\n",
              "      <td>0.680300</td>\n",
              "      <td>0.074884</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.838430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15600</td>\n",
              "      <td>0.689100</td>\n",
              "      <td>0.082580</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.850579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15800</td>\n",
              "      <td>0.443300</td>\n",
              "      <td>0.078403</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.851675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16000</td>\n",
              "      <td>0.587300</td>\n",
              "      <td>0.082773</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.854527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16200</td>\n",
              "      <td>0.491300</td>\n",
              "      <td>0.081309</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.854198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16400</td>\n",
              "      <td>0.656000</td>\n",
              "      <td>0.078733</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.852981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16600</td>\n",
              "      <td>0.775000</td>\n",
              "      <td>0.075642</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.852015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16800</td>\n",
              "      <td>0.619300</td>\n",
              "      <td>0.078635</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.853846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17000</td>\n",
              "      <td>0.738000</td>\n",
              "      <td>0.078748</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.853279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17200</td>\n",
              "      <td>0.500300</td>\n",
              "      <td>0.080102</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.855149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17400</td>\n",
              "      <td>0.671600</td>\n",
              "      <td>0.078652</td>\n",
              "      <td>0.990014</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.854637</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Training completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# SECTION 13: EVALUATE ON TEST SET\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EVALUATING ON TEST SET\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "test_results = trainer.evaluate(tokenized_test)\n",
        "print(\"\\nTest Metrics from Trainer:\")\n",
        "for key, value in test_results.items():\n",
        "    print(f\"  {key}: {value:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "H05ufoSFSANY",
        "outputId": "a9546a5e-ba6f-4924-c1f2-d943fd6a6a87"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "EVALUATING ON TEST SET\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5835' max='5835' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5835/5835 04:14]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Metrics from Trainer:\n",
            "  eval_loss: 0.0680\n",
            "  eval_model_preparation_time: 0.0070\n",
            "  eval_accuracy: 0.9900\n",
            "  eval_precision: 0.5000\n",
            "  eval_recall: 0.0043\n",
            "  eval_f1: 0.0085\n",
            "  eval_auc: 0.8117\n",
            "  eval_runtime: 254.3036\n",
            "  eval_samples_per_second: 91.7720\n",
            "  eval_steps_per_second: 22.9450\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =====================================================================\n",
        "# SECTION 14: DETAILED PREDICTIONS & ANALYSIS\n",
        "# =====================================================================\n",
        "print(\"\\nGenerating detailed predictions...\")\n",
        "test_preds = trainer.predict(tokenized_test)\n",
        "test_proba = torch.softmax(torch.tensor(test_preds.predictions), dim=1)[:, 1].cpu().numpy()\n",
        "test_pred_labels = np.argmax(test_preds.predictions, axis=1)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(\"=\"*70)\n",
        "print(classification_report(test_df[\"labels\"].values, test_pred_labels,\n",
        "                          target_names=[\"Non-Viral\", \"Viral\"]))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CONFUSION MATRIX\")\n",
        "print(\"=\"*70)\n",
        "cm = confusion_matrix(test_df[\"labels\"].values, test_pred_labels)\n",
        "print(f\"                Predicted\")\n",
        "print(f\"              Non-Viral  Viral\")\n",
        "print(f\"Actual Non-Viral  {cm[0,0]:6d}   {cm[0,1]:5d}\")\n",
        "print(f\"       Viral      {cm[1,0]:6d}   {cm[1,1]:5d}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "nmixCI-7SYsk",
        "outputId": "73459ba1-e8d9-4bf0-d88d-b1251034cdf8"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating detailed predictions...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "CLASSIFICATION REPORT\n",
            "======================================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Viral       0.99      1.00      0.99     23105\n",
            "       Viral       0.50      0.00      0.01       233\n",
            "\n",
            "    accuracy                           0.99     23338\n",
            "   macro avg       0.75      0.50      0.50     23338\n",
            "weighted avg       0.99      0.99      0.99     23338\n",
            "\n",
            "\n",
            "======================================================================\n",
            "CONFUSION MATRIX\n",
            "======================================================================\n",
            "                Predicted\n",
            "              Non-Viral  Viral\n",
            "Actual Non-Viral   23104       1\n",
            "       Viral         232       1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# SECTION 15: FINAL RESULTS SUMMARY\n",
        "# =====================================================================\n",
        "llama_results = {\n",
        "    \"model_name\": \"Llama-3.2-1B Fine-tuned (LoRA)\",\n",
        "    \"accuracy\": accuracy_score(test_df[\"labels\"].values, test_pred_labels),\n",
        "    \"precision\": precision_recall_fscore_support(test_df[\"labels\"].values, test_pred_labels, average='binary')[0],\n",
        "    \"recall\": precision_recall_fscore_support(test_df[\"labels\"].values, test_pred_labels, average='binary')[1],\n",
        "    \"f1\": precision_recall_fscore_support(test_df[\"labels\"].values, test_pred_labels, average='binary')[2],\n",
        "    \"auc\": roc_auc_score(test_df[\"labels\"].values, test_proba),\n",
        "}\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FINAL RESULTS SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "for metric, value in llama_results.items():\n",
        "    if metric != \"model_name\":\n",
        "        print(f\"{metric.upper():15s}: {value:.4f}\")\n",
        "    else:\n",
        "        print(f\"MODEL: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAUcnb0-ThUE",
        "outputId": "395c5b15-d104-4bfe-9fc4-43d9aec30265"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "FINAL RESULTS SUMMARY\n",
            "======================================================================\n",
            "MODEL: Llama-3.2-1B Fine-tuned (LoRA)\n",
            "ACCURACY       : 0.9900\n",
            "PRECISION      : 0.5000\n",
            "RECALL         : 0.0043\n",
            "F1             : 0.0085\n",
            "AUC            : 0.8117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# SECTION 16: SAVE MODEL\n",
        "# =====================================================================\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"SAVING MODEL\")\n",
        "print(f\"{'='*70}\")\n",
        "trainer.save_model(OUTPUT_DIR)\n",
        "tokenizer.save_pretrained(OUTPUT_DIR)\n",
        "print(f\"✓ Model saved to: {OUTPUT_DIR}\")\n",
        "\n",
        "# Save results to file\n",
        "results_path = f\"{OUTPUT_DIR}/test_results.txt\"\n",
        "with open(results_path, 'w') as f:\n",
        "    f.write(\"=\"*70 + \"\\n\")\n",
        "    f.write(\"LLAMA-3.2-1B FINE-TUNING RESULTS\\n\")\n",
        "    f.write(\"=\"*70 + \"\\n\\n\")\n",
        "    for metric, value in llama_results.items():\n",
        "        if metric != \"model_name\":\n",
        "            f.write(f\"{metric.upper():15s}: {value:.4f}\\n\")\n",
        "        else:\n",
        "            f.write(f\"MODEL: {value}\\n\")\n",
        "    f.write(\"\\n\" + classification_report(test_df[\"labels\"].values, test_pred_labels,\n",
        "                                         target_names=[\"Non-Viral\", \"Viral\"]))\n",
        "\n",
        "print(f\"✓ Results saved to: {results_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch5NRgdeU1v9",
        "outputId": "48caf376-6f4b-40dc-a526-25a12371e48c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "SAVING MODEL\n",
            "======================================================================\n",
            "✓ Model saved to: ./llama-virality-final\n",
            "✓ Results saved to: ./llama-virality-final/test_results.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# SECTION 17: INFERENCE ON RANDOM SAMPLES\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TESTING ON RANDOM SAMPLES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Select 10 random samples from the test set\n",
        "random_indices = np.random.choice(len(test_df), size=10, replace=False)\n",
        "random_samples = test_df.iloc[random_indices].copy()\n",
        "\n",
        "# Prepare samples for prediction\n",
        "sample_texts = random_samples[\"text\"].tolist()\n",
        "sample_labels = random_samples[\"labels\"].values\n",
        "\n",
        "# Tokenize samples\n",
        "sample_encodings = tokenizer(\n",
        "    sample_texts,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    max_length=MAX_LENGTH,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "# Move to the same device as model\n",
        "device = next(model.parameters()).device\n",
        "sample_encodings = {k: v.to(device) for k, v in sample_encodings.items()}\n",
        "\n",
        "# Get predictions\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(**sample_encodings)\n",
        "    logits = outputs.logits\n",
        "    probs = torch.softmax(logits, dim=1)\n",
        "    predictions = torch.argmax(logits, dim=1)\n",
        "\n",
        "# Convert to numpy\n",
        "probs_np = probs.cpu().numpy()\n",
        "predictions_np = predictions.cpu().numpy()\n",
        "\n",
        "# Display results\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"RANDOM SAMPLE PREDICTIONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for i, (text, true_label, pred_label, prob) in enumerate(zip(\n",
        "    sample_texts, sample_labels, predictions_np, probs_np\n",
        "), 1):\n",
        "    viral_prob = prob[1] * 100  # Probability of being viral\n",
        "    non_viral_prob = prob[0] * 100  # Probability of being non-viral\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"SAMPLE #{i}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Tweet: {text[:200]}{'...' if len(text) > 200 else ''}\")\n",
        "    print(f\"\\nTrue Label:      {'🔥 VIRAL' if true_label == 1 else '📊 Non-Viral'}\")\n",
        "    print(f\"Predicted Label: {'🔥 VIRAL' if pred_label == 1 else '📊 Non-Viral'}\")\n",
        "    print(f\"Correct:         {'✓ YES' if true_label == pred_label else '✗ NO'}\")\n",
        "    print(f\"\\nProbabilities:\")\n",
        "    print(f\"  Non-Viral: {non_viral_prob:5.2f}%\")\n",
        "    print(f\"  Viral:     {viral_prob:5.2f}%\")\n",
        "\n",
        "# Calculate accuracy on random samples\n",
        "random_accuracy = accuracy_score(sample_labels, predictions_np)\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"RANDOM SAMPLE ACCURACY: {random_accuracy*100:.2f}% ({int(random_accuracy*10)}/10 correct)\")\n",
        "print(f\"{'='*70}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ztCEsJqYjSh",
        "outputId": "f72cad1f-6b1e-40ec-8e27-8147f10ce788"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TESTING ON RANDOM SAMPLES\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "RANDOM SAMPLE PREDICTIONS\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "SAMPLE #1\n",
            "======================================================================\n",
            "Tweet: Royalty 🙌😍 Buy now pay later with afterpay! Available at checkout on orders $35 plus \n",
            "\n",
            ":\n",
            ":\n",
            "All of our lashes can be worn up to 25 times with proper care ♻️\n",
            ":\n",
            ":\n",
            ":\n",
            ": \n",
            "#biglashes #makeupmaffia #browsford...\n",
            "\n",
            "True Label:      📊 Non-Viral\n",
            "Predicted Label: 📊 Non-Viral\n",
            "Correct:         ✓ YES\n",
            "\n",
            "Probabilities:\n",
            "  Non-Viral: 99.97%\n",
            "  Viral:      0.03%\n",
            "\n",
            "======================================================================\n",
            "SAMPLE #2\n",
            "======================================================================\n",
            "Tweet: @acj1225 @sanjin_xr @RealEyeman WRONG.\n",
            "\n",
            "She was forced to become a lesbian in the DLC.\n",
            "\n",
            "True Label:      📊 Non-Viral\n",
            "Predicted Label: 📊 Non-Viral\n",
            "Correct:         ✓ YES\n",
            "\n",
            "Probabilities:\n",
            "  Non-Viral: 99.99%\n",
            "  Viral:      0.01%\n",
            "\n",
            "======================================================================\n",
            "SAMPLE #3\n",
            "======================================================================\n",
            "Tweet: Diplomacy doesn’t get you far in sports. They only remember the lie you told us. Ron gotta get media training. This ain’t Carolina\n",
            "\n",
            "True Label:      📊 Non-Viral\n",
            "Predicted Label: 📊 Non-Viral\n",
            "Correct:         ✓ YES\n",
            "\n",
            "Probabilities:\n",
            "  Non-Viral: 100.00%\n",
            "  Viral:      0.00%\n",
            "\n",
            "======================================================================\n",
            "SAMPLE #4\n",
            "======================================================================\n",
            "Tweet: Happy Valentine's Day to Ronniecoln 🧡💜 https://t.co/lz1lPczVvh\n",
            "\n",
            "True Label:      📊 Non-Viral\n",
            "Predicted Label: 📊 Non-Viral\n",
            "Correct:         ✓ YES\n",
            "\n",
            "Probabilities:\n",
            "  Non-Viral: 99.83%\n",
            "  Viral:      0.17%\n",
            "\n",
            "======================================================================\n",
            "SAMPLE #5\n",
            "======================================================================\n",
            "Tweet: This dish will have you howling at the moon this evening. 🌙 https://t.co/xUCEA75sFU\n",
            "\n",
            "True Label:      📊 Non-Viral\n",
            "Predicted Label: 📊 Non-Viral\n",
            "Correct:         ✓ YES\n",
            "\n",
            "Probabilities:\n",
            "  Non-Viral: 99.96%\n",
            "  Viral:      0.04%\n",
            "\n",
            "======================================================================\n",
            "SAMPLE #6\n",
            "======================================================================\n",
            "Tweet: Bruno Saltor:\n",
            "\n",
            "\"I've been coaching for four years and I've been under Graham, he's been the manager and always had the last word... Tomorrow is going to be the first time [selecting a starting XI]. I ...\n",
            "\n",
            "True Label:      📊 Non-Viral\n",
            "Predicted Label: 📊 Non-Viral\n",
            "Correct:         ✓ YES\n",
            "\n",
            "Probabilities:\n",
            "  Non-Viral: 99.78%\n",
            "  Viral:      0.22%\n",
            "\n",
            "======================================================================\n",
            "SAMPLE #7\n",
            "======================================================================\n",
            "Tweet: We are #hiring IT Service Management Senior Consultant in Raleigh, NC https://t.co/KmBBE7bYJv #jobs #Raleigh #IT #Technology\n",
            "\n",
            "True Label:      📊 Non-Viral\n",
            "Predicted Label: 📊 Non-Viral\n",
            "Correct:         ✓ YES\n",
            "\n",
            "Probabilities:\n",
            "  Non-Viral: 100.00%\n",
            "  Viral:      0.00%\n",
            "\n",
            "======================================================================\n",
            "SAMPLE #8\n",
            "======================================================================\n",
            "Tweet: @Lisa_ex1 I want you to crush my skull with your thighs and smother me with your breasts.\n",
            "\n",
            "True Label:      📊 Non-Viral\n",
            "Predicted Label: 📊 Non-Viral\n",
            "Correct:         ✓ YES\n",
            "\n",
            "Probabilities:\n",
            "  Non-Viral: 99.99%\n",
            "  Viral:      0.01%\n",
            "\n",
            "======================================================================\n",
            "SAMPLE #9\n",
            "======================================================================\n",
            "Tweet: Hi guys! Tomorrow is the answering day!😉 Have all a good night and prepare a nice questions.\n",
            "\n",
            "True Label:      📊 Non-Viral\n",
            "Predicted Label: 📊 Non-Viral\n",
            "Correct:         ✓ YES\n",
            "\n",
            "Probabilities:\n",
            "  Non-Viral: 99.96%\n",
            "  Viral:      0.04%\n",
            "\n",
            "======================================================================\n",
            "SAMPLE #10\n",
            "======================================================================\n",
            "Tweet: Hey Austin let's dance! \n",
            "This Saturday at The Waterhole Saloon with Duane Mark https://t.co/XrliohnI4h\n",
            "\n",
            "True Label:      📊 Non-Viral\n",
            "Predicted Label: 📊 Non-Viral\n",
            "Correct:         ✓ YES\n",
            "\n",
            "Probabilities:\n",
            "  Non-Viral: 99.98%\n",
            "  Viral:      0.02%\n",
            "\n",
            "======================================================================\n",
            "RANDOM SAMPLE ACCURACY: 100.00% (10/10 correct)\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "# SECTION 17: INFERENCE ON RANDOM SAMPLES + PROMPT ENGINEERING\n",
        "# =====================================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TESTING ON RANDOM SAMPLES WITH PROMPT ENGINEERING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Select 10 random samples from the test set\n",
        "random_indices = np.random.choice(len(test_df), size=10, replace=False)\n",
        "random_samples = test_df.iloc[random_indices].copy()\n",
        "\n",
        "# Prepare samples for prediction\n",
        "sample_texts = random_samples[\"text\"].tolist()\n",
        "sample_labels = random_samples[\"labels\"].values\n",
        "\n",
        "def predict_virality(texts, model, tokenizer, max_length=MAX_LENGTH):\n",
        "    \"\"\"Helper function to predict virality for a list of texts\"\"\"\n",
        "    encodings = tokenizer(\n",
        "        texts,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    device = next(model.parameters()).device\n",
        "    encodings = {k: v.to(device) for k, v in encodings.items()}\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encodings)\n",
        "        logits = outputs.logits\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        predictions = torch.argmax(logits, dim=1)\n",
        "\n",
        "    return predictions.cpu().numpy(), probs.cpu().numpy()\n",
        "\n",
        "def prompt_engineer_for_virality(tweet):\n",
        "    \"\"\"\n",
        "    Apply viral tweet engineering techniques:\n",
        "    1. Add emotional hooks\n",
        "    2. Create urgency/scarcity\n",
        "    3. Use power words\n",
        "    4. Add social proof elements\n",
        "    5. Make it controversial/thought-provoking\n",
        "    6. Use numbers and statistics\n",
        "    7. Add call-to-action elements\n",
        "    \"\"\"\n",
        "\n",
        "    # Extract core message (simplified approach)\n",
        "    core = tweet.strip()\n",
        "\n",
        "    # Viral engineering strategies (pick based on tweet content)\n",
        "    strategies = [\n",
        "        # Strategy 1: Emotional hook + urgency\n",
        "        f\"🚨 BREAKING: {core}\\n\\nThis changes EVERYTHING. Thread 🧵👇\",\n",
        "\n",
        "        # Strategy 2: Controversy + engagement\n",
        "        f\"Unpopular opinion: {core}\\n\\nChange my mind. 👇\",\n",
        "\n",
        "        # Strategy 3: Social proof + FOMO\n",
        "        f\"10M+ people are talking about this:\\n\\n{core}\\n\\nDon't miss out 🔥\",\n",
        "\n",
        "        # Strategy 4: Question + curiosity gap\n",
        "        f\"Why is nobody talking about this?\\n\\n{core}\\n\\nRetweet if you agree 🔄\",\n",
        "\n",
        "        # Strategy 5: Shock value + numbers\n",
        "        f\"97% of people don't know this:\\n\\n{core}\\n\\nLet that sink in. 💭\",\n",
        "    ]\n",
        "\n",
        "    # For this demo, we'll return all 5 variations\n",
        "    return strategies\n",
        "\n",
        "# Display original predictions\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ORIGINAL TWEETS - PREDICTIONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "original_preds, original_probs = predict_virality(sample_texts, model, tokenizer)\n",
        "\n",
        "original_results = []\n",
        "for i, (text, true_label, pred_label, prob) in enumerate(zip(\n",
        "    sample_texts, sample_labels, original_preds, original_probs\n",
        "), 1):\n",
        "    viral_prob = prob[1] * 100\n",
        "    original_results.append({\n",
        "        'text': text,\n",
        "        'true_label': true_label,\n",
        "        'pred_label': pred_label,\n",
        "        'viral_prob': viral_prob\n",
        "    })\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"SAMPLE #{i}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Tweet: {text[:150]}{'...' if len(text) > 150 else ''}\")\n",
        "    print(f\"True Label:      {'🔥 VIRAL' if true_label == 1 else '📊 Non-Viral'}\")\n",
        "    print(f\"Predicted:       {'🔥 VIRAL' if pred_label == 1 else '📊 Non-Viral'}\")\n",
        "    print(f\"Viral Probability: {viral_prob:.2f}%\")\n",
        "\n",
        "# Now apply prompt engineering\n",
        "print(\"\\n\\n\" + \"=\"*70)\n",
        "print(\"PROMPT-ENGINEERED VERSIONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "engineered_results = []\n",
        "\n",
        "for i, (text, result) in enumerate(zip(sample_texts, original_results), 1):\n",
        "    print(f\"\\n{'#'*70}\")\n",
        "    print(f\"SAMPLE #{i} - VIRAL ENGINEERING EXPERIMENTS\")\n",
        "    print(f\"{'#'*70}\")\n",
        "\n",
        "    # Get engineered versions\n",
        "    engineered_versions = prompt_engineer_for_virality(text)\n",
        "\n",
        "    # Predict for all versions\n",
        "    eng_preds, eng_probs = predict_virality(engineered_versions, model, tokenizer)\n",
        "\n",
        "    print(f\"\\n📝 ORIGINAL (Viral prob: {result['viral_prob']:.2f}%):\")\n",
        "    print(f\"   {text[:120]}{'...' if len(text) > 120 else ''}\")\n",
        "\n",
        "    best_improvement = 0\n",
        "    best_version = None\n",
        "    best_prob = result['viral_prob']\n",
        "\n",
        "    for j, (eng_text, eng_pred, eng_prob) in enumerate(zip(\n",
        "        engineered_versions, eng_preds, eng_probs\n",
        "    ), 1):\n",
        "        viral_prob = eng_prob[1] * 100\n",
        "        improvement = viral_prob - result['viral_prob']\n",
        "\n",
        "        print(f\"\\n🔧 VERSION {j} (Viral prob: {viral_prob:.2f}%, {improvement:+.2f}% change):\")\n",
        "        print(f\"   {eng_text[:200]}{'...' if len(eng_text) > 200 else ''}\")\n",
        "        print(f\"   Status: {'🔥 VIRAL' if eng_pred == 1 else '📊 Non-Viral'}\")\n",
        "\n",
        "        if viral_prob > best_prob:\n",
        "            best_prob = viral_prob\n",
        "            best_improvement = improvement\n",
        "            best_version = j\n",
        "\n",
        "    if best_version:\n",
        "        print(f\"\\n✨ BEST VERSION: #{best_version} with {best_prob:.2f}% viral probability (+{best_improvement:.2f}%)\")\n",
        "    else:\n",
        "        print(f\"\\n⚠️ Original tweet had highest viral probability\")\n",
        "\n",
        "    engineered_results.append({\n",
        "        'original_prob': result['viral_prob'],\n",
        "        'best_engineered_prob': best_prob,\n",
        "        'improvement': best_improvement\n",
        "    })\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\n\\n\" + \"=\"*70)\n",
        "print(\"PROMPT ENGINEERING SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "avg_original = np.mean([r['original_prob'] for r in engineered_results])\n",
        "avg_best = np.mean([r['best_engineered_prob'] for r in engineered_results])\n",
        "avg_improvement = np.mean([r['improvement'] for r in engineered_results])\n",
        "\n",
        "improved_count = sum(1 for r in engineered_results if r['improvement'] > 0)\n",
        "\n",
        "print(f\"\\nAverage Original Viral Probability:    {avg_original:.2f}%\")\n",
        "print(f\"Average Best Engineered Probability:   {avg_best:.2f}%\")\n",
        "print(f\"Average Improvement:                   {avg_improvement:+.2f}%\")\n",
        "print(f\"Samples Improved:                      {improved_count}/10 ({improved_count*10}%)\")\n",
        "\n",
        "max_improvement = max(engineered_results, key=lambda x: x['improvement'])\n",
        "print(f\"\\nLargest Improvement:                   +{max_improvement['improvement']:.2f}%\")\n",
        "print(f\"  (from {max_improvement['original_prob']:.2f}% to {max_improvement['best_engineered_prob']:.2f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcMOsaUeYj_U",
        "outputId": "fe931c33-93ef-46c9-98be-880a1ea500f9"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TESTING ON RANDOM SAMPLES WITH PROMPT ENGINEERING\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "ORIGINAL TWEETS - PREDICTIONS\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "SAMPLE #1\n",
            "======================================================================\n",
            "Tweet: Is it tiiiiiiime to release the sweet treats... 🧛‍♂️ Muhhhhhaaaaaahhhhhhh! 🎃 everyone deserve to be a kid 💬 No matter how old you get! Soooon 🤗 https:...\n",
            "True Label:      📊 Non-Viral\n",
            "Predicted:       📊 Non-Viral\n",
            "Viral Probability: 0.33%\n",
            "\n",
            "======================================================================\n",
            "SAMPLE #2\n",
            "======================================================================\n",
            "Tweet: As U.S. COVID deaths near 1 million, advocates press for a memorial day : NPR https://t.co/JwPfUtMSGa\n",
            "True Label:      📊 Non-Viral\n",
            "Predicted:       📊 Non-Viral\n",
            "Viral Probability: 0.02%\n",
            "\n",
            "======================================================================\n",
            "SAMPLE #3\n",
            "======================================================================\n",
            "Tweet: Donald Trump is on Fox News trying to explain himself. There’s no excuse for his inaction. If he would have acted two weeks earlier thousands of lives...\n",
            "True Label:      📊 Non-Viral\n",
            "Predicted:       📊 Non-Viral\n",
            "Viral Probability: 0.25%\n",
            "\n",
            "======================================================================\n",
            "SAMPLE #4\n",
            "======================================================================\n",
            "Tweet: Interesting to note that, in Huruma this pastor and his church grabbed a whole section of public road that passed through his church, fenced it turned...\n",
            "True Label:      📊 Non-Viral\n",
            "Predicted:       📊 Non-Viral\n",
            "Viral Probability: 0.03%\n",
            "\n",
            "======================================================================\n",
            "SAMPLE #5\n",
            "======================================================================\n",
            "Tweet: @thecraigrpowers 'the insurection of 1/6'? 'ka fucking boom'?\n",
            "True Label:      📊 Non-Viral\n",
            "Predicted:       📊 Non-Viral\n",
            "Viral Probability: 0.02%\n",
            "\n",
            "======================================================================\n",
            "SAMPLE #6\n",
            "======================================================================\n",
            "Tweet: 07:01, 1/8   Good morning, Savannah nest fans! https://t.co/r8btcslfH5\n",
            "True Label:      📊 Non-Viral\n",
            "Predicted:       📊 Non-Viral\n",
            "Viral Probability: 0.02%\n",
            "\n",
            "======================================================================\n",
            "SAMPLE #7\n",
            "======================================================================\n",
            "Tweet: @bobpoekert @mycoliza @hdevalence I'm not sure what point you're trying to make.\n",
            "True Label:      📊 Non-Viral\n",
            "Predicted:       📊 Non-Viral\n",
            "Viral Probability: 0.00%\n",
            "\n",
            "======================================================================\n",
            "SAMPLE #8\n",
            "======================================================================\n",
            "Tweet: 🌈『女性専科』: グローバル スタンダードで、貴女の悩みにコメントします🌹🙋‍♀️挙手制⏰60分” with Frankly Speaking! 率直な気持ち. Today, Feb 24 at 9:00 PM JST in @clubhouse. Join us! https://t.co/Urx...\n",
            "True Label:      📊 Non-Viral\n",
            "Predicted:       📊 Non-Viral\n",
            "Viral Probability: 0.09%\n",
            "\n",
            "======================================================================\n",
            "SAMPLE #9\n",
            "======================================================================\n",
            "Tweet: Bolstering growth opportunities for families, workers, tourists, and businesses in small towns.\n",
            "True Label:      📊 Non-Viral\n",
            "Predicted:       📊 Non-Viral\n",
            "Viral Probability: 0.01%\n",
            "\n",
            "======================================================================\n",
            "SAMPLE #10\n",
            "======================================================================\n",
            "Tweet: Making a grande entrance 🤩\n",
            "\n",
            "@CoolsHannes is starting his #postdocposition at @AIMediaDem_Lab and @DDC_SDU November 1. \n",
            " \n",
            "But today he stopped by and (...\n",
            "True Label:      📊 Non-Viral\n",
            "Predicted:       📊 Non-Viral\n",
            "Viral Probability: 0.03%\n",
            "\n",
            "\n",
            "======================================================================\n",
            "PROMPT-ENGINEERED VERSIONS\n",
            "======================================================================\n",
            "\n",
            "######################################################################\n",
            "SAMPLE #1 - VIRAL ENGINEERING EXPERIMENTS\n",
            "######################################################################\n",
            "\n",
            "📝 ORIGINAL (Viral prob: 0.33%):\n",
            "   Is it tiiiiiiime to release the sweet treats... 🧛‍♂️ Muhhhhhaaaaaahhhhhhh! 🎃 everyone deserve to be a kid 💬 No matter ho...\n",
            "\n",
            "🔧 VERSION 1 (Viral prob: 0.03%, -0.31% change):\n",
            "   🚨 BREAKING: Is it tiiiiiiime to release the sweet treats... 🧛‍♂️ Muhhhhhaaaaaahhhhhhh! 🎃 everyone deserve to be a kid 💬 No matter how old you get! Soooon 🤗 https://t.co/ZUteb2CPaK\n",
            "\n",
            "This changes EVERYT...\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 2 (Viral prob: 0.01%, -0.32% change):\n",
            "   Unpopular opinion: Is it tiiiiiiime to release the sweet treats... 🧛‍♂️ Muhhhhhaaaaaahhhhhhh! 🎃 everyone deserve to be a kid 💬 No matter how old you get! Soooon 🤗 https://t.co/ZUteb2CPaK\n",
            "\n",
            "Change my mi...\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 3 (Viral prob: 0.01%, -0.32% change):\n",
            "   10M+ people are talking about this:\n",
            "\n",
            "Is it tiiiiiiime to release the sweet treats... 🧛‍♂️ Muhhhhhaaaaaahhhhhhh! 🎃 everyone deserve to be a kid 💬 No matter how old you get! Soooon 🤗 https://t.co/ZUteb2...\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 4 (Viral prob: 0.03%, -0.30% change):\n",
            "   Why is nobody talking about this?\n",
            "\n",
            "Is it tiiiiiiime to release the sweet treats... 🧛‍♂️ Muhhhhhaaaaaahhhhhhh! 🎃 everyone deserve to be a kid 💬 No matter how old you get! Soooon 🤗 https://t.co/ZUteb2CP...\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 5 (Viral prob: 0.03%, -0.30% change):\n",
            "   97% of people don't know this:\n",
            "\n",
            "Is it tiiiiiiime to release the sweet treats... 🧛‍♂️ Muhhhhhaaaaaahhhhhhh! 🎃 everyone deserve to be a kid 💬 No matter how old you get! Soooon 🤗 https://t.co/ZUteb2CPaK\n",
            "...\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "⚠️ Original tweet had highest viral probability\n",
            "\n",
            "######################################################################\n",
            "SAMPLE #2 - VIRAL ENGINEERING EXPERIMENTS\n",
            "######################################################################\n",
            "\n",
            "📝 ORIGINAL (Viral prob: 0.02%):\n",
            "   As U.S. COVID deaths near 1 million, advocates press for a memorial day : NPR https://t.co/JwPfUtMSGa\n",
            "\n",
            "🔧 VERSION 1 (Viral prob: 0.03%, +0.02% change):\n",
            "   🚨 BREAKING: As U.S. COVID deaths near 1 million, advocates press for a memorial day : NPR https://t.co/JwPfUtMSGa\n",
            "\n",
            "This changes EVERYTHING. Thread 🧵👇\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 2 (Viral prob: 0.01%, -0.00% change):\n",
            "   Unpopular opinion: As U.S. COVID deaths near 1 million, advocates press for a memorial day : NPR https://t.co/JwPfUtMSGa\n",
            "\n",
            "Change my mind. 👇\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 3 (Viral prob: 0.00%, -0.01% change):\n",
            "   10M+ people are talking about this:\n",
            "\n",
            "As U.S. COVID deaths near 1 million, advocates press for a memorial day : NPR https://t.co/JwPfUtMSGa\n",
            "\n",
            "Don't miss out 🔥\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 4 (Viral prob: 0.03%, +0.02% change):\n",
            "   Why is nobody talking about this?\n",
            "\n",
            "As U.S. COVID deaths near 1 million, advocates press for a memorial day : NPR https://t.co/JwPfUtMSGa\n",
            "\n",
            "Retweet if you agree 🔄\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 5 (Viral prob: 0.21%, +0.19% change):\n",
            "   97% of people don't know this:\n",
            "\n",
            "As U.S. COVID deaths near 1 million, advocates press for a memorial day : NPR https://t.co/JwPfUtMSGa\n",
            "\n",
            "Let that sink in. 💭\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "✨ BEST VERSION: #5 with 0.21% viral probability (+0.19%)\n",
            "\n",
            "######################################################################\n",
            "SAMPLE #3 - VIRAL ENGINEERING EXPERIMENTS\n",
            "######################################################################\n",
            "\n",
            "📝 ORIGINAL (Viral prob: 0.25%):\n",
            "   Donald Trump is on Fox News trying to explain himself. There’s no excuse for his inaction. If he would have acted two we...\n",
            "\n",
            "🔧 VERSION 1 (Viral prob: 0.23%, -0.02% change):\n",
            "   🚨 BREAKING: Donald Trump is on Fox News trying to explain himself. There’s no excuse for his inaction. If he would have acted two weeks earlier thousands of lives would have been saved. #TrumpKnew\n",
            "\n",
            "Th...\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 2 (Viral prob: 0.04%, -0.21% change):\n",
            "   Unpopular opinion: Donald Trump is on Fox News trying to explain himself. There’s no excuse for his inaction. If he would have acted two weeks earlier thousands of lives would have been saved. #TrumpK...\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 3 (Viral prob: 0.01%, -0.24% change):\n",
            "   10M+ people are talking about this:\n",
            "\n",
            "Donald Trump is on Fox News trying to explain himself. There’s no excuse for his inaction. If he would have acted two weeks earlier thousands of lives would have b...\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 4 (Viral prob: 0.12%, -0.13% change):\n",
            "   Why is nobody talking about this?\n",
            "\n",
            "Donald Trump is on Fox News trying to explain himself. There’s no excuse for his inaction. If he would have acted two weeks earlier thousands of lives would have bee...\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 5 (Viral prob: 1.00%, +0.75% change):\n",
            "   97% of people don't know this:\n",
            "\n",
            "Donald Trump is on Fox News trying to explain himself. There’s no excuse for his inaction. If he would have acted two weeks earlier thousands of lives would have been s...\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "✨ BEST VERSION: #5 with 1.00% viral probability (+0.75%)\n",
            "\n",
            "######################################################################\n",
            "SAMPLE #4 - VIRAL ENGINEERING EXPERIMENTS\n",
            "######################################################################\n",
            "\n",
            "📝 ORIGINAL (Viral prob: 0.03%):\n",
            "   Interesting to note that, in Huruma this pastor and his church grabbed a whole section of public road that passed throug...\n",
            "\n",
            "🔧 VERSION 1 (Viral prob: 0.02%, -0.02% change):\n",
            "   🚨 BREAKING: Interesting to note that, in Huruma this pastor and his church grabbed a whole section of public road that passed through his church, fenced it turned it into part of church land.\n",
            "\n",
            "The com...\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 2 (Viral prob: 0.01%, -0.02% change):\n",
            "   Unpopular opinion: Interesting to note that, in Huruma this pastor and his church grabbed a whole section of public road that passed through his church, fenced it turned it into part of church land.\n",
            "\n",
            "...\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 3 (Viral prob: 0.00%, -0.03% change):\n",
            "   10M+ people are talking about this:\n",
            "\n",
            "Interesting to note that, in Huruma this pastor and his church grabbed a whole section of public road that passed through his church, fenced it turned it into part...\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 4 (Viral prob: 0.01%, -0.02% change):\n",
            "   Why is nobody talking about this?\n",
            "\n",
            "Interesting to note that, in Huruma this pastor and his church grabbed a whole section of public road that passed through his church, fenced it turned it into part o...\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 5 (Viral prob: 0.04%, +0.01% change):\n",
            "   97% of people don't know this:\n",
            "\n",
            "Interesting to note that, in Huruma this pastor and his church grabbed a whole section of public road that passed through his church, fenced it turned it into part of c...\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "✨ BEST VERSION: #5 with 0.04% viral probability (+0.01%)\n",
            "\n",
            "######################################################################\n",
            "SAMPLE #5 - VIRAL ENGINEERING EXPERIMENTS\n",
            "######################################################################\n",
            "\n",
            "📝 ORIGINAL (Viral prob: 0.02%):\n",
            "   @thecraigrpowers 'the insurection of 1/6'? 'ka fucking boom'?\n",
            "\n",
            "🔧 VERSION 1 (Viral prob: 0.05%, +0.03% change):\n",
            "   🚨 BREAKING: @thecraigrpowers 'the insurection of 1/6'? 'ka fucking boom'?\n",
            "\n",
            "This changes EVERYTHING. Thread 🧵👇\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 2 (Viral prob: 0.01%, -0.01% change):\n",
            "   Unpopular opinion: @thecraigrpowers 'the insurection of 1/6'? 'ka fucking boom'?\n",
            "\n",
            "Change my mind. 👇\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 3 (Viral prob: 0.00%, -0.02% change):\n",
            "   10M+ people are talking about this:\n",
            "\n",
            "@thecraigrpowers 'the insurection of 1/6'? 'ka fucking boom'?\n",
            "\n",
            "Don't miss out 🔥\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 4 (Viral prob: 0.03%, +0.01% change):\n",
            "   Why is nobody talking about this?\n",
            "\n",
            "@thecraigrpowers 'the insurection of 1/6'? 'ka fucking boom'?\n",
            "\n",
            "Retweet if you agree 🔄\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 5 (Viral prob: 0.04%, +0.02% change):\n",
            "   97% of people don't know this:\n",
            "\n",
            "@thecraigrpowers 'the insurection of 1/6'? 'ka fucking boom'?\n",
            "\n",
            "Let that sink in. 💭\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "✨ BEST VERSION: #1 with 0.05% viral probability (+0.03%)\n",
            "\n",
            "######################################################################\n",
            "SAMPLE #6 - VIRAL ENGINEERING EXPERIMENTS\n",
            "######################################################################\n",
            "\n",
            "📝 ORIGINAL (Viral prob: 0.02%):\n",
            "   07:01, 1/8   Good morning, Savannah nest fans! https://t.co/r8btcslfH5\n",
            "\n",
            "🔧 VERSION 1 (Viral prob: 0.02%, +0.00% change):\n",
            "   🚨 BREAKING: 07:01, 1/8   Good morning, Savannah nest fans! https://t.co/r8btcslfH5\n",
            "\n",
            "This changes EVERYTHING. Thread 🧵👇\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 2 (Viral prob: 0.00%, -0.01% change):\n",
            "   Unpopular opinion: 07:01, 1/8   Good morning, Savannah nest fans! https://t.co/r8btcslfH5\n",
            "\n",
            "Change my mind. 👇\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 3 (Viral prob: 0.00%, -0.02% change):\n",
            "   10M+ people are talking about this:\n",
            "\n",
            "07:01, 1/8   Good morning, Savannah nest fans! https://t.co/r8btcslfH5\n",
            "\n",
            "Don't miss out 🔥\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 4 (Viral prob: 0.00%, -0.01% change):\n",
            "   Why is nobody talking about this?\n",
            "\n",
            "07:01, 1/8   Good morning, Savannah nest fans! https://t.co/r8btcslfH5\n",
            "\n",
            "Retweet if you agree 🔄\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 5 (Viral prob: 0.03%, +0.01% change):\n",
            "   97% of people don't know this:\n",
            "\n",
            "07:01, 1/8   Good morning, Savannah nest fans! https://t.co/r8btcslfH5\n",
            "\n",
            "Let that sink in. 💭\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "✨ BEST VERSION: #5 with 0.03% viral probability (+0.01%)\n",
            "\n",
            "######################################################################\n",
            "SAMPLE #7 - VIRAL ENGINEERING EXPERIMENTS\n",
            "######################################################################\n",
            "\n",
            "📝 ORIGINAL (Viral prob: 0.00%):\n",
            "   @bobpoekert @mycoliza @hdevalence I'm not sure what point you're trying to make.\n",
            "\n",
            "🔧 VERSION 1 (Viral prob: 0.02%, +0.02% change):\n",
            "   🚨 BREAKING: @bobpoekert @mycoliza @hdevalence I'm not sure what point you're trying to make.\n",
            "\n",
            "This changes EVERYTHING. Thread 🧵👇\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 2 (Viral prob: 0.00%, +0.00% change):\n",
            "   Unpopular opinion: @bobpoekert @mycoliza @hdevalence I'm not sure what point you're trying to make.\n",
            "\n",
            "Change my mind. 👇\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 3 (Viral prob: 0.00%, +0.00% change):\n",
            "   10M+ people are talking about this:\n",
            "\n",
            "@bobpoekert @mycoliza @hdevalence I'm not sure what point you're trying to make.\n",
            "\n",
            "Don't miss out 🔥\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 4 (Viral prob: 0.01%, +0.01% change):\n",
            "   Why is nobody talking about this?\n",
            "\n",
            "@bobpoekert @mycoliza @hdevalence I'm not sure what point you're trying to make.\n",
            "\n",
            "Retweet if you agree 🔄\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 5 (Viral prob: 0.01%, +0.01% change):\n",
            "   97% of people don't know this:\n",
            "\n",
            "@bobpoekert @mycoliza @hdevalence I'm not sure what point you're trying to make.\n",
            "\n",
            "Let that sink in. 💭\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "✨ BEST VERSION: #1 with 0.02% viral probability (+0.02%)\n",
            "\n",
            "######################################################################\n",
            "SAMPLE #8 - VIRAL ENGINEERING EXPERIMENTS\n",
            "######################################################################\n",
            "\n",
            "📝 ORIGINAL (Viral prob: 0.09%):\n",
            "   🌈『女性専科』: グローバル スタンダードで、貴女の悩みにコメントします🌹🙋‍♀️挙手制⏰60分” with Frankly Speaking! 率直な気持ち. Today, Feb 24 at 9:00 PM JST in @clubho...\n",
            "\n",
            "🔧 VERSION 1 (Viral prob: 0.04%, -0.06% change):\n",
            "   🚨 BREAKING: 🌈『女性専科』: グローバル スタンダードで、貴女の悩みにコメントします🌹🙋‍♀️挙手制⏰60分” with Frankly Speaking! 率直な気持ち. Today, Feb 24 at 9:00 PM JST in @clubhouse. Join us! https://t.co/UrxuMoO9YC\n",
            "\n",
            "This changes EVERYTHING. Thre...\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 2 (Viral prob: 0.01%, -0.08% change):\n",
            "   Unpopular opinion: 🌈『女性専科』: グローバル スタンダードで、貴女の悩みにコメントします🌹🙋‍♀️挙手制⏰60分” with Frankly Speaking! 率直な気持ち. Today, Feb 24 at 9:00 PM JST in @clubhouse. Join us! https://t.co/UrxuMoO9YC\n",
            "\n",
            "Change my mind. 👇\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 3 (Viral prob: 0.00%, -0.09% change):\n",
            "   10M+ people are talking about this:\n",
            "\n",
            "🌈『女性専科』: グローバル スタンダードで、貴女の悩みにコメントします🌹🙋‍♀️挙手制⏰60分” with Frankly Speaking! 率直な気持ち. Today, Feb 24 at 9:00 PM JST in @clubhouse. Join us! https://t.co/UrxuMoO9YC\n",
            "\n",
            "Don'...\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 4 (Viral prob: 0.01%, -0.08% change):\n",
            "   Why is nobody talking about this?\n",
            "\n",
            "🌈『女性専科』: グローバル スタンダードで、貴女の悩みにコメントします🌹🙋‍♀️挙手制⏰60分” with Frankly Speaking! 率直な気持ち. Today, Feb 24 at 9:00 PM JST in @clubhouse. Join us! https://t.co/UrxuMoO9YC\n",
            "\n",
            "Retwee...\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 5 (Viral prob: 0.03%, -0.07% change):\n",
            "   97% of people don't know this:\n",
            "\n",
            "🌈『女性専科』: グローバル スタンダードで、貴女の悩みにコメントします🌹🙋‍♀️挙手制⏰60分” with Frankly Speaking! 率直な気持ち. Today, Feb 24 at 9:00 PM JST in @clubhouse. Join us! https://t.co/UrxuMoO9YC\n",
            "\n",
            "Let that ...\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "⚠️ Original tweet had highest viral probability\n",
            "\n",
            "######################################################################\n",
            "SAMPLE #9 - VIRAL ENGINEERING EXPERIMENTS\n",
            "######################################################################\n",
            "\n",
            "📝 ORIGINAL (Viral prob: 0.01%):\n",
            "   Bolstering growth opportunities for families, workers, tourists, and businesses in small towns.\n",
            "\n",
            "🔧 VERSION 1 (Viral prob: 0.03%, +0.02% change):\n",
            "   🚨 BREAKING: Bolstering growth opportunities for families, workers, tourists, and businesses in small towns.\n",
            "\n",
            "This changes EVERYTHING. Thread 🧵👇\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 2 (Viral prob: 0.03%, +0.03% change):\n",
            "   Unpopular opinion: Bolstering growth opportunities for families, workers, tourists, and businesses in small towns.\n",
            "\n",
            "Change my mind. 👇\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 3 (Viral prob: 0.00%, -0.01% change):\n",
            "   10M+ people are talking about this:\n",
            "\n",
            "Bolstering growth opportunities for families, workers, tourists, and businesses in small towns.\n",
            "\n",
            "Don't miss out 🔥\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 4 (Viral prob: 0.01%, +0.00% change):\n",
            "   Why is nobody talking about this?\n",
            "\n",
            "Bolstering growth opportunities for families, workers, tourists, and businesses in small towns.\n",
            "\n",
            "Retweet if you agree 🔄\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 5 (Viral prob: 0.08%, +0.07% change):\n",
            "   97% of people don't know this:\n",
            "\n",
            "Bolstering growth opportunities for families, workers, tourists, and businesses in small towns.\n",
            "\n",
            "Let that sink in. 💭\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "✨ BEST VERSION: #5 with 0.08% viral probability (+0.07%)\n",
            "\n",
            "######################################################################\n",
            "SAMPLE #10 - VIRAL ENGINEERING EXPERIMENTS\n",
            "######################################################################\n",
            "\n",
            "📝 ORIGINAL (Viral prob: 0.03%):\n",
            "   Making a grande entrance 🤩\n",
            "\n",
            "@CoolsHannes is starting his #postdocposition at @AIMediaDem_Lab and @DDC_SDU November 1. \n",
            " ...\n",
            "\n",
            "🔧 VERSION 1 (Viral prob: 0.02%, -0.01% change):\n",
            "   🚨 BREAKING: Making a grande entrance 🤩\n",
            "\n",
            "@CoolsHannes is starting his #postdocposition at @AIMediaDem_Lab and @DDC_SDU November 1. \n",
            " \n",
            "But today he stopped by and (unlike me) immediately found the on bo...\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 2 (Viral prob: 0.02%, -0.01% change):\n",
            "   Unpopular opinion: Making a grande entrance 🤩\n",
            "\n",
            "@CoolsHannes is starting his #postdocposition at @AIMediaDem_Lab and @DDC_SDU November 1. \n",
            " \n",
            "But today he stopped by and (unlike me) immediately found th...\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 3 (Viral prob: 0.00%, -0.02% change):\n",
            "   10M+ people are talking about this:\n",
            "\n",
            "Making a grande entrance 🤩\n",
            "\n",
            "@CoolsHannes is starting his #postdocposition at @AIMediaDem_Lab and @DDC_SDU November 1. \n",
            " \n",
            "But today he stopped by and (unlike me) im...\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 4 (Viral prob: 0.01%, -0.02% change):\n",
            "   Why is nobody talking about this?\n",
            "\n",
            "Making a grande entrance 🤩\n",
            "\n",
            "@CoolsHannes is starting his #postdocposition at @AIMediaDem_Lab and @DDC_SDU November 1. \n",
            " \n",
            "But today he stopped by and (unlike me) imme...\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "🔧 VERSION 5 (Viral prob: 0.02%, -0.01% change):\n",
            "   97% of people don't know this:\n",
            "\n",
            "Making a grande entrance 🤩\n",
            "\n",
            "@CoolsHannes is starting his #postdocposition at @AIMediaDem_Lab and @DDC_SDU November 1. \n",
            " \n",
            "But today he stopped by and (unlike me) immedia...\n",
            "   Status: 📊 Non-Viral\n",
            "\n",
            "⚠️ Original tweet had highest viral probability\n",
            "\n",
            "\n",
            "======================================================================\n",
            "PROMPT ENGINEERING SUMMARY\n",
            "======================================================================\n",
            "\n",
            "Average Original Viral Probability:    0.08%\n",
            "Average Best Engineered Probability:   0.19%\n",
            "Average Improvement:                   +0.11%\n",
            "Samples Improved:                      7/10 (70%)\n",
            "\n",
            "Largest Improvement:                   +0.75%\n",
            "  (from 0.25% to 1.00%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FH1D6fQ_ZNl4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}